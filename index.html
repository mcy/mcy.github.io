<!DOCTYPE html> <html lang="en-us"> <head> <link href="https://gmpg.org/xfn/11" rel="profile"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta http-equiv="content-type" content="text/html; charset=utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1"> <title> mcyoung </title> <link rel="stylesheet" href="https://mcyoung.xyz/public/css/syntax.css"> <link rel="stylesheet" href="https://mcyoung.xyz/public/css/syntax-overrides.css"> <link rel="stylesheet" href="https://mcyoung.xyz/public/css/style.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn" crossorigin="anonymous"> <link rel="preload" href="https://mcyoung.xyz/public/fonts/abril-fatface.woff2" as="font" type="font/woff2" crossorigin> <link rel="preload" href="https://mcyoung.xyz/public/fonts/rokkitt.woff2" as="font" type="font/woff2" crossorigin> <link rel="preload" href="https://mcyoung.xyz/public/fonts/rokkitt-italic.woff2" as="font" type="font/woff2" crossorigin> <link rel="preload" href="https://mcyoung.xyz/public/fonts/spline-mono.woff2" as="font" type="font/woff2" crossorigin> <link rel="preload" href="https://mcyoung.xyz/public/fonts/spline-mono-italic.woff2" as="font" type="font/woff2" crossorigin> <link rel="shortcut icon" href="https://mcyoung.xyz/public/favicon.ico"> <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml"> <script src="https://mcyoung.xyz/public/js/minimap.js"></script> <script data-goatcounter="https://mcy.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script> </head> <body> <div class="sidebar"> <div class="sidebar-avatar hide-if-mobile"> <a href="https://mcyoung.xyz/posts"> <img class="sidebar-avatar" src="https://mcyoung.xyz/public/images/avatar.png" alt="Yeah, I drew this. Check out my art blog."></a> </div> <div class="container sidebar-sticky"> <div class="sidebar-about"> <h1><a href="https://mcyoung.xyz/posts"> mcyoung </a></h1> <div class="lead hide-if-mobile">I'm Miguel. I write about compilers, performance, and silly computer things. I also draw Pokémon. </div> </div> <hr class="hide-if-mobile"/> <nav class="sidebar-nav"> <a class="sidebar-nav-item active" href="https://mcyoung.xyz">Home</a> • <a class="sidebar-nav-item" href="https://mcyoung.xyz/about">About</a> • <a class="sidebar-nav-item" href="https://mcyoung.xyz/posts">Posts</a> • <a class="sidebar-nav-item" href="https://mcyoung.xyz/tags">Tags</a> </nav> <nav class="sidebar-nav"> <a class="sidebar-nav-item " href="https://art.mcyoung.xyz">Art</a> • <a class="sidebar-nav-item" href="https://github.com/mcy">GitHub</a> • <a class="sidebar-nav-item" href="https://mcyoung.xyz/resume">Resumé</a> • <a class="sidebar-nav-item" href="https://mcyoung.xyz/syllabus">Syllabus</a> </nav> <br class="hide-if-mobile"/> <span class="hide-if-mobile"> <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA</a> • <a href="https://varz.mcyoung.xyz/">Site Analytics</a> <br> &copy; 2024 Miguel Young de la Sota</span> </div> </div> <div class="content container"><div class="posts"> <div class="post-preview"> <div class="post-title"> <span class="post-meta"> 2023-11-27 • 5751 words • 31 minutes <br class="show-if-mobile"/> <span class="hide-if-mobile">•</span> <a href="https://mcyoung.xyz/tags.html#rust">#rust</a> • <a href="https://mcyoung.xyz/tags.html#optimization">#optimization</a> </span> <h1><a href="/2023/11/27/simd-base64/"> Designing a SIMD Algorithm from Scratch </a></h1> </div> <div class="post"> <p>Another explainer on a fun, esoteric topic: optimizing code with SIMD (single instruction multiple data, also sometimes called <em>vectorization</em>). Designing a good, fast, portable SIMD algorithm is not a simple matter and requires thinking a little bit like a circuit designer.</p> <p>Here’s the mandatory performance benchmark graph to catch your eye.</p> <p><img src="https://mcyoung.xyz/public/images/simd-b64/graph.png" alt="perf perf perf"/></p> <p>“SIMD” often gets thrown around as a buzzword by performance and HPC (high performance computing) nerds, but I don’t think it’s a topic that has very friendly introductions out there, for a lot of reasons.</p> <ul> <li>It’s not something you will really want to care about unless you think performance is cool.</li> <li>APIs for programming with SIMD in most programming languages are <em>garbage</em> (I’ll get into why).</li> <li>SIMD algorithms are hard to think about if you’re very procedural-programming-brained. A functional programming mindset can help a lot.</li> </ul> <p>This post is mostly about <a href="https://docs.rs/vb64/latest/vb64/"><code class="language-plaintext highlighter-rouge">vb64</code></a> (which stands for <em>v</em>ector <em>b</em>ase<em>64</em>), a base64 codec I wrote to see for myself if Rust’s <code class="language-plaintext highlighter-rouge">std::simd</code> library is any good, but it’s also an excuse to talk about SIMD in general.</p> <p>What <em>is</em> SIMD, anyways? Let’s dive in.</p> <p>If you want to skip straight to the writeup on <code class="language-plaintext highlighter-rouge">vb64</code>, click <a href="#parsing-with-simd">here</a>.</p> <h2 id="problems-with-physics"><a href="#problems-with-physics">Problems with Physics</a></h2> <p>Unfortunately, computers exist in the real world<sup>[citation-needed]</sup>, and are bound by the laws of nature. SIMD has relatively little to do with theoretical CS considerations, and everything to do with <em>physics</em>.</p> <p>In the infancy of modern computing, you could simply improve performance of existing programs by buying new computers. This is often incorrectly attributed to Moore’s law (the number of transistors on IC designs doubles every two years). Moore’s law still appears to hold as of 2023, but some time in the last 15 years the <a href="https://en.wikipedia.org/wiki/Dennard_scaling">Dennard scaling</a> effect broke down. This means that denser transistors eventually means increased power dissipation density. In simpler terms, we don’t know how to continue to increase the clock frequency of computers without literally <em>liquefying</em> them.</p> <p>So, since the early aughts, the hot new thing has been bigger core counts. Make your program more multi-threaded and it will run faster on bigger CPUs. This comes with synchronization overhead, since now the cores need to cooperate. All control flow, be it jumps, virtual calls, or synchronization will result in “stall”.</p> <p>The main causes of stall are <em>branches</em>, instructions that indicate code can take one of two possible paths (like an <code class="language-plaintext highlighter-rouge">if</code> statement), and <em>memory operations</em>. Branches include all control flow: <code class="language-plaintext highlighter-rouge">if</code> statements, loops, function calls, function returns, even <code class="language-plaintext highlighter-rouge">switch</code> statements in C. Memory operations are loads and stores, especially ones that are cache-unfriendly.</p> <h3 id="procedural-code-is-slow"><a href="#procedural-code-is-slow">Procedural Code Is Slow</a></h3> <p>Modern compute cores do not execute code line-by-line, because that would be very inefficient. Suppose I have this program:</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">a</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">;</span>
<span class="k">let</span> <span class="n">b</span> <span class="o">=</span> <span class="n">x</span> <span class="o">^</span> <span class="n">y</span><span class="p">;</span>
<span class="nd">println!</span><span class="p">(</span><span class="s">"{a}, {b}"</span><span class="p">);</span>
</code></pre></div></div> <p>There’s no reason for the CPU to wait to finish computing <code class="language-plaintext highlighter-rouge">a</code> before it begins computing <code class="language-plaintext highlighter-rouge">b</code>; it does not depend on <code class="language-plaintext highlighter-rouge">a</code>, and while the add is being executed, the xor circuits are idle. Computers say “program order be damned” and issue the add for <code class="language-plaintext highlighter-rouge">a</code> and the xor for <code class="language-plaintext highlighter-rouge">b</code> simultaneously. This is called <em>instruction-level parallelism</em>, and dependencies that get in the way of it are often called <em>data hazards</em>.</p> <p>Of course, the Zen 2 in the machine I’m writing this with does not have one measly adder per core. It has dozens and dozens! The opportunities for parallelism are massive, as long as the compiler in your CPU’s execution pipeline can clear any data hazards in the way.</p> <p>The better the core can do this, the more it can saturate all of the “functional units” for things like arithmetic, and the more numbers it can crunch per unit time, approaching maximum utilization of the hardware. Whenever the compiler can’t do this, the execution pipeline stalls and your code is slower.</p> <p>Branches stall because they need to wait for the branch condition to be computed before fetching the next instruction (speculative execution is a somewhat iffy workaround for this). Memory operations stall because the data needs to physically arrive at the CPU, and the speed of light is finite in this universe.</p> <p>Trying to reduce stall by improving opportunities for single-core parallelism is not a new idea. Consider the not-so-humble GPU, whose purpose in life is to render images. Images are vectors of pixels (i.e., color values), and rendering operations tend to be highly local. For example, a convolution kernel for a Gaussian blur will be two or even three orders of magnitude smaller than the final image, lending itself to locality.</p> <p>Thus, GPUs are built for divide-and-conquer: they provide primitives for doing batched operations, and extremely limited control flow.</p> <p>“SIMD” is synonymous with “batching”. It stands for “single instruction, multiple data”: a single instruction dispatches parallel operations on multiple <em>lanes</em> of data. GPUs are the original SIMD machines.</p> <h2 id="lane-wise"><a href="#lane-wise">Lane-Wise</a></h2> <p>“SIMD” and “vector” are often used interchangeably. The fundamental unit a SIMD instruction (or “vector instruction”) operates on is a vector: a fixed-size array of numbers that you primarily operate on component-wise These components are called <em>lanes</em>.</p> <p>SIMD vectors are usually quite small, since they need to fit into registers. For example, on my machine, the largest vectors are 256 bits wide. This is enough for 32 bytes (a <code class="language-plaintext highlighter-rouge">u8x32</code>), 4 double-precision floats (an <code class="language-plaintext highlighter-rouge">f64x8</code>), or all kinds of things in between.</p> <p><img src="https://mcyoung.xyz/public/images/simd-b64/vectors.png" alt="some 256-bit vectors"/></p> <p>Although this doesn’t seem like much, remember that offloading the overhead of keeping the pipeline saturated by a factor of 4x can translate to that big of a speedup in latency.</p> <h3 id="one-bit-lanes"><a href="#one-bit-lanes">One-Bit Lanes</a></h3> <p>The simplest vector operations are bitwise: and, or, xor. Ordinary integers can be thought of as vectors themselves, with respect to the bitwise operations. That’s literally what “bitwise” means: lanes-wise with lanes that are one bit wide. An <code class="language-plaintext highlighter-rouge">i32</code> is, in this regard, an <code class="language-plaintext highlighter-rouge">i1x32</code>.</p> <p>In fact, as a warmup, let’s look at the problem of counting the number of 1 bits in an integer. This operation is called “population count”, or <code class="language-plaintext highlighter-rouge">popcnt</code>. If we view an <code class="language-plaintext highlighter-rouge">i32</code> as an <code class="language-plaintext highlighter-rouge">i1x32</code>, <code class="language-plaintext highlighter-rouge">popcnt</code> is just a fold or reduce operation:</p> <p>```rust godbolt:o=-O pub fn popcnt(mut x: u32) -&gt; u32 { let mut bits = [0; 32]; for (i, bit) in bits.iter_mut().enumerate() { *bit = (x » i) &amp; 1; } bits.into_iter().fold(0, |total, bit| total + bit) }</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
In other words, we interpret the integer as an array of bits and then add the
bits together to a 32-bit accumulator. Note that the accumulator needs to be
higher precision to avoid overflow: accumulating into an `i1` (as with the
`Iterator::reduce()` method) will only tell us whether the number of 1 bits is
even or odd.

Of course, this produces... comically bad code, frankly. We can do much better
if we notice that we can _vectorize_ the addition: first we add all of the
adjacent pairs of bits together, then the pairs of pairs, and so on. This means
the number of adds is logarithmic in the number of bits in the integer.

Visually, what we do is we "unzip" each vector, shift one to line up the lanes,
add them, and then repeat with lanes twice as big.

![first two popcnt merge steps](https://mcyoung.xyz/public/images/simd-b64/popcnt.png)

This is what that looks like in code.

```rust godbolt:o=-O
pub fn popcnt(mut x: u32) -&gt; u32 {
  // View x as a i1x32, and split it into two vectors
  // that contain the even and odd bits, respectively.
  let even = x &amp; 0x55555555; // 0x5 == 0b0101.
  let odds = x &amp; 0xaaaaaaaa; // 0xa == 0b1010.
  // Shift odds down to align the bits, and then add them together.
  // We interpret x now as a i2x16. When adding, each two-bit
  // lane cannot overflow, because the value in each lane is
  // either 0b00 or 0b01.
  x = even + (odds &gt;&gt; 1);

  // Repeat again but now splitting even and odd bit-pairs.
  let even = x &amp; 0x33333333; // 0x3 == 0b0011.
  let odds = x &amp; 0xcccccccc; // 0xc == 0b1100.
  // We need to shift by 2 to align, and now for this addition
  // we interpret x as a i4x8.
  x = even + (odds &gt;&gt; 2);

  // Again. The pattern should now be obvious.
  let even = x &amp; 0x0f0f0f0f; // 0x0f == 0b00001111.
  let odds = x &amp; 0xf0f0f0f0; // 0xf0 == 0b11110000.
  x = even + (odds &gt;&gt; 4); // i8x4

  let even = x &amp; 0x00ff00ff;
  let odds = x &amp; 0xff00ff00;
  x = even + (odds &gt;&gt; 8);  // i16x2

  let even = x &amp; 0x0000ffff;
  let odds = x &amp; 0xffff0000;
  // Because the value of `x` is at most 32, although we interpret this as a
  // i32x1 add, we could get away with just one e.g. i16 add.
  x = even + (odds &gt;&gt; 16);

  x // Done. All bits have been added.
}
</code></pre></div></div> <p>This still won’t optimize down to a <code class="language-plaintext highlighter-rouge">popcnt</code> instruction, of course. The search scope for such a simplification is in the regime of superoptimizers. However, the generated code is small and fast, which is why this is the ideal implementation of <code class="language-plaintext highlighter-rouge">popcnt</code> for systems without such an instruction.</p> <p>It’s <em>especially</em> nice because it is implementable for e.g. <code class="language-plaintext highlighter-rouge">u64</code> with only one more reduction step (remember: it’s <code class="language-plaintext highlighter-rouge">$O(\log n)$</code>!), and does not at any point require a full <code class="language-plaintext highlighter-rouge">u64</code> addition.</p> <p>Even though this is “just” using scalars, divide-and-conquer approaches like this are the bread and butter of the SIMD programmer.</p> <h3 id="scaling-up-operations-on-real-vectors"><a href="#scaling-up-operations-on-real-vectors">Scaling Up: Operations on Real Vectors</a></h3> <p>Proper SIMD vectors provide more sophisticated semantics than scalars do, particularly because there is more need to provide replacements for things like control flow. Remember, control flow is slow!</p> <p>What’s actually available is highly dependent on the architecture you’re compiling to (more on this later), but the way vector instruction sets are usually structured is something like this.</p> <p>We have <em>vector registers</em> that are kind of like really big general-purpose registers. For example, on x86, most “high performance” cores (like my Zen 2) implement AVX2, which provides 256 bit <code class="language-plaintext highlighter-rouge">ymm</code> vectors. The registers themselves do not have a “lane count”; that is specified by the instructions. For example, the “vector byte add instruction” interprets the register as being divided into eight-byte lanes and adds them. The corresponding x86 instruction is <code class="language-plaintext highlighter-rouge">vpaddb</code>, which interprets a <code class="language-plaintext highlighter-rouge">ymm</code> as an <code class="language-plaintext highlighter-rouge">i8x32</code>.</p> <p>The operations you usually get are:</p> <ol> <li> <p>Bitwise operations. These don’t need to specify a lane width because it’s always implicitly <code class="language-plaintext highlighter-rouge">1</code>: they’re <em>bit</em>wise.</p> </li> <li> <p>Lane-wise arithmetic. This is addition, subtraction, multiplication, division (both int and float), and shifts<sup id="fnref:shifts-are-arithmetic" role="doc-noteref"><a href="#fn:shifts-are-arithmetic" class="footnote" rel="footnote">1</a></sup> (int only). Lane-wise min and max are also common. These require specifying a lane width. Typically the smallest number of lanes is two or four.</p> </li> <li> <p>Lane-wise compare. Given <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code>, we can create a new <em>mask vector</em> <code class="language-plaintext highlighter-rouge">m</code> such that <code class="language-plaintext highlighter-rouge">m[i] = a[i] &lt; b[i]</code> (or any other comparison operation). A mask vector’s lanes contain boolean values with an unusual bit-pattern: all-zeros (for false) or all-ones (for true)<sup id="fnref:minus-true" role="doc-noteref"><a href="#fn:minus-true" class="footnote" rel="footnote">2</a></sup>.</p> <ul> <li>Masks can be used to select between two vectors: for example, given <code class="language-plaintext highlighter-rouge">m</code>, <code class="language-plaintext highlighter-rouge">x</code>, and <code class="language-plaintext highlighter-rouge">y</code>, you can form a fourth vector <code class="language-plaintext highlighter-rouge">z</code> such that <code class="language-plaintext highlighter-rouge">z[i] = m[i] ? a[i] : b[i]</code>.</li> </ul> </li> <li> <p>Shuffles (sometimes called swizzles). Given <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">x</code>, create a third vector <code class="language-plaintext highlighter-rouge">s</code> such that <code class="language-plaintext highlighter-rouge">s[i] = a[x[i]]</code>. <code class="language-plaintext highlighter-rouge">a</code> is used as a lookup table, and <code class="language-plaintext highlighter-rouge">x</code> as a set of indices. Out of bounds produces a special value, usually zero. This emulates parallelized array access without needing to actually touch RAM (RAM is extremely slow).</p> <ul> <li>Often there is a “shuffle2” or “riffle” operation that allows taking elements from one of two vectors. Given <code class="language-plaintext highlighter-rouge">a</code>, <code class="language-plaintext highlighter-rouge">b</code>, and <code class="language-plaintext highlighter-rouge">x</code>, we now define <code class="language-plaintext highlighter-rouge">s</code> as being <code class="language-plaintext highlighter-rouge">s[i] = (a ++ b)[x[i]]</code>, where <code class="language-plaintext highlighter-rouge">a ++ b</code> is a double-width concatenation. How this is actually implemented depends on architecture, and it’s easy to build out of single shuffles regardless.</li> </ul> </li> </ol> <p>(1) and (2) are ordinary number crunching. Nothing deeply special about them.</p> <p>The comparison and select operations in (3) are intended to help SIMD code stay “branchless”. Branchless code is written such that it performs the same operations regardless of its inputs, and relies on the properties of those operations to produce correct results. For example, this might mean taking advantage of identities like <code class="language-plaintext highlighter-rouge">x * 0 = 0</code> and <code class="language-plaintext highlighter-rouge">a ^ b ^ a = b</code> to discard “garbage” results.</p> <p>The shuffles described in (4) are much more powerful than meets the eye.</p> <p>For example, “broadcast” (sometimes called “splat”) makes a vector whose lanes are all the same scalar, like Rust’s <code class="language-plaintext highlighter-rouge">[42; N]</code> array literal. A broadcast can be expressed as a shuffle: create a vector with the desired value in the first lane, and then shuffle it with an index vector of <code class="language-plaintext highlighter-rouge">[0, 0, ...]</code>.</p> <p><img src="https://mcyoung.xyz/public/images/simd-b64/broadcast.png" alt="diagram of a broadcast"/></p> <p>“Interleave” (also called “zip” or “pack”) takes two vectors <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code> and creates two new vectors <code class="language-plaintext highlighter-rouge">c</code> and <code class="language-plaintext highlighter-rouge">d</code> whose lanes are alternating lanes from <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code>. If the lane count is <code class="language-plaintext highlighter-rouge">n</code>, then <code class="language-plaintext highlighter-rouge">c = [a[0], b[0], a[1], b[1], ...]</code> and <code class="language-plaintext highlighter-rouge">d = [a[n/2], b[n/2], a[n/2 + 1], b[n/2 + 1], ...]</code>. This can also be implemented as a shuffle2, with shuffle indices of <code class="language-plaintext highlighter-rouge">[0, n, 1, n + 1, ...]</code>. “Deinterleave” (or “unzip”, or “unpack”) is the opposite operation: it interprets a pair of vectors as two halves of a larger vector of pairs, and produces two new vectors consisting of the halves of each pair.</p> <p>Interleave can also be interpreted as taking a <code class="language-plaintext highlighter-rouge">[T; N]</code>, transmuting it to a <code class="language-plaintext highlighter-rouge">[[T; N/2]; 2]</code>, performing a matrix transpose to turn it into a <code class="language-plaintext highlighter-rouge">[[T; 2]; N/2]</code>, and then transmuting that back to <code class="language-plaintext highlighter-rouge">[T; N]</code> again. Deinterleave is the same but it transmutes to <code class="language-plaintext highlighter-rouge">[[T; 2]; N/2]</code> first.</p> <p><img src="https://mcyoung.xyz/public/images/simd-b64/interleave.png" alt="diagram of a interleave"/></p> <p>“Rotate” takes a vector <code class="language-plaintext highlighter-rouge">a</code> with <code class="language-plaintext highlighter-rouge">n</code> lanes and produces a new vector <code class="language-plaintext highlighter-rouge">b</code> such that <code class="language-plaintext highlighter-rouge">b[i] = a[(i + j) % n]</code>, for some chosen integer <code class="language-plaintext highlighter-rouge">j</code>. This is yet another shuffle, with indices <code class="language-plaintext highlighter-rouge">[j, j + 1, ..., n - 1, 0, 1, ... j - 1]</code>.</p> <p><img src="https://mcyoung.xyz/public/images/simd-b64/rotate.png" alt="diagram of a rotate"/></p> <p>Shuffles are worth trying to wrap your mind around. SIMD programming is all about reinterpreting larger-than-an-integer-sized blocks of data as smaller blocks of varying sizes, and shuffling is important for getting data into the right “place”.</p> <h3 id="intrinsics-and-instruction-selection"><a href="#intrinsics-and-instruction-selection">Intrinsics and Instruction Selection</a></h3> <p>Earlier, I mentioned that what you get varies by architecture. This section is basically a giant footnote.</p> <p>So, there’s two big factors that go into this.</p> <ol> <li>We’ve learned over time which operations tend to be most useful to programmers. x86 might have something that ARM doesn’t because it “seemed like a good idea at the time” but turned out to be kinda niche.</li> <li>Instruction set extensions are often market differentiators, even within the same vendor. Intel has AVX-512, which provides even more sophisticated instructions, but it’s only available on high-end server chips, because it makes manufacturing more expensive.</li> </ol> <p>Toolchains generalize different extensions as “target features”. Features can be detected at runtime through architecture-specific magic. On Linux, the <code class="language-plaintext highlighter-rouge">lscpu</code> command will list what features the CPU advertises that it recognizes, which correlate with the names of features that e.g. LLVM understands. What features are enabled for a particular function affects how LLVM compiles it. For example, LLVM will only emit <code class="language-plaintext highlighter-rouge">ymm</code>-using code when compiling with <code class="language-plaintext highlighter-rouge">+avx2</code>.</p> <p>So how do you write portable SIMD code? On the surface, the answer is mostly “you don’t”, but it’s more complicated than that, and for that we need to understand how the later parts of a compiler works.</p> <p>When a user requests an add by writing <code class="language-plaintext highlighter-rouge">a + b</code>, how should I decide which instruction to use for it? This seems like a trick question… <em>just</em> an <code class="language-plaintext highlighter-rouge">add</code> right? On x86, even this isn’t so easy, since you have a choice between the actual <code class="language-plaintext highlighter-rouge">add</code> instruction, or a <code class="language-plaintext highlighter-rouge">lea</code> instruction (which, among other things, preserves the <code class="language-plaintext highlighter-rouge">rflags</code> register). This question becomes more complicated for more sophisticated operations. This general problem is called <em>instruction selection</em>.</p> <p>Because which “target features” are enabled affects which instructions are available, they affect instruction selection. When I went over operations “typically available”, this means that compilers will usually be able to select good choices of instructions for them on most architectures.</p> <p>Compiling with something like <code class="language-plaintext highlighter-rouge">-march=native</code> or <code class="language-plaintext highlighter-rouge">-Ctarget-cpu=native</code> gets you “the best” code possible for the machine you’re building on, but it might not be portable<sup id="fnref:abi" role="doc-noteref"><a href="#fn:abi" class="footnote" rel="footnote">3</a></sup> to different processors. Gentoo was quite famous for building packages from source on user machines to take advantage of this (not to mention that they loved using <code class="language-plaintext highlighter-rouge">-O3</code>, which mostly exists to slow down build times with little benefit).</p> <p>There is also runtime feature detection, where a program decides which version of a function to call at runtime by asking the CPU what it supports. Code deployed on heterogenous devices (like cryptography libraries) often make use of this. Doing this correctly is very hard and something I don’t particularly want to dig deeply into here.</p> <p>The situation is made worse by the fact that in C++, you usually write SIMD code using “intrinsics”, which are special functions with inscrutable names like <code class="language-plaintext highlighter-rouge">_mm256_cvtps_epu32</code> that represent a low-level operation in a specific instruction set (this is a float to int cast from AVX2). Intrinsics are defined by hardware vendors, but don’t necessarily map down to single instructions; the compiler can still optimize these instructions by merging, deduplication, and through instruction selection.</p> <p>As a result you wind up writing the same code multiple times for different instruction sets, with only minor maintainability benefits over writing assembly.</p> <p>The alternative is a portable SIMD library, which does some instruction selection behind the scenes at the library level but tries to rely on the compiler for most of the heavy-duty work. For a long time I was skeptical that this approach would actually produce good, competitive code, which brings us to the actual point of this article: using Rust’s portable SIMD library to implement a somewhat fussy algorithm, and measuring performance.</p> <h2 id="parsing-with-simd"><a href="#parsing-with-simd">Parsing with SIMD</a></h2> <p>Let’s design a SIMD implementation for a well-known algorithm. Although it doesn’t look like it at first, the power of shuffles makes it possible to parse text with SIMD. And this parsing can be very, very fast.</p> <p>In this case, we’re going to implement base64 decoding. To review, base64 is an encoding scheme for arbitrary binary data into ASCII. We interpret a byte slice as a bit vector, and divide it into six-bit chunks called <em>sextets</em>. Then, each sextet from 0 to 63 is mapped to an ASCII character:</p> <ol> <li><code class="language-plaintext highlighter-rouge">0</code> to <code class="language-plaintext highlighter-rouge">25</code> go to <code class="language-plaintext highlighter-rouge">'A'</code> to <code class="language-plaintext highlighter-rouge">'Z'</code>.</li> <li><code class="language-plaintext highlighter-rouge">26</code> to <code class="language-plaintext highlighter-rouge">51</code> go to <code class="language-plaintext highlighter-rouge">'a'</code> to <code class="language-plaintext highlighter-rouge">'z'</code>.</li> <li><code class="language-plaintext highlighter-rouge">52</code> to <code class="language-plaintext highlighter-rouge">61</code> go to <code class="language-plaintext highlighter-rouge">'0'</code> to <code class="language-plaintext highlighter-rouge">'9'</code>.</li> <li><code class="language-plaintext highlighter-rouge">62</code> goes to <code class="language-plaintext highlighter-rouge">+</code>.</li> <li><code class="language-plaintext highlighter-rouge">63</code> goes to <code class="language-plaintext highlighter-rouge">/</code>.</li> </ol> <p>There <em>are</em> other variants of base64, but the bulk of the complexity is the same for each variant.</p> <p>There are a few basic pitfalls to keep in mind.</p> <ol> <li> <p>Base64 is a “big endian” format: specifically, the bits in each byte are big endian. Because a sextet can span only parts of a byte, this distinction is important.</p> </li> <li> <p>We need to beware of cases where the input length is not divisible by 4; ostensibly messages should be padded with <code class="language-plaintext highlighter-rouge">=</code> to a multiple of 4, but it’s easy to just handle messages that aren’t padded correctly.</p> </li> </ol> <p>The length of a decoded message is given by this function:</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">decoded_len</span><span class="p">(</span><span class="n">input</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">usize</span> <span class="p">{</span>
  <span class="n">input</span> <span class="o">/</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">+</span> <span class="k">match</span> <span class="n">input</span> <span class="o">%</span> <span class="mi">4</span> <span class="p">{</span>
    <span class="mi">1</span> <span class="p">|</span> <span class="mi">2</span> <span class="k">=&gt;</span> <span class="mi">1</span><span class="p">,</span>
    <span class="mi">3</span> <span class="k">=&gt;</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">_</span> <span class="k">=&gt;</span> <span class="mi">0</span><span class="p">,</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>Given all this, the easiest way to implement base64 is something like this.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">decode</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="o">&amp;</span><span class="p">[</span><span class="nb">u8</span><span class="p">],</span> <span class="n">out</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">(),</span> <span class="n">Error</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="c1">// Tear off at most two trailing =.</span>
  <span class="k">let</span> <span class="n">data</span> <span class="o">=</span> <span class="k">match</span> <span class="n">data</span> <span class="p">{</span>
    <span class="p">[</span><span class="n">p</span> <span class="o">@</span> <span class="o">..</span><span class="p">,</span> <span class="sc">b'='</span><span class="p">,</span> <span class="sc">b'='</span><span class="p">]</span> <span class="p">|</span> <span class="p">[</span><span class="n">p</span> <span class="o">@</span> <span class="o">..</span><span class="p">,</span> <span class="sc">b'='</span><span class="p">]</span> <span class="p">|</span> <span class="n">p</span> <span class="k">=&gt;</span> <span class="n">p</span><span class="p">,</span>
  <span class="p">};</span>

  <span class="c1">// Split the input into chunks of at most 4 bytes.</span>
  <span class="k">for</span> <span class="n">chunk</span> <span class="k">in</span> <span class="n">data</span><span class="nf">.chunks</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">bytes</span> <span class="o">=</span> <span class="mi">0u32</span><span class="p">;</span>
    <span class="k">for</span> <span class="o">&amp;</span><span class="n">byte</span> <span class="k">in</span> <span class="n">chunk</span> <span class="p">{</span>
      <span class="c1">// Translate each ASCII character into its corresponding</span>
      <span class="c1">// sextet, or return an error.</span>
      <span class="k">let</span> <span class="n">sextet</span> <span class="o">=</span> <span class="k">match</span> <span class="n">byte</span> <span class="p">{</span>
        <span class="sc">b'A'</span><span class="o">..=</span><span class="sc">b'Z'</span> <span class="k">=&gt;</span> <span class="n">byte</span> <span class="o">-</span> <span class="sc">b'A'</span><span class="p">,</span>
        <span class="sc">b'a'</span><span class="o">..=</span><span class="sc">b'z'</span> <span class="k">=&gt;</span> <span class="n">byte</span> <span class="o">-</span> <span class="sc">b'a'</span> <span class="o">+</span> <span class="mi">26</span><span class="p">,</span>
        <span class="sc">b'0'</span><span class="o">..=</span><span class="sc">b'9'</span> <span class="k">=&gt;</span> <span class="n">byte</span> <span class="o">-</span> <span class="sc">b'0'</span> <span class="o">+</span> <span class="mi">52</span><span class="p">,</span>
        <span class="sc">b'+'</span> <span class="k">=&gt;</span> <span class="mi">62</span><span class="p">,</span>
        <span class="sc">b'/'</span> <span class="k">=&gt;</span> <span class="mi">63</span><span class="p">,</span>
        <span class="n">_</span> <span class="k">=&gt;</span> <span class="k">return</span> <span class="nf">Err</span><span class="p">(</span><span class="nf">Error</span><span class="p">(</span><span class="o">...</span><span class="p">)),</span>
      <span class="p">};</span>

      <span class="c1">// Append the sextet to the temporary buffer.</span>
      <span class="n">bytes</span> <span class="o">&lt;&lt;=</span> <span class="mi">6</span><span class="p">;</span>
      <span class="n">bytes</span> <span class="p">|</span><span class="o">=</span> <span class="n">sextet</span> <span class="k">as</span> <span class="nb">u32</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// Shift things so the actual data winds up at the</span>
    <span class="c1">// top of `bytes`.</span>
    <span class="n">bytes</span> <span class="o">&lt;&lt;=</span> <span class="mi">32</span> <span class="o">-</span> <span class="mi">6</span> <span class="o">*</span> <span class="n">chunk</span><span class="nf">.len</span><span class="p">();</span>

    <span class="c1">// Append the decoded data to `out`, keeping in mind that</span>
    <span class="c1">// `bytes` is big-endian encoded.</span>
    <span class="k">let</span> <span class="n">decoded</span> <span class="o">=</span> <span class="nf">decoded_len</span><span class="p">(</span><span class="n">chunk</span><span class="nf">.len</span><span class="p">());</span>
    <span class="n">out</span><span class="nf">.extend_from_slice</span><span class="p">(</span><span class="o">&amp;</span><span class="n">bytes</span><span class="nf">.to_be_bytes</span><span class="p">()[</span><span class="o">..</span><span class="n">decoded</span><span class="p">]);</span>
  <span class="p">}</span>

  <span class="nf">Ok</span><span class="p">(())</span>
<span class="p">}</span>
</code></pre></div></div> <p>So, what’s the process of turning this into a SIMD version? We want to follow one directive with inexorable, robotic dedication.</p> <p><strong>Eliminate all branches.</strong></p> <p>This is not completely feasible, since the input is of variable length. But we can try. There are several branches in this code:</p> <ol> <li>The <code class="language-plaintext highlighter-rouge">for chunk in</code> line. This one is is the length check: it checks if there is any data left to process.</li> <li>The <code class="language-plaintext highlighter-rouge">for &amp;byte in</code> line. This is the hottest loop: it branches once per input byte.</li> <li>The <code class="language-plaintext highlighter-rouge">match byte</code> line is several branches, to determine which of the five “valid” match arms we land in.</li> <li>The <code class="language-plaintext highlighter-rouge">return Err</code> line. Returning in a hot loop is extra control flow, which is not ideal.</li> <li>The call to <code class="language-plaintext highlighter-rouge">decoded_len</code> contains a <code class="language-plaintext highlighter-rouge">match</code>, which generates branches.</li> <li>The call to <code class="language-plaintext highlighter-rouge">Vec::extend_from_slice</code>. This contains not just branches, but potential calls into the allocator. Extremely slow.</li> </ol> <p>(5) is the easiest to deal with. The <code class="language-plaintext highlighter-rouge">match</code> is mapping the values <code class="language-plaintext highlighter-rouge">0, 1, 2, 3</code> to <code class="language-plaintext highlighter-rouge">0, 1, 1, 2</code>. Call this function <code class="language-plaintext highlighter-rouge">f</code>. Then, the sequence given by <code class="language-plaintext highlighter-rouge">x - f(x)</code> is <code class="language-plaintext highlighter-rouge">0, 0, 1, 1</code>. This just happens to equal <code class="language-plaintext highlighter-rouge">x / 2</code> (or <code class="language-plaintext highlighter-rouge">x &gt;&gt; 1</code>), so we can write a completely branchless version of <code class="language-plaintext highlighter-rouge">decoded_len</code> like so.</p> <p>```rust godbolt:o=-O pub fn decoded_len(input: usize) -&gt; usize { let mod4 = input % 4; input / 4 * 3 + (mod4 - mod4 / 2) }</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
That's one branch eliminated[^why-cant-llvm-do-it]. ✅

[^why-cant-llvm-do-it]:
    Why can't we leave this kind of thing to LLVM? Finding this particular
    branchless implementation is tricky. LLVM is smart enough to fold the match
    into a switch table, but that's unnecessary memory traffic to look at the
    table. (In this domain, unnecessary memory traffic makes our code slower.)

    Incidentally, with the code I wrote for the original `decoded_len()`, LLVM
    produces a jump _and_ a lookup table, which is definitely an odd choice? I
    went down something of a rabbit-hole.
    https://github.com/rust-lang/rust/issues/118306

    As for getting LLVM to find the "branchless" version of the lookup table?
    The search space is quite large, and this kind of "general strength
    reduction" problem is fairly open (keywords: "superoptimizers").

The others will not prove so easy. Let's turn our attention to the innermost
loop next, branches (2), (3), and (4).

### The Hottest Loop

The superpower of SIMD is that because you operate on so much data at a time,
you can unroll the loop so hard it becomes branchless.

The insight is this: we want to load at most four bytes, do something to them,
and then spit out at most three decoded bytes. While doing this operation, we
may encounter a syntax error so we need to report that somehow.

Here's some facts we can take advantage of.

1. We don't need to figure out how many bytes are in the "output" of the hot
   loop: our handy branchless `decoded_len()` does that for us.
2. Invalid base64 is extremely rare. We want that syntax error to cost as little
   as possible. If the user still cares about which byte was the problem, they
   can scan the input for it after the fact.
3. `A` is zero in base64. If we're parsing a truncated chunk, padding it with
   `A` won't change the value[^pad-with-A].

[^pad-with-A]:
    To be clear on why this works: suppose that in our reference implementation,
    we only handle inputs that are a multiple-of-4 length, and are padded with
    `=` as necessary, and we treat `=` as zero in the `match`. Then, for the
    purposes of computing the `bytes` value (before appending it to `out`), we
    can assume the chunk length is always 4.

This suggests an interface for the body of the "hottest loop". We can factor it
out as a separate function, and simplify since we can assume our input is always
four bytes now.

```rust
fn decode_hot(ascii: [u8; 4]) -&gt; ([u8; 3], bool) {
  let mut bytes = 0u32;
  let mut ok = true;
  for byte in ascii {
    let sextet = match byte {
      b'A'..=b'Z' =&gt; byte - b'A',
      b'a'..=b'z' =&gt; byte - b'a' + 26,
      b'0'..=b'9' =&gt; byte - b'0' + 52,
      b'+' =&gt; 62,
      b'/' =&gt; 63,
      _ =&gt; !0,
    };

    bytes &lt;&lt;= 6;
    bytes |= sextet as u32;
    ok &amp;= byte == !0;
  }

  // This is the `to_be_bytes()` call.
  let [b1, b2, b3, _] = bytes.to_le_bytes();
  ([b3, b2, b1], ok)
}

// In decode()...
for chunk in data.chunks(4) {
  let mut ascii = [b'A'; 4];
  ascii[..chunk.len()].copy_from_slice(chunk);

  let (bytes, ok) = decode_hot(ascii);
  if !ok {
    return Err(Error)
  }

  let len = decoded_len(chunk.len());
  out.extend_from_slice(&amp;bytes[..decoded]);
}
</code></pre></div></div> <p>You’re probably thinking: why not return <code class="language-plaintext highlighter-rouge">Option&lt;[u8; 3]&gt;</code>? Returning an enum will make it messier to eliminate the <code class="language-plaintext highlighter-rouge">if !ok</code> branch later on (which we will!). We want to write branchless code, so let’s focus on finding a way of producing that three-byte output without needing to do early returns.</p> <p>Now’s when we want to start talking about vectors rather than arrays, so let’s try to rewrite our function as such.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">decode_hot</span><span class="p">(</span><span class="n">ascii</span><span class="p">:</span> <span class="n">Simd</span><span class="o">&lt;</span><span class="nb">u8</span><span class="p">,</span> <span class="mi">4</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="n">Simd</span><span class="o">&lt;</span><span class="nb">u8</span><span class="p">,</span> <span class="mi">4</span><span class="o">&gt;</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="p">{</span>
  <span class="nd">unimplemented!</span><span class="p">()</span>
<span class="p">}</span>
</code></pre></div></div> <p>Note that the output is now four bytes, not three. SIMD lane counts need to be powers of two, and that last element will never get looked at, so we don’t need to worry about what winds up there.</p> <p>The callsite also needs to be tweaked, but only slightly, because <code class="language-plaintext highlighter-rouge">Simd&lt;u8, 4&gt;</code> is <code class="language-plaintext highlighter-rouge">From&lt;[u8; 4]&gt;</code>.</p> <h3 id="ascii-to-sextet"><a href="#ascii-to-sextet">ASCII to Sextet</a></h3> <p>Let’s look at the first part of the <code class="language-plaintext highlighter-rouge">for byte in ascii</code> loop. We need to map each lane of the <code class="language-plaintext highlighter-rouge">Simd&lt;u8, 4&gt;</code> to the corresponding sextet, and somehow signal which ones are invalid. First, notice something special about the <code class="language-plaintext highlighter-rouge">match</code>: almost every arm can be written as <code class="language-plaintext highlighter-rouge">byte - C</code> for some constant <code class="language-plaintext highlighter-rouge">C</code>. The non-range case looks a little silly, but humor me:</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="n">sextet</span> <span class="o">=</span> <span class="k">match</span> <span class="n">byte</span> <span class="p">{</span>
  <span class="sc">b'A'</span><span class="o">..=</span><span class="sc">b'Z'</span> <span class="k">=&gt;</span> <span class="n">byte</span> <span class="o">-</span> <span class="sc">b'A'</span><span class="p">,</span>
  <span class="sc">b'a'</span><span class="o">..=</span><span class="sc">b'z'</span> <span class="k">=&gt;</span> <span class="n">byte</span> <span class="o">-</span> <span class="sc">b'a'</span> <span class="o">+</span> <span class="mi">26</span><span class="p">,</span>
  <span class="sc">b'0'</span><span class="o">..=</span><span class="sc">b'9'</span> <span class="k">=&gt;</span> <span class="n">byte</span> <span class="o">-</span> <span class="sc">b'0'</span> <span class="o">+</span> <span class="mi">52</span><span class="p">,</span>
  <span class="sc">b'+'</span>        <span class="k">=&gt;</span> <span class="n">byte</span> <span class="o">-</span> <span class="sc">b'+'</span> <span class="o">+</span> <span class="mi">62</span><span class="p">,</span>
  <span class="sc">b'/'</span>        <span class="k">=&gt;</span> <span class="n">byte</span> <span class="o">-</span> <span class="sc">b'/'</span> <span class="o">+</span> <span class="mi">63</span><span class="p">,</span>
  <span class="n">_</span> <span class="k">=&gt;</span> <span class="o">!</span><span class="mi">0</span><span class="p">,</span>
<span class="p">};</span>
</code></pre></div></div> <p>So, it should be sufficient to build a vector <code class="language-plaintext highlighter-rouge">offsets</code> that contains the appropriate constant <code class="language-plaintext highlighter-rouge">C</code> for each lane, and then <code class="language-plaintext highlighter-rouge">let sextets = ascii - offsets;</code></p> <p>How can we build <code class="language-plaintext highlighter-rouge">offsets</code>? Using compare-and-select.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// A lane-wise version of `x &gt;= start &amp;&amp; x &lt;= end`.</span>
<span class="k">fn</span> <span class="nf">in_range</span><span class="p">(</span><span class="n">bytes</span><span class="p">:</span> <span class="n">Simd</span><span class="o">&lt;</span><span class="nb">u8</span><span class="p">,</span> <span class="mi">4</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">start</span><span class="p">:</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">end</span><span class="p">:</span> <span class="nb">u8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Mask</span><span class="o">&lt;</span><span class="nb">i8</span><span class="p">,</span> <span class="mi">4</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="n">bytes</span><span class="nf">.simd_ge</span><span class="p">(</span><span class="nn">Simd</span><span class="p">::</span><span class="nf">splat</span><span class="p">(</span><span class="n">start</span><span class="p">))</span> <span class="o">&amp;</span> <span class="n">bytes</span><span class="nf">.simd_le</span><span class="p">(</span><span class="nn">Simd</span><span class="p">::</span><span class="nf">splat</span><span class="p">(</span><span class="n">end</span><span class="p">))</span>
<span class="p">}</span>

<span class="c1">// Create masks for each of the five ranges.</span>
<span class="c1">// Note that these are disjoint: for any two masks, m1 &amp; m2 == 0.</span>
<span class="k">let</span> <span class="n">uppers</span> <span class="o">=</span> <span class="nf">in_range</span><span class="p">(</span><span class="n">ascii</span><span class="p">,</span> <span class="sc">b'A'</span><span class="p">,</span> <span class="sc">b'Z'</span><span class="p">);</span>
<span class="k">let</span> <span class="n">lowers</span> <span class="o">=</span> <span class="nf">in_range</span><span class="p">(</span><span class="n">ascii</span><span class="p">,</span> <span class="sc">b'a'</span><span class="p">,</span> <span class="sc">b'z'</span><span class="p">);</span>
<span class="k">let</span> <span class="n">digits</span> <span class="o">=</span> <span class="nf">in_range</span><span class="p">(</span><span class="n">ascii</span><span class="p">,</span> <span class="sc">b'0'</span><span class="p">,</span> <span class="sc">b'9'</span><span class="p">);</span>
<span class="k">let</span> <span class="n">pluses</span> <span class="o">=</span> <span class="n">ascii</span><span class="nf">.simd_eq</span><span class="p">([</span><span class="sc">b'+'</span><span class="p">;</span> <span class="n">N</span><span class="p">]</span><span class="nf">.into</span><span class="p">());</span>
<span class="k">let</span> <span class="n">solidi</span> <span class="o">=</span> <span class="n">ascii</span><span class="nf">.simd_eq</span><span class="p">([</span><span class="sc">b'/'</span><span class="p">;</span> <span class="n">N</span><span class="p">]</span><span class="nf">.into</span><span class="p">());</span>

<span class="c1">// If any byte was invalid, none of the masks will select for it,</span>
<span class="c1">// so that lane will be 0 in the or of all the masks. This is our</span>
<span class="c1">// validation check.</span>
<span class="k">let</span> <span class="n">ok</span> <span class="o">=</span> <span class="p">(</span><span class="n">uppers</span> <span class="p">|</span> <span class="n">lowers</span> <span class="p">|</span> <span class="n">digits</span> <span class="p">|</span> <span class="n">pluses</span> <span class="p">|</span> <span class="n">solidi</span><span class="p">)</span><span class="nf">.all</span><span class="p">();</span>

<span class="c1">// Given a mask, create a new vector by splatting `value`</span>
<span class="c1">// over the set lanes.</span>
<span class="k">fn</span> <span class="nf">masked_splat</span><span class="p">(</span><span class="n">mask</span><span class="p">:</span> <span class="n">Mask</span><span class="o">&lt;</span><span class="nb">i8</span><span class="p">,</span> <span class="n">N</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">i8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Simd</span><span class="o">&lt;</span><span class="nb">i8</span><span class="p">,</span> <span class="mi">4</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="n">mask</span><span class="nf">.select</span><span class="p">(</span><span class="nn">Simd</span><span class="p">::</span><span class="nf">splat</span><span class="p">(</span><span class="n">val</span><span class="p">),</span> <span class="nn">Simd</span><span class="p">::</span><span class="nf">splat</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="p">}</span>

<span class="c1">// Fill the the lanes of the offset vector by filling the</span>
<span class="c1">// set lanes with the corresponding offset. This is like</span>
<span class="c1">// a "vectorized" version of the `match`.</span>
<span class="k">let</span> <span class="n">offsets</span> <span class="o">=</span> <span class="nf">masked_splat</span><span class="p">(</span><span class="n">uppers</span><span class="p">,</span>  <span class="mi">65</span><span class="p">)</span>
            <span class="p">|</span> <span class="nf">masked_splat</span><span class="p">(</span><span class="n">lowers</span><span class="p">,</span>  <span class="mi">71</span><span class="p">)</span>
            <span class="p">|</span> <span class="nf">masked_splat</span><span class="p">(</span><span class="n">digits</span><span class="p">,</span>  <span class="o">-</span><span class="mi">4</span><span class="p">)</span>
            <span class="p">|</span> <span class="nf">masked_splat</span><span class="p">(</span><span class="n">pluses</span><span class="p">,</span> <span class="o">-</span><span class="mi">19</span><span class="p">)</span>
            <span class="p">|</span> <span class="nf">masked_splat</span><span class="p">(</span><span class="n">solidi</span><span class="p">,</span> <span class="o">-</span><span class="mi">16</span><span class="p">);</span>

<span class="c1">// Finally, Build the sextets vector.</span>
<span class="k">let</span> <span class="n">sextets</span> <span class="o">=</span> <span class="n">ascii</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">i8</span><span class="o">&gt;</span><span class="p">()</span> <span class="o">-</span> <span class="n">offsets</span><span class="p">;</span>
</code></pre></div></div> <p>This solution is quite elegant, and will produce very competitive code, but it’s not actually ideal. We need to do a lot of comparisons here: eight in total. We also keep lots of values alive at the same time, which might lead to unwanted register pressure.</p> <h3 id="simd-hash-table"><a href="#simd-hash-table">SIMD Hash Table</a></h3> <p>Let’s look at the byte representations of the ranges. <code class="language-plaintext highlighter-rouge">A-Z</code>, <code class="language-plaintext highlighter-rouge">a-z</code>, and <code class="language-plaintext highlighter-rouge">0-9</code> are, as byte ranges, <code class="language-plaintext highlighter-rouge">0x41..0x5b</code>, <code class="language-plaintext highlighter-rouge">0x61..0x7b</code>, and <code class="language-plaintext highlighter-rouge">0x30..0x3a</code>. Notice they all have different high nybbles! What’s more, <code class="language-plaintext highlighter-rouge">+</code> and <code class="language-plaintext highlighter-rouge">/</code> are <code class="language-plaintext highlighter-rouge">0x2b</code> and <code class="language-plaintext highlighter-rouge">0x2f</code>, so the function <code class="language-plaintext highlighter-rouge">byte &gt;&gt; 4</code> is <em>almost</em> enough to distinguish all the ranges. If we subtract one if <code class="language-plaintext highlighter-rouge">byte == b'/'</code>, we have a <em>perfect hash</em> for the ranges.</p> <p>In other words, the value <code class="language-plaintext highlighter-rouge">(byte &gt;&gt; 4) - (byte == '/')</code> maps the ranges as follows:</p> <ul> <li><code class="language-plaintext highlighter-rouge">A-Z</code> goes to 4 or 5.</li> <li><code class="language-plaintext highlighter-rouge">a-z</code> goes to 6 or 7.</li> <li><code class="language-plaintext highlighter-rouge">0-9</code> goes to 3.</li> <li><code class="language-plaintext highlighter-rouge">+</code> goes to 2.</li> <li><code class="language-plaintext highlighter-rouge">/</code> goes to 1.</li> </ul> <p>This is small enough that we could cram a lookup table of values for building the <code class="language-plaintext highlighter-rouge">offsets</code> vector into another SIMD vector, and use a shuffle operation to do the lookup.</p> <p>This is not my original idea; I came across a <a href="https://github.com/WojciechMula/base64simd/issues/3">GitHub issue</a> where an anonymous user points out this perfect hash.</p> <p>Our new ascii-to-sextet code looks like this:</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Compute the perfect hash for each lane.</span>
<span class="k">let</span> <span class="n">hashes</span> <span class="o">=</span> <span class="p">(</span><span class="n">ascii</span> <span class="o">&gt;&gt;</span> <span class="nn">Simd</span><span class="p">::</span><span class="nf">splat</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
  <span class="o">+</span> <span class="nn">Simd</span><span class="p">::</span><span class="nf">simd_eq</span><span class="p">(</span><span class="n">ascii</span><span class="p">,</span> <span class="nn">Simd</span><span class="p">::</span><span class="nf">splat</span><span class="p">(</span><span class="sc">b'/'</span><span class="p">))</span>
    <span class="nf">.to_int</span><span class="p">()</span>  <span class="c1">// to_int() is equivalent to masked_splat(-1, 0).</span>
    <span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">();</span>

<span class="c1">// Look up offsets based on each hash and subtract them from `ascii`.</span>
<span class="k">let</span> <span class="n">sextets</span> <span class="o">=</span> <span class="n">ascii</span>
    <span class="c1">// This lookup table corresponds to the offsets we used to build the</span>
    <span class="c1">// `offsets` vector in the previous implementation, placed in the</span>
    <span class="c1">// indices that the perfect hash produces.</span>
  <span class="o">-</span> <span class="nn">Simd</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">i8</span><span class="p">,</span> <span class="mi">8</span><span class="o">&gt;</span><span class="p">::</span><span class="nf">from</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">65</span><span class="p">,</span> <span class="o">-</span><span class="mi">65</span><span class="p">,</span> <span class="o">-</span><span class="mi">71</span><span class="p">,</span> <span class="o">-</span><span class="mi">71</span><span class="p">])</span>
    <span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">()</span>
    <span class="nf">.swizzle_dyn</span><span class="p">(</span><span class="n">hashes</span><span class="p">);</span>
</code></pre></div></div> <p>There is a small wrinkle here: <a href="https://doc.rust-lang.org/std/simd/struct.Simd.html#method.swizzle_dyn"><code class="language-plaintext highlighter-rouge">Simd::swizzle_dyn()</code></a> requires that the index array be the same length as the lookup table. This is annoying because right now <code class="language-plaintext highlighter-rouge">ascii</code> is a <code class="language-plaintext highlighter-rouge">Simd&lt;u8, 4&gt;</code>, but that will not be the case later on, so I will simply sweep this under the rug.</p> <p>Note that we no longer get validation as a side-effect of computing the sextets vector. The same GitHub issue also provides an exact bloom-filter for checking that a particular byte is valid; you can see my implementation <a href="https://github.com/mcy/vb64/blob/894f833e933860e070dabcfcc189430c45fecbd7/src/simd.rs#L93">here</a>. I’m not sure how the OP constructed the bloom filter, but the search space is small enough that you could have written a little script to brute force it.</p> <h3 id="riffling-the-sextets"><a href="#riffling-the-sextets">Riffling the Sextets</a></h3> <p>Now comes a much tricker operation: we need to somehow pack all four sextets into three bytes. One way to try to wrap our head around what the packing code in <code class="language-plaintext highlighter-rouge">decode_hot()</code> is doing is to pass in the all-ones sextet in one of the four bytes, and see where those ones end up in the return value.</p> <p>This is not unlike how they use radioactive dyes in biology to track the moment of molecules or cells through an organism.</p> <p>```rust godbolt:e,m fn bits(value: u32) -&gt; String { let [b1, b2, b3, b4] = value.reverse_bits().to_le_bytes(); format!(“{b1:08b} {b2:08b} {b3:08b} {b4:08b}”) }</p> <p>fn decode_pack(input: [u8; 4]) { let mut output = 0u32; for byte in input { output «= 6; output |= byte as u32; } output «= 8;</p> <p>println!(“{}\n{}\n”, bits(u32::from_be_bytes(input)), bits(output)); }</p> <p>decode_pack([0b111111, 0, 0, 0]); decode_pack([0, 0b111111, 0, 0]); decode_pack([0, 0, 0b111111, 0]); decode_pack([0, 0, 0, 0b111111]);</p> <p>// Output: // 11111100 00000000 00000000 00000000 // 00111111 00000000 00000000 00000000 // // 00000000 11111100 00000000 00000000 // 11000000 00001111 00000000 00000000 // // 00000000 00000000 11111100 00000000 // 00000000 11110000 00000011 00000000 // // 00000000 00000000 00000000 11111100 // 00000000 00000000 11111100 00000000</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Bingo. Playing around with the inputs lets us verify which pieces of the bytes
wind up where. For example, by passing `0b110000` as `input[1]`, we see that the
two high bits of `input[1]` correspond to the low bits of `output[0]`. I've
written the code so that the bits in each byte are printed in little-endian
order, so bits on the left are the low bits.

Putting this all together, we can draw a schematic of what this operation does
to a general `Simd&lt;u8, 4&gt;`.

![the riffling operation](https://mcyoung.xyz/public/images/simd-b64/riffle.png)

Now, there's no single instruction that will do this for us. Shuffles can be
used to move bytes around, but we're dealing with _pieces_ of bytes here. We
also can't really do a shift, since we need bits that are overshifted to move
into adjacent lanes.

The trick is to just make the lanes bigger.

Among the operations available for SIMD vectors are lane-wise casts, which allow
us to zero-extend, sign-extend, or truncate each lane. So what we can do is cast
`sextets` to a vector of `u16`, do the shift there and then... somehow put the
parts back together?

Let's see how far shifting gets us. How much do we need to shift things by?
First, notice that the order of the bits within each chunk that doesn't cross a
byte boundary doesn't change. For example, the four low bits of `input[1]` are
in the same order when they become the high bits of `output[1]`, and the two
high bits of `input[1]` are also in the same order when they become the low bits
of `output[0]`.

This means we can determine how far to shift by comparing the bit position of
the lowest bit of a byte of `input` with the bit position of the corresponding
bit in `output`.

`input[0]`'s low bit is the third bit of `output[0]`, so we need to shift
`input[0]` by 2. `input[1]`'s lowest bit is the fifth bit of `output[1]`, so we
need to shift by 4. Analogously, the shifts for `input[2]` and `input[3]` turn
out to be 6 and 0. In code:

```rust
let sextets = ...;
let shifted = sextets.cast::&lt;u16&gt;() &lt;&lt; Simd::from([2, 4, 6, 0]);
</code></pre></div></div> <p>So now we have a <code class="language-plaintext highlighter-rouge">Simd&lt;u16, 4&gt;</code> that contains the individual chunks that we need to move around, in the high and low bytes of each <code class="language-plaintext highlighter-rouge">u16</code>, which we can think of as being analogous to a <code class="language-plaintext highlighter-rouge">[[u8; 2]; 4]</code>. For example, <code class="language-plaintext highlighter-rouge">shifted[0][0]</code> contains <code class="language-plaintext highlighter-rouge">sextet[0]</code>, but shifted. This corresponds to the red segment in the first schematic. The smaller blue segment is given by <code class="language-plaintext highlighter-rouge">shifted[1][1]</code>, i.e., the high byte of the second <code class="language-plaintext highlighter-rouge">u16</code>. It’s already in the right place within that byte, so we want <code class="language-plaintext highlighter-rouge">output[0] = shifted[0][0] | shifted[1][1]</code>.</p> <p>This suggests a more general strategy: we want to take two vectors, the low bytes and the high bytes of each <code class="language-plaintext highlighter-rouge">u16</code> in <code class="language-plaintext highlighter-rouge">shifted</code>, respectively, and somehow shuffle them so that when or’ed together, they give the desired output.</p> <p>Look at the schematic again: if we had a vector consisting of <code class="language-plaintext highlighter-rouge">[..aaaaaa, ....bbbb, ......cc]</code>, we could or it with a vector like <code class="language-plaintext highlighter-rouge">[bb......, cccc...., dddddd..]</code> to get the desired result.</p> <p>One problem: <code class="language-plaintext highlighter-rouge">dddddd..</code> is <code class="language-plaintext highlighter-rouge">shifted[3][0]</code>, i.e., it’s a low byte. If we change the vector we shift by to <code class="language-plaintext highlighter-rouge">[2, 4, 6, 8]</code>, though, it winds up in <code class="language-plaintext highlighter-rouge">shifted[3][1]</code>, since it’s been shifted up by <code class="language-plaintext highlighter-rouge">8</code> bits: a full byte.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Split shifted into low byte and high byte vectors.</span>
<span class="c1">// Same way you'd split a single u16 into bytes, but lane-wise.</span>
<span class="k">let</span> <span class="n">lo</span> <span class="o">=</span> <span class="n">shifted</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">();</span>
<span class="k">let</span> <span class="n">hi</span> <span class="o">=</span> <span class="p">(</span><span class="n">shifted</span> <span class="o">&gt;&gt;</span> <span class="nn">Simd</span><span class="p">::</span><span class="nf">from</span><span class="p">([</span><span class="mi">8</span><span class="p">;</span> <span class="mi">4</span><span class="p">]))</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">();</span>

<span class="c1">// Align the lanes: we want to get shifted[0][0] | shifted[1][1],</span>
<span class="c1">// shifted[1][0] | shifted[2][1], etc.</span>
<span class="k">let</span> <span class="n">output</span> <span class="o">=</span> <span class="n">lo</span> <span class="p">|</span> <span class="n">hi</span><span class="py">.rotate_lanes_left</span><span class="p">::</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">();</span>
</code></pre></div></div> <p>Et voila, here is our new, totally branchless implementation of <code class="language-plaintext highlighter-rouge">decode_hot()</code>.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="nf">decode_hot</span><span class="p">(</span><span class="n">ascii</span><span class="p">:</span> <span class="n">Simd</span><span class="o">&lt;</span><span class="nb">u8</span><span class="p">,</span> <span class="mi">4</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="n">Simd</span><span class="o">&lt;</span><span class="nb">u8</span><span class="p">,</span> <span class="mi">4</span><span class="o">&gt;</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">let</span> <span class="n">hashes</span> <span class="o">=</span> <span class="p">(</span><span class="n">ascii</span> <span class="o">&gt;&gt;</span> <span class="nn">Simd</span><span class="p">::</span><span class="nf">splat</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
    <span class="o">+</span> <span class="nn">Simd</span><span class="p">::</span><span class="nf">simd_eq</span><span class="p">(</span><span class="n">ascii</span><span class="p">,</span> <span class="nn">Simd</span><span class="p">::</span><span class="nf">splat</span><span class="p">(</span><span class="sc">b'/'</span><span class="p">))</span>
      <span class="nf">.to_int</span><span class="p">()</span>
      <span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">();</span>

  <span class="k">let</span> <span class="n">sextets</span> <span class="o">=</span> <span class="n">ascii</span>
    <span class="o">-</span> <span class="nn">Simd</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">i8</span><span class="p">,</span> <span class="mi">8</span><span class="o">&gt;</span><span class="p">::</span><span class="nf">from</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">65</span><span class="p">,</span> <span class="o">-</span><span class="mi">65</span><span class="p">,</span> <span class="o">-</span><span class="mi">71</span><span class="p">,</span> <span class="o">-</span><span class="mi">71</span><span class="p">])</span>
      <span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">()</span>
      <span class="nf">.swizzle_dyn</span><span class="p">(</span><span class="n">hashes</span><span class="p">);</span>  <span class="c1">// Note quite right yet, see next section.</span>

  <span class="k">let</span> <span class="n">ok</span> <span class="o">=</span> <span class="cm">/* bloom filter shenanigans */</span><span class="p">;</span>

  <span class="k">let</span> <span class="n">shifted</span> <span class="o">=</span> <span class="n">sextets</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u16</span><span class="o">&gt;</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="nn">Simd</span><span class="p">::</span><span class="nf">from</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]);</span>
  <span class="k">let</span> <span class="n">lo</span> <span class="o">=</span> <span class="n">shifted</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">();</span>
  <span class="k">let</span> <span class="n">hi</span> <span class="o">=</span> <span class="p">(</span><span class="n">shifted</span> <span class="o">&gt;&gt;</span> <span class="nn">Simd</span><span class="p">::</span><span class="nf">splat</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">();</span>
  <span class="k">let</span> <span class="n">output</span> <span class="o">=</span> <span class="n">lo</span> <span class="p">|</span> <span class="n">hi</span><span class="py">.rotate_lanes_left</span><span class="p">::</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">();</span>

  <span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">ok</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div> <p>The compactness of this solution should not be understated. The simplicity of this solution is a large part of what makes it so efficient, because it aggressively leverages the primitives the hardware offers us.</p> <h3 id="scaling-up"><a href="#scaling-up">Scaling Up</a></h3> <p>Ok, so now we have to contend with a new aspect of our implementation that’s crap: a <code class="language-plaintext highlighter-rouge">Simd&lt;u8, 4&gt;</code> is tiny. That’s not even 128 bits, which are the smallest vector registers on x86. What we need to do is make <code class="language-plaintext highlighter-rouge">decode_hot()</code> generic on the lane count. This will allow us to tune the number of lanes to batch together depending on benchmarks later on.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">decode_hot</span><span class="o">&lt;</span><span class="k">const</span> <span class="n">N</span><span class="p">:</span> <span class="nb">usize</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ascii</span><span class="p">:</span> <span class="n">Simd</span><span class="o">&lt;</span><span class="nb">u8</span><span class="p">,</span> <span class="n">N</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="n">Simd</span><span class="o">&lt;</span><span class="nb">u8</span><span class="p">,</span> <span class="n">N</span><span class="o">&gt;</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span>
<span class="k">where</span>
  <span class="c1">// This makes sure N is a small power of 2.</span>
  <span class="n">LaneCount</span><span class="o">&lt;</span><span class="n">N</span><span class="o">&gt;</span><span class="p">:</span> <span class="n">SupportedLaneCount</span><span class="p">,</span>
<span class="p">{</span>
  <span class="k">let</span> <span class="n">hashes</span> <span class="o">=</span> <span class="p">(</span><span class="n">ascii</span> <span class="o">&gt;&gt;</span> <span class="nn">Simd</span><span class="p">::</span><span class="nf">splat</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
    <span class="o">+</span> <span class="nn">Simd</span><span class="p">::</span><span class="nf">simd_eq</span><span class="p">(</span><span class="n">ascii</span><span class="p">,</span> <span class="nn">Simd</span><span class="p">::</span><span class="nf">splat</span><span class="p">(</span><span class="sc">b'/'</span><span class="p">))</span>
      <span class="nf">.to_int</span><span class="p">()</span>
      <span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">();</span>

  <span class="k">let</span> <span class="n">sextets</span> <span class="o">=</span> <span class="n">ascii</span>
    <span class="o">-</span> <span class="nf">tiled</span><span class="p">(</span><span class="o">&amp;</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">65</span><span class="p">,</span> <span class="o">-</span><span class="mi">65</span><span class="p">,</span> <span class="o">-</span><span class="mi">71</span><span class="p">,</span> <span class="o">-</span><span class="mi">71</span><span class="p">])</span>
      <span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">()</span>
      <span class="nf">.swizzle_dyn</span><span class="p">(</span><span class="n">hashes</span><span class="p">);</span>  <span class="c1">// Works fine now, as long as N &gt;= 8.</span>

  <span class="k">let</span> <span class="n">ok</span> <span class="o">=</span> <span class="cm">/* bloom filter shenanigans */</span><span class="p">;</span>

  <span class="k">let</span> <span class="n">shifted</span> <span class="o">=</span> <span class="n">sextets</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u16</span><span class="o">&gt;</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="nf">tiled</span><span class="p">(</span><span class="o">&amp;</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]);</span>
  <span class="k">let</span> <span class="n">lo</span> <span class="o">=</span> <span class="n">shifted</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">();</span>
  <span class="k">let</span> <span class="n">hi</span> <span class="o">=</span> <span class="p">(</span><span class="n">shifted</span> <span class="o">&gt;&gt;</span> <span class="nn">Simd</span><span class="p">::</span><span class="nf">splat</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">();</span>
  <span class="k">let</span> <span class="n">output</span> <span class="o">=</span> <span class="n">lo</span> <span class="p">|</span> <span class="n">hi</span><span class="py">.rotate_lanes_left</span><span class="p">::</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">();</span>

  <span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">ok</span><span class="p">)</span>
<span class="p">}</span>

<span class="cd">/// Generates a new vector made up of repeated "tiles" of identical</span>
<span class="cd">/// data.</span>
<span class="k">const</span> <span class="k">fn</span> <span class="n">tiled</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="k">const</span> <span class="n">N</span><span class="p">:</span> <span class="nb">usize</span><span class="o">&gt;</span><span class="p">(</span><span class="n">tile</span><span class="p">:</span> <span class="o">&amp;</span><span class="p">[</span><span class="n">T</span><span class="p">])</span> <span class="k">-&gt;</span> <span class="n">Simd</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">N</span><span class="o">&gt;</span>
<span class="k">where</span>
  <span class="n">T</span><span class="p">:</span> <span class="n">SimdElement</span><span class="p">,</span>
  <span class="n">LaneCount</span><span class="o">&lt;</span><span class="n">N</span><span class="o">&gt;</span><span class="p">:</span> <span class="n">SupportedLaneCount</span><span class="p">,</span>
<span class="p">{</span>
  <span class="k">let</span> <span class="k">mut</span> <span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="n">tile</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span> <span class="n">N</span><span class="p">];</span>
  <span class="k">let</span> <span class="k">mut</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span> <span class="p">{</span>
    <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tile</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="n">tile</span><span class="nf">.len</span><span class="p">()];</span>
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="nn">Simd</span><span class="p">::</span><span class="nf">from_array</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div> <p>We have to change virtually nothing, which is pretty awesome! But unfortunately, this code is subtly incorrect. Remember how in the <code class="language-plaintext highlighter-rouge">N = 4</code> case, the result of <code class="language-plaintext highlighter-rouge">output</code> had a garbage value that we ignore in its highest lane? Well, now that garbage data is interleaved into output: every fourth lane contains garbage.</p> <p>We can use a shuffle to delete these lanes, thankfully. Specifically, we want <code class="language-plaintext highlighter-rouge">shuffled[i] = output[i + i / 3]</code>, which skips every forth index. So, <code class="language-plaintext highlighter-rouge">shuffled[3] = output[4]</code>, skipping over the garbage value in <code class="language-plaintext highlighter-rouge">output[3]</code>. If <code class="language-plaintext highlighter-rouge">i + i / 3</code> overflows <code class="language-plaintext highlighter-rouge">N</code>, that’s ok, because that’s the high quarter of the final output vector, which is ignored anyways. In code:</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">decode_hot</span><span class="o">&lt;</span><span class="k">const</span> <span class="n">N</span><span class="p">:</span> <span class="nb">usize</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ascii</span><span class="p">:</span> <span class="n">Simd</span><span class="o">&lt;</span><span class="nb">u8</span><span class="p">,</span> <span class="n">N</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="p">(</span><span class="n">Simd</span><span class="o">&lt;</span><span class="nb">u8</span><span class="p">,</span> <span class="n">N</span><span class="o">&gt;</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span>
<span class="k">where</span>
  <span class="c1">// This makes sure N is a small power of 2.</span>
  <span class="n">LaneCount</span><span class="o">&lt;</span><span class="n">N</span><span class="o">&gt;</span><span class="p">:</span> <span class="n">SupportedLaneCount</span><span class="p">,</span>
<span class="p">{</span>
  <span class="cm">/* snip */</span>

  <span class="k">let</span> <span class="n">decoded_chunks</span> <span class="o">=</span> <span class="n">lo</span> <span class="p">|</span> <span class="n">hi</span><span class="py">.rotate_lanes_left</span><span class="p">::</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">();</span>
  <span class="k">let</span> <span class="n">output</span> <span class="o">=</span> <span class="nd">swizzle!</span><span class="p">(</span><span class="n">N</span><span class="p">;</span> <span class="n">decoded_chunks</span><span class="p">,</span> <span class="nd">array!</span><span class="p">(</span><span class="n">N</span><span class="p">;</span> <span class="p">|</span><span class="n">i</span><span class="p">|</span> <span class="n">i</span> <span class="o">+</span> <span class="n">i</span> <span class="o">/</span> <span class="mi">3</span><span class="p">));</span>

  <span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">ok</span><span class="p">)</span>
<span class="p">}</span>
</code></pre></div></div> <blockquote> <p><code class="language-plaintext highlighter-rouge">swizzle!()</code> is a helper macro<sup id="fnref:macros" role="doc-noteref"><a href="#fn:macros" class="footnote" rel="footnote">4</a></sup> for generating generic implementations of <code class="language-plaintext highlighter-rouge">std::simd::Swizzle</code>, and <code class="language-plaintext highlighter-rouge">array!()</code> is something I wrote for generating generic-length array constants; the closure is called once for each <code class="language-plaintext highlighter-rouge">i in 0..N</code>.</p> </blockquote> <p>So now we can decode 32 base64 bytes in parallel by calling <code class="language-plaintext highlighter-rouge">decode_hot::&lt;32&gt;()</code>. We’ll try to keep things generic from here, so we can tune the lane parameter based on benchmarks.</p> <h3 id="the-outer-loop"><a href="#the-outer-loop">The Outer Loop</a></h3> <p>Let’s look at <code class="language-plaintext highlighter-rouge">decode()</code> again. Let’s start by making it generic on the internal lane count, too.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">decode</span><span class="o">&lt;</span><span class="k">const</span> <span class="n">N</span><span class="p">:</span> <span class="nb">usize</span><span class="o">&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="o">&amp;</span><span class="p">[</span><span class="nb">u8</span><span class="p">],</span> <span class="n">out</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">(),</span> <span class="n">Error</span><span class="o">&gt;</span>
<span class="k">where</span>
  <span class="n">LaneCount</span><span class="o">&lt;</span><span class="n">N</span><span class="o">&gt;</span><span class="p">:</span> <span class="n">SupportedLaneCount</span><span class="p">,</span>
<span class="p">{</span>
  <span class="k">let</span> <span class="n">data</span> <span class="o">=</span> <span class="k">match</span> <span class="n">data</span> <span class="p">{</span>
    <span class="p">[</span><span class="n">p</span> <span class="o">@</span> <span class="o">..</span><span class="p">,</span> <span class="sc">b'='</span><span class="p">,</span> <span class="sc">b'='</span><span class="p">]</span> <span class="p">|</span> <span class="p">[</span><span class="n">p</span> <span class="o">@</span> <span class="o">..</span><span class="p">,</span> <span class="sc">b'='</span><span class="p">]</span> <span class="p">|</span> <span class="n">p</span> <span class="k">=&gt;</span> <span class="n">p</span><span class="p">,</span>
  <span class="p">};</span>

  <span class="k">for</span> <span class="n">chunk</span> <span class="k">in</span> <span class="n">data</span><span class="nf">.chunks</span><span class="p">(</span><span class="n">N</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// N-sized chunks now.</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">ascii</span> <span class="o">=</span> <span class="p">[</span><span class="sc">b'A'</span><span class="p">;</span> <span class="n">N</span><span class="p">];</span>
    <span class="n">ascii</span><span class="p">[</span><span class="o">..</span><span class="n">chunk</span><span class="nf">.len</span><span class="p">()]</span><span class="nf">.copy_from_slice</span><span class="p">(</span><span class="n">chunk</span><span class="p">);</span>

    <span class="k">let</span> <span class="p">(</span><span class="n">dec</span><span class="p">,</span> <span class="n">ok</span><span class="p">)</span> <span class="o">=</span> <span class="nn">decode_hot</span><span class="p">::</span><span class="o">&lt;</span><span class="n">N</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ascii</span><span class="nf">.into</span><span class="p">());</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">ok</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">return</span> <span class="nf">Err</span><span class="p">(</span><span class="n">Error</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="k">let</span> <span class="n">decoded</span> <span class="o">=</span> <span class="nf">decoded_len</span><span class="p">(</span><span class="n">chunk</span><span class="nf">.len</span><span class="p">());</span>
    <span class="n">out</span><span class="nf">.extend_from_slice</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dec</span><span class="p">[</span><span class="o">..</span><span class="n">decoded</span><span class="p">]);</span>
  <span class="p">}</span>

  <span class="nf">Ok</span><span class="p">(())</span>
<span class="p">}</span>
</code></pre></div></div> <p>What branches are left? There’s still the branch from <code class="language-plaintext highlighter-rouge">for chunks in ...</code>. It’s not ideal because it can’t do an exact pointer comparison, and needs to do a <code class="language-plaintext highlighter-rouge">&gt;=</code> comparison on a length instead.</p> <p>We call <code class="language-plaintext highlighter-rouge">[T]::copy_from_slice</code>, which is super slow because it needs to make a variable-length <code class="language-plaintext highlighter-rouge">memcpy</code> call, which can’t be inlined. Function calls are branches! The bounds checks are also a problem.</p> <p>We branch on <code class="language-plaintext highlighter-rouge">ok</code> every loop iteration, still. Not returning early in <code class="language-plaintext highlighter-rouge">decode_hot</code> doesn’t win us anything (yet).</p> <p>We potentially call the allocator in <code class="language-plaintext highlighter-rouge">extend_from_slice</code>, and perform another non-inline-able <code class="language-plaintext highlighter-rouge">memcpy</code> call.</p> <h3 id="preallocating-with-slop"><a href="#preallocating-with-slop">Preallocating with Slop</a></h3> <p>The last of these is the easiest to address: we can reserve space in <code class="language-plaintext highlighter-rouge">out</code>, since we know exactly how much data we need to write thanks to <code class="language-plaintext highlighter-rouge">decoded_len</code>. Better yet, we can reserve some “slop”: i.e., scratch space past where the end of the message would be, so we can perform full SIMD stores, instead of the variable-length memcpy.</p> <p>This way, in each iteration, we write the full SIMD vector, including any garbage bytes in the upper quarter. Then, the next write is offset <code class="language-plaintext highlighter-rouge">3/4 * N</code> bytes over, so it overwrites the garbage bytes with decoded message bytes. The garbage bytes from the final right get “deleted” by not being included in the final <code class="language-plaintext highlighter-rouge">Vec::set_len()</code> that “commits” the memory we wrote to.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">decode</span><span class="o">&lt;</span><span class="k">const</span> <span class="n">N</span><span class="p">:</span> <span class="nb">usize</span><span class="o">&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="o">&amp;</span><span class="p">[</span><span class="nb">u8</span><span class="p">],</span> <span class="n">out</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">(),</span> <span class="n">Error</span><span class="o">&gt;</span>
<span class="k">where</span> <span class="n">LaneCount</span><span class="o">&lt;</span><span class="n">N</span><span class="o">&gt;</span><span class="p">:</span> <span class="n">SupportedLaneCount</span><span class="p">,</span>
<span class="p">{</span>
  <span class="k">let</span> <span class="n">data</span> <span class="o">=</span> <span class="k">match</span> <span class="n">data</span> <span class="p">{</span>
    <span class="p">[</span><span class="n">p</span> <span class="o">@</span> <span class="o">..</span><span class="p">,</span> <span class="sc">b'='</span><span class="p">,</span> <span class="sc">b'='</span><span class="p">]</span> <span class="p">|</span> <span class="p">[</span><span class="n">p</span> <span class="o">@</span> <span class="o">..</span><span class="p">,</span> <span class="sc">b'='</span><span class="p">]</span> <span class="p">|</span> <span class="n">p</span> <span class="k">=&gt;</span> <span class="n">p</span><span class="p">,</span>
  <span class="p">};</span>

  <span class="k">let</span> <span class="n">final_len</span> <span class="o">=</span> <span class="nf">decoded_len</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
  <span class="n">out</span><span class="nf">.reserve</span><span class="p">(</span><span class="n">final_len</span> <span class="o">+</span> <span class="n">N</span> <span class="o">/</span> <span class="mi">4</span><span class="p">);</span>  <span class="c1">// Reserve with slop.</span>

  <span class="c1">// Get a raw pointer to where we should start writing.</span>
  <span class="k">let</span> <span class="k">mut</span> <span class="n">ptr</span> <span class="o">=</span> <span class="n">out</span><span class="nf">.as_mut_ptr_range</span><span class="p">()</span><span class="nf">.end</span><span class="p">();</span>
  <span class="k">let</span> <span class="n">start</span> <span class="o">=</span> <span class="n">ptr</span><span class="p">;</span>

  <span class="k">for</span> <span class="n">chunk</span> <span class="k">in</span> <span class="n">data</span><span class="nf">.chunks</span><span class="p">(</span><span class="n">N</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// N-sized chunks now.</span>
    <span class="cm">/* snip */</span>

    <span class="k">let</span> <span class="n">decoded</span> <span class="o">=</span> <span class="nf">decoded_len</span><span class="p">(</span><span class="n">chunk</span><span class="nf">.len</span><span class="p">());</span>
    <span class="k">unsafe</span> <span class="p">{</span>
      <span class="c1">// Do a raw write and advance the pointer.</span>
      <span class="n">ptr</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="n">Simd</span><span class="o">&lt;</span><span class="nb">u8</span><span class="p">,</span> <span class="n">N</span><span class="o">&gt;&gt;</span><span class="p">()</span><span class="nf">.write_unaligned</span><span class="p">(</span><span class="n">dec</span><span class="p">);</span>
      <span class="n">ptr</span> <span class="o">=</span> <span class="n">ptr</span><span class="nf">.add</span><span class="p">(</span><span class="n">decoded</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="k">unsafe</span> <span class="p">{</span>
    <span class="c1">// Update the vector's final length.</span>
    <span class="c1">// This is the final "commit".</span>
    <span class="k">let</span> <span class="n">len</span> <span class="o">=</span> <span class="n">ptr</span><span class="nf">.offset_from</span><span class="p">(</span><span class="n">start</span><span class="p">);</span>
    <span class="n">out</span><span class="nf">.set_len</span><span class="p">(</span><span class="n">len</span> <span class="k">as</span> <span class="nb">usize</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="nf">Ok</span><span class="p">(())</span>
<span class="p">}</span>
</code></pre></div></div> <p>This is safe, because we’ve pre-allocated exactly the amount of memory we need, and where <code class="language-plaintext highlighter-rouge">ptr</code> lands is equal to the amount of memory actually decoded. We could also compute the final length of <code class="language-plaintext highlighter-rouge">out</code> ahead of time.</p> <p>Note that if we early return due to <code class="language-plaintext highlighter-rouge">if !ok</code>, <code class="language-plaintext highlighter-rouge">out</code> remains unmodified, because even though we did write to its buffer, we never execute the “commit” part, so the code remains correct.</p> <h3 id="delaying-failure"><a href="#delaying-failure">Delaying Failure</a></h3> <p>Next up, we can eliminate the <code class="language-plaintext highlighter-rouge">if !ok</code> branches by waiting to return an error until as late as possible: just before the <code class="language-plaintext highlighter-rouge">set_len</code> call.</p> <p>Remember our observation from before: most base64 encoded blobs are valid, so this unhappy path should be very rare. Also, syntax errors cannot cause code that follows to misbehave arbitrarily, so letting it go wild doesn’t hurt anything.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">decode</span><span class="o">&lt;</span><span class="k">const</span> <span class="n">N</span><span class="p">:</span> <span class="nb">usize</span><span class="o">&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="o">&amp;</span><span class="p">[</span><span class="nb">u8</span><span class="p">],</span> <span class="n">out</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">(),</span> <span class="n">Error</span><span class="o">&gt;</span>
<span class="k">where</span> <span class="n">LaneCount</span><span class="o">&lt;</span><span class="n">N</span><span class="o">&gt;</span><span class="p">:</span> <span class="n">SupportedLaneCount</span><span class="p">,</span>
<span class="p">{</span>
  <span class="cm">/* snip */</span>
  <span class="k">let</span> <span class="k">mut</span> <span class="n">error</span> <span class="o">=</span> <span class="k">false</span><span class="p">;</span>
  <span class="k">for</span> <span class="n">chunk</span> <span class="k">in</span> <span class="n">data</span><span class="nf">.chunks</span><span class="p">(</span><span class="n">N</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">ascii</span> <span class="o">=</span> <span class="p">[</span><span class="sc">b'A'</span><span class="p">;</span> <span class="n">N</span><span class="p">];</span>
    <span class="n">ascii</span><span class="p">[</span><span class="o">..</span><span class="n">chunk</span><span class="nf">.len</span><span class="p">()]</span><span class="nf">.copy_from_slice</span><span class="p">(</span><span class="n">chunk</span><span class="p">);</span>

    <span class="k">let</span> <span class="p">(</span><span class="n">dec</span><span class="p">,</span> <span class="n">ok</span><span class="p">)</span> <span class="o">=</span> <span class="nn">decode_hot</span><span class="p">::</span><span class="o">&lt;</span><span class="n">N</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ascii</span><span class="nf">.into</span><span class="p">());</span>
    <span class="n">error</span> <span class="p">|</span><span class="o">=</span> <span class="o">!</span><span class="n">ok</span><span class="p">;</span>

    <span class="cm">/* snip */</span>
  <span class="p">}</span>

  <span class="k">if</span> <span class="n">error</span> <span class="p">{</span>
    <span class="k">return</span> <span class="nf">Err</span><span class="p">(</span><span class="n">Error</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="k">unsafe</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">len</span> <span class="o">=</span> <span class="n">ptr</span><span class="nf">.offset_from</span><span class="p">(</span><span class="n">start</span><span class="p">);</span>
    <span class="n">out</span><span class="nf">.set_len</span><span class="p">(</span><span class="n">len</span> <span class="k">as</span> <span class="nb">usize</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="nf">Ok</span><span class="p">(())</span>
<span class="p">}</span>
</code></pre></div></div> <p>The branch is still “there”, sure, but it’s out of the hot loop.</p> <p>Because we never hit the <code class="language-plaintext highlighter-rouge">set_len</code> call and commit whatever garbage we wrote, said garbage essentially disappears when we return early, to be overwritten by future calls to <code class="language-plaintext highlighter-rouge">Vec::push()</code>.</p> <h3 id="unroll-it-harder"><a href="#unroll-it-harder">Unroll It Harder</a></h3> <p>Ok, let’s look at the memcpy from <code class="language-plaintext highlighter-rouge">copy_from_slice</code> at the start of the hot loop. The loop has already been partly unrolled: it does <code class="language-plaintext highlighter-rouge">N</code> iterations with SIMD each step, doing something funny on the last step to make up for the missing data (padding with <code class="language-plaintext highlighter-rouge">A</code>).</p> <p>We can take this a step further by doing an “unroll and jam” optimization. This type of unrolling splits the loop into two parts: a hot vectorized loop and a cold remainder part. The hot loop <em>always</em> handles length <code class="language-plaintext highlighter-rouge">N</code> input, and the remainder runs at most once and handles <code class="language-plaintext highlighter-rouge">i &lt; N</code> input.</p> <p>Rust provides an iterator adapter for hand-rolled (lol) unroll-and-jam: <code class="language-plaintext highlighter-rouge">Iterator::chunks_exact()</code>.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">fn</span> <span class="n">decode</span><span class="o">&lt;</span><span class="k">const</span> <span class="n">N</span><span class="p">:</span> <span class="nb">usize</span><span class="o">&gt;</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="o">&amp;</span><span class="p">[</span><span class="nb">u8</span><span class="p">],</span> <span class="n">out</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="nb">Vec</span><span class="o">&lt;</span><span class="nb">u8</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">(),</span> <span class="n">Error</span><span class="o">&gt;</span>
<span class="k">where</span> <span class="n">LaneCount</span><span class="o">&lt;</span><span class="n">N</span><span class="o">&gt;</span><span class="p">:</span> <span class="n">SupportedLaneCount</span><span class="p">,</span>
<span class="p">{</span>
  <span class="cm">/* snip */</span>
  <span class="k">let</span> <span class="k">mut</span> <span class="n">error</span> <span class="o">=</span> <span class="k">false</span><span class="p">;</span>
  <span class="k">let</span> <span class="k">mut</span> <span class="n">chunks</span> <span class="o">=</span> <span class="n">data</span><span class="nf">.chunks_exact</span><span class="p">(</span><span class="n">N</span><span class="p">);</span>
  <span class="k">for</span> <span class="n">chunk</span> <span class="k">in</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">chunks</span> <span class="p">{</span>
    <span class="c1">// Simd::from_slice() can do a load in one instruction.</span>
    <span class="c1">// The bounds check is easy for the compiler to elide.</span>
    <span class="k">let</span> <span class="p">(</span><span class="n">dec</span><span class="p">,</span> <span class="n">ok</span><span class="p">)</span> <span class="o">=</span> <span class="nn">decode_hot</span><span class="p">::</span><span class="o">&lt;</span><span class="n">N</span><span class="o">&gt;</span><span class="p">(</span><span class="nn">Simd</span><span class="p">::</span><span class="nf">from_slice</span><span class="p">(</span><span class="n">chunk</span><span class="p">));</span>
    <span class="n">error</span> <span class="p">|</span><span class="o">=</span> <span class="o">!</span><span class="n">ok</span><span class="p">;</span>
    <span class="cm">/* snip */</span>
  <span class="p">}</span>

  <span class="k">let</span> <span class="n">rest</span> <span class="o">=</span> <span class="n">chunks</span><span class="nf">.remainder</span><span class="p">();</span>
  <span class="k">if</span> <span class="o">!</span><span class="n">rest</span><span class="nf">.empty</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">ascii</span> <span class="o">=</span> <span class="p">[</span><span class="sc">b'A'</span><span class="p">;</span> <span class="n">N</span><span class="p">];</span>
    <span class="n">ascii</span><span class="p">[</span><span class="o">..</span><span class="n">chunk</span><span class="nf">.len</span><span class="p">()]</span><span class="nf">.copy_from_slice</span><span class="p">(</span><span class="n">chunk</span><span class="p">);</span>

    <span class="k">let</span> <span class="p">(</span><span class="n">dec</span><span class="p">,</span> <span class="n">ok</span><span class="p">)</span> <span class="o">=</span> <span class="nn">decode_hot</span><span class="p">::</span><span class="o">&lt;</span><span class="n">N</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ascii</span><span class="nf">.into</span><span class="p">());</span>
    <span class="cm">/* snip */</span>
  <span class="p">}</span>

  <span class="cm">/* snip */</span>
<span class="p">}</span>
</code></pre></div></div> <p>Splitting into two parts lets us call <code class="language-plaintext highlighter-rouge">Simd::from_slice()</code>, which performs a single, vector-sized load.</p> <h2 id="so-how-fast-is-it"><a href="#so-how-fast-is-it">So, How Fast Is It?</a></h2> <p>At this point, it looks like we’ve addressed every branch that we can, so some benchmarks are in order. I wrote a benchmark that decodes messages of every length from 0 to something like 200 or 500 bytes, and compared it against the baseline base64 implementation on crates.io.</p> <p>I compiled with <code class="language-plaintext highlighter-rouge">-Zbuild-std</code> and <code class="language-plaintext highlighter-rouge">-Ctarget-cpu=native</code> to try to get the best results. Based on some tuning, <code class="language-plaintext highlighter-rouge">N = 32</code> was the best length, since it used one YMM register for each iteration of the hot loop.</p> <p><img src="https://mcyoung.xyz/public/images/simd-b64/graph-old.png" alt="a performance graph; our code is really good compared to the baseline, but variance is high"/></p> <p>So, we have the baseline beat. But what’s up with that crazy heartbeat waveform? You can tell it has something to do with the “remainder” part of the loop, since it correlates strongly with <code class="language-plaintext highlighter-rouge">data.len() % 32</code>.</p> <p>I stared at the assembly for a while. I don’t remember what was there, but I think that <code class="language-plaintext highlighter-rouge">copy_from_slice</code> had been inlined and unrolled into a loop that loaded each byte at a time. The moral equivalent of this:</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="k">mut</span> <span class="n">ascii</span> <span class="o">=</span> <span class="p">[</span><span class="sc">b'A'</span><span class="p">;</span> <span class="n">N</span><span class="p">];</span>
<span class="k">for</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="k">in</span> <span class="nn">Iterator</span><span class="p">::</span><span class="nf">zip</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">ascii</span><span class="p">,</span> <span class="n">chunk</span><span class="p">)</span> <span class="p">{</span>
  <span class="o">*</span><span class="n">a</span> <span class="o">=</span> <span class="o">*</span><span class="n">b</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>I decided to try <code class="language-plaintext highlighter-rouge">Simd::gather_or()</code>, which is kind of like a “vectorized load”. It wound up producing worse assembly, so I gave up on using a gather and instead wrote a carefully optimized loading function by hand.</p> <h3 id="unroll-and-jam-revisited"><a href="#unroll-and-jam-revisited">Unroll and Jam, Revisited</a></h3> <p>The idea here is to perform the largest scalar loads Rust offers where possible. The strategy is again unroll and jam: perform <code class="language-plaintext highlighter-rouge">u128</code> loads in a loop and deal with the remainder separately.</p> <p>The hot part looks like this:</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="k">mut</span> <span class="n">buf</span> <span class="o">=</span> <span class="p">[</span><span class="sc">b'A'</span><span class="p">;</span> <span class="n">N</span><span class="p">];</span>

<span class="c1">// Load a bunch of big 16-byte chunks. LLVM will lower these to XMM loads.</span>
<span class="k">let</span> <span class="n">ascii_ptr</span> <span class="o">=</span> <span class="n">buf</span><span class="nf">.as_mut_ptr</span><span class="p">();</span>
<span class="k">let</span> <span class="k">mut</span> <span class="n">write_at</span> <span class="o">=</span> <span class="n">ascii_ptr</span><span class="p">;</span>
<span class="k">if</span> <span class="n">slice</span><span class="nf">.len</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">16</span> <span class="p">{</span>
  <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="n">slice</span><span class="nf">.len</span><span class="p">()</span> <span class="o">/</span> <span class="mi">16</span> <span class="p">{</span>
    <span class="k">unsafe</span> <span class="p">{</span>
      <span class="n">write_at</span> <span class="o">=</span> <span class="n">write_at</span><span class="nf">.add</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="mi">16</span><span class="p">);</span>

      <span class="k">let</span> <span class="n">word</span> <span class="o">=</span> <span class="n">slice</span><span class="nf">.as_ptr</span><span class="p">()</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u128</span><span class="o">&gt;</span><span class="p">()</span><span class="nf">.add</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="nf">.read_unaligned</span><span class="p">();</span>
      <span class="n">write_at</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u128</span><span class="o">&gt;</span><span class="p">()</span><span class="nf">.write_unaligned</span><span class="p">(</span><span class="n">word</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>The cold part seems hard to optimize at first. What’s the least number of unaligned loads you need to do to load 15 bytes from memory? It’s two! You can load a <code class="language-plaintext highlighter-rouge">u64</code> from <code class="language-plaintext highlighter-rouge">p</code>, and then another one from <code class="language-plaintext highlighter-rouge">p + 7</code>; these loads (call them <code class="language-plaintext highlighter-rouge">a</code> and <code class="language-plaintext highlighter-rouge">b</code>) overlap by one byte, but we can or them together to merge that byte, so our loaded value is <code class="language-plaintext highlighter-rouge">a as u128 | (b as u128 &lt;&lt; 56)</code>.</p> <p>A similar trick works if the data to load is between a <code class="language-plaintext highlighter-rouge">u32</code> and a <code class="language-plaintext highlighter-rouge">u64</code>. Finally, to load 1, 2, or 3 bytes, we can load <code class="language-plaintext highlighter-rouge">p</code>, <code class="language-plaintext highlighter-rouge">p + len/2</code> and <code class="language-plaintext highlighter-rouge">p + len-1</code>; depending on whether <code class="language-plaintext highlighter-rouge">len</code> is 1, 2, or 3, this will potentially load the same byte multiple times; however, this reduces the number of branches necessary, since we don’t need to distinguish the 1, 2, or 3 lines.</p> <p>This is the kind of code that’s probably easier to read than to explain.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">unsafe</span> <span class="p">{</span>
  <span class="k">let</span> <span class="n">ptr</span> <span class="o">=</span> <span class="n">slice</span><span class="nf">.as_ptr</span><span class="p">()</span><span class="nf">.offset</span><span class="p">(</span><span class="n">write_at</span><span class="nf">.offset_from</span><span class="p">(</span><span class="n">ascii_ptr</span><span class="p">));</span>
  <span class="k">let</span> <span class="n">len</span> <span class="o">=</span> <span class="n">slice</span><span class="nf">.len</span><span class="p">()</span> <span class="o">%</span> <span class="mi">16</span><span class="p">;</span>

  <span class="k">if</span> <span class="n">len</span> <span class="o">&gt;=</span> <span class="mi">8</span> <span class="p">{</span>
    <span class="c1">// Load two overlapping u64s.</span>
    <span class="k">let</span> <span class="n">lo</span> <span class="o">=</span> <span class="n">ptr</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u64</span><span class="o">&gt;</span><span class="p">()</span><span class="nf">.read_unaligned</span><span class="p">()</span> <span class="k">as</span> <span class="nb">u128</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">hi</span> <span class="o">=</span> <span class="n">ptr</span><span class="nf">.add</span><span class="p">(</span><span class="n">len</span> <span class="o">-</span> <span class="mi">8</span><span class="p">)</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u64</span><span class="o">&gt;</span><span class="p">()</span><span class="nf">.read_unaligned</span><span class="p">()</span> <span class="k">as</span> <span class="nb">u128</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">data</span> <span class="o">=</span> <span class="n">lo</span> <span class="p">|</span> <span class="p">(</span><span class="n">hi</span> <span class="o">&lt;&lt;</span> <span class="p">((</span><span class="n">len</span> <span class="o">-</span> <span class="mi">8</span><span class="p">)</span> <span class="o">*</span> <span class="mi">8</span><span class="p">));</span>

    <span class="k">let</span> <span class="n">z</span> <span class="o">=</span> <span class="nn">u128</span><span class="p">::</span><span class="nf">from_ne_bytes</span><span class="p">([</span><span class="sc">b'A'</span><span class="p">;</span> <span class="mi">16</span><span class="p">])</span> <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="n">len</span> <span class="o">*</span> <span class="mi">8</span><span class="p">);</span>
    <span class="n">write_at</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u128</span><span class="o">&gt;</span><span class="p">()</span><span class="nf">.write_unaligned</span><span class="p">(</span><span class="n">data</span> <span class="p">|</span> <span class="n">z</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="n">len</span> <span class="o">&gt;=</span> <span class="mi">4</span> <span class="p">{</span>
    <span class="c1">// Load two overlapping u32s.</span>
    <span class="k">let</span> <span class="n">lo</span> <span class="o">=</span> <span class="n">ptr</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u32</span><span class="o">&gt;</span><span class="p">()</span><span class="nf">.read_unaligned</span><span class="p">()</span> <span class="k">as</span> <span class="nb">u64</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">hi</span> <span class="o">=</span> <span class="n">ptr</span><span class="nf">.add</span><span class="p">(</span><span class="n">len</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u32</span><span class="o">&gt;</span><span class="p">()</span><span class="nf">.read_unaligned</span><span class="p">()</span> <span class="k">as</span> <span class="nb">u64</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">data</span> <span class="o">=</span> <span class="n">lo</span> <span class="p">|</span> <span class="p">(</span><span class="n">hi</span> <span class="o">&lt;&lt;</span> <span class="p">((</span><span class="n">len</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="mi">8</span><span class="p">));</span>

    <span class="k">let</span> <span class="n">z</span> <span class="o">=</span> <span class="nn">u64</span><span class="p">::</span><span class="nf">from_ne_bytes</span><span class="p">([</span><span class="sc">b'A'</span><span class="p">;</span> <span class="mi">8</span><span class="p">])</span> <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="n">len</span> <span class="o">*</span> <span class="mi">8</span><span class="p">);</span>
    <span class="n">write_at</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u64</span><span class="o">&gt;</span><span class="p">()</span><span class="nf">.write_unaligned</span><span class="p">(</span><span class="n">data</span> <span class="p">|</span> <span class="n">z</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="c1">// Load 3 overlapping u8s.</span>

    <span class="c1">// For len       1       2       3     ...</span>
    <span class="c1">// ... this is  ptr[0]  ptr[0]  ptr[0]</span>
    <span class="k">let</span> <span class="n">lo</span> <span class="o">=</span> <span class="n">ptr</span><span class="nf">.read</span><span class="p">()</span> <span class="k">as</span> <span class="nb">u32</span><span class="p">;</span>
    <span class="c1">// ... this is  ptr[0]  ptr[1]  ptr[1]</span>
    <span class="k">let</span> <span class="n">mid</span> <span class="o">=</span> <span class="n">ptr</span><span class="nf">.add</span><span class="p">(</span><span class="n">len</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span><span class="nf">.read</span><span class="p">()</span> <span class="k">as</span> <span class="nb">u32</span><span class="p">;</span>
    <span class="c1">// ... this is  ptr[0]  ptr[1]  ptr[2]</span>
    <span class="k">let</span> <span class="n">hi</span> <span class="o">=</span> <span class="n">ptr</span><span class="nf">.add</span><span class="p">(</span><span class="n">len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="nf">.read</span><span class="p">()</span> <span class="k">as</span> <span class="nb">u32</span><span class="p">;</span>

    <span class="k">let</span> <span class="n">data</span> <span class="o">=</span> <span class="n">lo</span> <span class="p">|</span> <span class="p">(</span><span class="n">mid</span> <span class="o">&lt;&lt;</span> <span class="p">((</span><span class="n">len</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">8</span><span class="p">))</span> <span class="p">|</span> <span class="n">hi</span> <span class="o">&lt;&lt;</span> <span class="p">((</span><span class="n">len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">8</span><span class="p">);</span>

    <span class="k">let</span> <span class="n">z</span> <span class="o">=</span> <span class="nn">u32</span><span class="p">::</span><span class="nf">from_ne_bytes</span><span class="p">([</span><span class="sc">b'A'</span><span class="p">;</span> <span class="mi">4</span><span class="p">])</span> <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="n">len</span> <span class="o">*</span> <span class="mi">8</span><span class="p">);</span>
    <span class="n">write_at</span><span class="py">.cast</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">u32</span><span class="o">&gt;</span><span class="p">()</span><span class="nf">.write_unaligned</span><span class="p">(</span><span class="n">data</span> <span class="p">|</span> <span class="n">z</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>I learned this type of loading code while contributing to Abseil: it’s very useful for loading variable-length data for data-hungry algorithms, like a codec or a hash function.</p> <p>Here’s the same benchmark again, but with our new loading code.</p> <p><img src="https://mcyoung.xyz/public/images/simd-b64/graph.png" alt="a performance graph; our code is even better and the variance is very tight"/></p> <p>The results are really, really good. The variance is super tight, and our performance is 2x that of the baseline pretty much everywhere. <em>Success.</em></p> <h3 id="encoding-web-safe"><a href="#encoding-web-safe">Encoding? Web-Safe?</a></h3> <p>Writing an encoding function is simple enough: first, implement an <code class="language-plaintext highlighter-rouge">encode_hot()</code> function that reverses the operations from <code class="language-plaintext highlighter-rouge">decode_hot()</code>. The perfect hash from before won’t work, so you’ll need to <a href="https://github.com/mcy/vb64/blob/main/src/simd.rs#L170">invent a new one</a>.</p> <p>Also, the loading/storing code around the encoder is slightly different, too. <code class="language-plaintext highlighter-rouge">vb64</code> implements a very efficient encoding routine too, so I suggest taking a look at the source code if you’re interested.</p> <p>There is a base64 variant called web-safe base64, that replaces the <code class="language-plaintext highlighter-rouge">+</code> and <code class="language-plaintext highlighter-rouge">/</code> characters with <code class="language-plaintext highlighter-rouge">-</code> and <code class="language-plaintext highlighter-rouge">_</code>. Building a perfect hash for these is trickier: you would probably have to do something like <code class="language-plaintext highlighter-rouge">(byte &gt;&gt; 4) - (byte == '_' ? '_' : 0)</code>. I don’t support web-safe base64 yet, but only because I haven’t gotten around to it.</p> <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2> <p>My library doesn’t really solve an important problem; base64 decoding isn’t a bottleneck… anywhere that I know of, really. But writing SIMD code is really fun! Writing branchless code is often overkill but can give you a good appreciation for what your compilers can and <em>can’t</em> do for you.</p> <p>This project was also an excuse to try <code class="language-plaintext highlighter-rouge">std::simd</code>. I think it’s great overall, and generates excellent code. There’s some rough edges I’d like to see fixed to make SIMD code even simpler, but overall I’m very happy with the work that’s been done there.</p> <p>This is probably one of the most complicated posts I’ve written in a long time. SIMD (and performance in general) is a complex topic that requires a breadth of knowledge of tricks and hardware, a lot of which isn’t written down. More of it is written down now, though.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:shifts-are-arithmetic" role="doc-endnote"> <p>Shifts are better understood as arithmetic. They have a lane width, and closely approximate multiplication and division. AVX2 doesn’t even have vector shift <em>or</em> vector division: you emulate it with multiplication. <a href="#fnref:shifts-are-arithmetic" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:minus-true" role="doc-endnote"> <p>The two common representations of <code class="language-plaintext highlighter-rouge">true</code> and <code class="language-plaintext highlighter-rouge">false</code>, i.e. <code class="language-plaintext highlighter-rouge">1</code> and <code class="language-plaintext highlighter-rouge">0</code> or <code class="language-plaintext highlighter-rouge">0xff...</code> and <code class="language-plaintext highlighter-rouge">0</code>, are related by the two’s complement operation.</p> <p>For example, if I write <code class="language-plaintext highlighter-rouge">uint32_t m = -(a == b);</code>, <code class="language-plaintext highlighter-rouge">m</code> will be zero if <code class="language-plaintext highlighter-rouge">a == b</code> is false, and all-ones otherwise. This because applying any arithmetic operation to a <code class="language-plaintext highlighter-rouge">bool</code> promotes it to <code class="language-plaintext highlighter-rouge">int</code>, so <code class="language-plaintext highlighter-rouge">false</code> maps to <code class="language-plaintext highlighter-rouge">0</code> and <code class="language-plaintext highlighter-rouge">true</code> maps to <code class="language-plaintext highlighter-rouge">1</code>. Applying the <code class="language-plaintext highlighter-rouge">-</code> sends <code class="language-plaintext highlighter-rouge">0</code> to <code class="language-plaintext highlighter-rouge">0</code> and <code class="language-plaintext highlighter-rouge">1</code> to <code class="language-plaintext highlighter-rouge">-1</code>, and it’s useful to know that in two’s complement, <code class="language-plaintext highlighter-rouge">-1</code> is represented as all-ones.</p> <p>The all-ones representation for <code class="language-plaintext highlighter-rouge">true</code> is useful, because it can be used to implement branchless select very easily. For example,</p> <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">select_if_eq</span><span class="p">(</span><span class="kt">int</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="n">x</span><span class="p">,</span> <span class="kt">int</span> <span class="n">y</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">mask</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">a</span> <span class="o">==</span> <span class="n">b</span><span class="p">);</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">mask</span> <span class="o">&amp;</span> <span class="n">x</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="o">~</span><span class="n">mask</span> <span class="o">&amp;</span> <span class="n">y</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div> </div> <p>This function returns <code class="language-plaintext highlighter-rouge">x</code> if <code class="language-plaintext highlighter-rouge">a == b</code>, and <code class="language-plaintext highlighter-rouge">y</code> otherwise. Can you tell why? <a href="#fnref:minus-true" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:abi" role="doc-endnote"> <p>Target features also affect ABI in subtle ways that I could write many, many more words on. Compiling libraries you plan to distribute with weird target feature flags is a recipe for disaster. <a href="#fnref:abi" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:macros" role="doc-endnote"> <p>See <a href="https://github.com/mcy/vb64/blob/ed75566393a25d174a2766c3f8947d9c6a506315/src/util.rs"><code class="language-plaintext highlighter-rouge">vb64/src/util.rs</code></a>. <a href="#fnref:macros" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div> </div> </div> <div class="post-preview"> <div class="post-title"> <span class="post-meta"> 2023-09-29 • 2009 words • 11 minutes <br class="show-if-mobile"/> <span class="hide-if-mobile">•</span> <a href="https://mcyoung.xyz/tags.html#math">#math</a> </span> <h1><a href="/2023/09/29/what-is-a-matrix/"> What is a Matrix? A Miserable Pile of Coefficients! </a></h1> </div> <div class="post"> <p>Linear algebra is undoubtedly the most useful field in all of algebra. It finds applications in all kinds of science and engineering, like quantum mechanics, graphics programming, and machine learning. It is the “most well-behaved” algebraic theory, in that other abstract algebra topics often try to approximate linear algebra, when possible.</p> <p>For many students, linear algebra means vectors and matrices and determinants, and complex formulas for computing them. Matrices, in particular, come equipped with a fairly complicated, and <em>a fortiori</em> convoluted, multiplication operation.</p> <p>This is not the only way to teach linear algebra, of course. Matrices and their multiplication appear complicated, but actually are a natural and compact way to represent a particular type of <em>function</em>, i.e., a linear map (or linear transformation).</p> <p>This article is a short introduction to viewing linear algebra from the perspective of abstract algebra, from which matrices arise as a computational tool, rather than an object of study in and of themselves. I do assume some degree of familiarity with the idea of a matrix.</p> <h2 id="linear-spaces"><a href="#linear-spaces">Linear Spaces</a></h2> <p>Most linear algebra courses open with a description of vectors in Euclidean space: <code class="language-plaintext highlighter-rouge">$\R^n$</code>. Vectors there are defined as tuples of real numbers that can be added, multiplied, and scaled. Two vectors can be combined into a number through the dot product. Vectors come equipped with a notion of magnitude and direction.</p> <p>However, this highly geometric picture can be counterproductive, since it is hard to apply geometric intuition directly to higher dimensions. It also obscures how this connects to working over a different number system, like the complex numbers.</p> <p>Instead, I’d like to open with the concept of a <em>linear space</em>, which is somewhat more abstract than a vector space<sup id="fnref:vs-in-generality" role="doc-noteref"><a href="#fn:vs-in-generality" class="footnote" rel="footnote">1</a></sup>.</p> <p>First, we will need a notion of a “coefficient”, which is essentially something that you can do arithmetic with. We will draw coefficients from a designated <em>ground field</em> <code class="language-plaintext highlighter-rouge">$K$</code>. A field is a setting for doing arithmetic: a set of objects that can be added, subtracted, and multiplied, and divided in the “usual fashion” along with special <code class="language-plaintext highlighter-rouge">$0$</code> and <code class="language-plaintext highlighter-rouge">$1$</code> values. E.g. <code class="language-plaintext highlighter-rouge">$a + 0 = a$</code>, <code class="language-plaintext highlighter-rouge">$1a = a$</code>, <code class="language-plaintext highlighter-rouge">$a(b + c) = ab + ac$</code>, and so on.</p> <p>Not only are the real numbers <code class="language-plaintext highlighter-rouge">$\R$</code> a field, but so are the complex numbers <code class="language-plaintext highlighter-rouge">$\C$</code>, and the rational numbers <code class="language-plaintext highlighter-rouge">$\Q$</code>. If we drop the “division” requirement, we can also include the integers <code class="language-plaintext highlighter-rouge">$\Z$</code>, or polynomials with rational coefficients <code class="language-plaintext highlighter-rouge">$\Q[x]$</code>, for example.</p> <p>Having chosen our coefficients <code class="language-plaintext highlighter-rouge">$K$</code>, a linear space <code class="language-plaintext highlighter-rouge">$V$</code> <em>over</em> <code class="language-plaintext highlighter-rouge">$K$</code> is another set of objects that can be added and subtracted (and including a special value <code class="language-plaintext highlighter-rouge">$0$</code>)<sup id="fnref:ab-group" role="doc-noteref"><a href="#fn:ab-group" class="footnote" rel="footnote">2</a></sup>, along with a <em>scaling operation</em>, which takes a coefficient <code class="language-plaintext highlighter-rouge">$c \in K$</code> and one of our objects <code class="language-plaintext highlighter-rouge">$v \in V$</code> and produces a new <code class="language-plaintext highlighter-rouge">$cv \in V$</code>.</p> <p>The important part of the scaling operation is that it’s compatible with addition: if we have <code class="language-plaintext highlighter-rouge">$a, b \in K$</code> and <code class="language-plaintext highlighter-rouge">$v, w \in V$</code>, we require that</p> <p>```latex render:gather* a (v + w) = av + aw <br/> (a + b) v = av + bv</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
This is what makes a linear space "linear": you can write equations that look
like first-degree polynomials (e.g. `$ax + b$`), and which can be _manipulated
like first-degree polynomials_.

These polynomials are called linear because their graph looks like a line.
There's no multiplication, so we can't have `$x^2$`, but we do have
multiplication by a coefficient. This is what makes linear algebra is "linear".

Some examples: `$n$`-tuples of elements drawn from any field are a linear space
over that field, by componentwise addition and scalar multiplication; e.g.,
`$R^3$`. Setting `$n = 1$` shows that every field is a linear space over itself.

Polynomials in one variable over some field, `$K[x]$`, are also a linear space,
since polynomials can be added together and scaled by a any value in `$K$`
(since lone coefficients are degree zero polynomials). Real-valued functions
also form a linear space over `$\R$` in a similar way.

### Linear Transformations

A linear map is a function `$f: V \to W$` between two linear spaces `$V$` and
`$W$` over `$K$` which "respects" the linear structure in a particular way. That
is, for any `$c\in K$` and `$v, w \in V$`,

```latex render:gather*
f(v + w) = f(v) + f(w) \\
f(cv) = c \cdot f(v)
</code></pre></div></div> <p>We call this type of relationship (respecting addition and scaling) “linearity”. One way to think of this relationship is that <code class="language-plaintext highlighter-rouge">$f$</code> is kind of like a different kind of coefficient, in that it distributes over addition, which commutes with the “ordinary” coefficients from <code class="language-plaintext highlighter-rouge">$K$</code>. However, applying <code class="language-plaintext highlighter-rouge">$f$</code> produces a value from <code class="language-plaintext highlighter-rouge">$W$</code> rather than <code class="language-plaintext highlighter-rouge">$V$</code>.</p> <p>Another way to think of it is that if we have a linear polynomial like <code class="language-plaintext highlighter-rouge">$p(x) = ax + b$</code> in <code class="language-plaintext highlighter-rouge">$x$</code>, then <code class="language-plaintext highlighter-rouge">$f(p(x)) = p(f(x))$</code>. We say that <code class="language-plaintext highlighter-rouge">$f$</code> <em>commutes</em> with all linear polynomials.</p> <p>The most obvious sort of linear map is scaling. Given any coefficient <code class="language-plaintext highlighter-rouge">$c \in K$</code>, it defines a “scaling map”:</p> <p>```latex render:gather* \mu_c: V \to V <br/> v \mapsto cv</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
It's trivial to check this is a linear map, by plugging it into the above
equations: it's linear because scaling is distributive and commutative.

Linear maps are the essential thing we study in linear algebra, since they
describe all the different kinds of relationships between linear spaces.

Some linear maps are complicated. For example, a function from `$\R^2 \to \R^2$`
that rotates the plane by some angle `$\theta$` is linear, as are operations
that stretch or shear the plane. However, they can't "bend" or "fold" the plane:
they are all fairly rigid motions. In the linear space `$\Q[x]$` of rational
polynomials, multiplication by _any_ polynomial, such as `$x$` or `$x^2 - 1$`,
is a linear map. The notion of "linear map" depends heavily on the space we're
in.

Unfortunately, linear maps as they are quite opaque, and do not lend themselves
well to calculation. However, we can build an explicit representation using a
_linear basis_.

## Linear Basis

For any linear space, we can construct a relatively small of elements such that
any element of the space can be expressed as some linear function of these
elements.

Explicitly, for any `$V$`, we can construct a sequence[^indices] `$e_i$` such
that for any `$v \in V$`, we can find `$c_i \in K$` such that

[^indices]:
    Throughout `$i$`, `$j$`, and `$k$` are indices in some unspecified but
    ordered indexing set, usually `$\{1, 2, ..., n\}$`. I will not bother giving
    this index set a name.

```latex render:
v = \sum_i c_i e_i.
</code></pre></div></div> <p>Such a set <code class="language-plaintext highlighter-rouge">$e_i$</code> is called a <em>basis</em> if it is linearly independent: no one <code class="language-plaintext highlighter-rouge">$e_i$</code> can be expressed as a linear function of the rest. The <em>dimension</em> of <code class="language-plaintext highlighter-rouge">$V$</code>, denoted <code class="language-plaintext highlighter-rouge">$\dim V$</code>, is the number of elements in any choice of basis. This value does not depend on the choice of basis<sup id="fnref:invariant-dim" role="doc-noteref"><a href="#fn:invariant-dim" class="footnote" rel="footnote">3</a></sup>.</p> <p>Constructing a basis for any <code class="language-plaintext highlighter-rouge">$V$</code> is easy: we can do this recursively. First, pick a random element <code class="language-plaintext highlighter-rouge">$e_1$</code> of <code class="language-plaintext highlighter-rouge">$V$</code>, and define a new linear space <code class="language-plaintext highlighter-rouge">$V/e_1$</code> where we have identified all elements that differ by a factor of <code class="language-plaintext highlighter-rouge">$e_1$</code> as equal (i.e., if <code class="language-plaintext highlighter-rouge">$v - w = ce_1$</code>, we treat <code class="language-plaintext highlighter-rouge">$v$</code> and <code class="language-plaintext highlighter-rouge">$w$</code> as equal in <code class="language-plaintext highlighter-rouge">$V/e_1$</code>).</p> <p>Then, a basis for <code class="language-plaintext highlighter-rouge">$V$</code> is a basis of <code class="language-plaintext highlighter-rouge">$V/e_1$</code> with <code class="language-plaintext highlighter-rouge">$e_1$</code> added. The construction of <code class="language-plaintext highlighter-rouge">$V/e_1$</code> is essentially “collapsing” the dimension <code class="language-plaintext highlighter-rouge">$e_1$</code> “points” in, giving us a new space where we’ve “deleted” all of the elements that have a nonzero <code class="language-plaintext highlighter-rouge">$e_1$</code> component.</p> <p>However, this only works when the dimension is finite; more complex methods must be used for infinite-dimensional spaces. For example, the polynomials <code class="language-plaintext highlighter-rouge">$\Q[x]$</code> are an infinite-dimensional space, with basis elements <code class="language-plaintext highlighter-rouge">$\\{1, x, x^2, x^3, ...\\}$</code>. In general, for any linear space <code class="language-plaintext highlighter-rouge">$V$</code>, it <em>is</em> always possible to arbitrarily choose a basis, although it may be infinite<sup id="fnref:rq" role="doc-noteref"><a href="#fn:rq" class="footnote" rel="footnote">4</a></sup>.</p> <p>Bases are useful because they give us a concrete representation of any element of <code class="language-plaintext highlighter-rouge">$V$</code>. Given a fixed basis <code class="language-plaintext highlighter-rouge">$e_i$</code>, we can represent any <code class="language-plaintext highlighter-rouge">$w = \sum_i c_i e_i$</code> by the coefficients <code class="language-plaintext highlighter-rouge">$c_i$</code> themselves. For a finite-dimensional <code class="language-plaintext highlighter-rouge">$V$</code>, this brings us back <em>column vectors</em>: <code class="language-plaintext highlighter-rouge">$(\dim V)$</code>-tuples of coefficients from <code class="language-plaintext highlighter-rouge">$K$</code> that are added and scaled componentwise.</p> <p>```latex render: \Mat{c_0 \ c_1 \ \vdots \ c_n} \,\underset{\text{given } e_i}{:=}\, \sum_i c_i e_i</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
The `$i$`th basis element is represented as the vector whose entries are all
`$0$` except for the `$i$`th one, which is `$1$`. E.g.,

```latex render:
\Mat{1 \\ 0 \\ \vdots \\ 0} \,\underset{\text{given } e_i}{=}\, e_1, \,\,\,
\Mat{0 \\ 1 \\ \vdots \\ 0} \,\underset{\text{given } e_i}{=}\, e_2, \,\,\,
...
</code></pre></div></div> <p>It is important to recall that the choice of basis is <em>arbitrary</em>. From the mathematical perspective, any basis is just as good as any other, although some may be more computationally convenient.</p> <p>Over <code class="language-plaintext highlighter-rouge">$\R^2$</code>, <code class="language-plaintext highlighter-rouge">$(1, 0)$</code> and <code class="language-plaintext highlighter-rouge">$(0, 1)$</code> are sometimes called the “standard basis”, but <code class="language-plaintext highlighter-rouge">$(1, 2)$</code> and <code class="language-plaintext highlighter-rouge">$(3, -4)$</code> are also a basis for this space. One easy mistake to make, particularly when working over the tuple space <code class="language-plaintext highlighter-rouge">$K^n$</code>, is to confuse the actual elements of the linear space with the coefficient vectors that represent them. Working with abstract linear spaces eliminates this source of confusion.</p> <h3 id="representing-linear-transformations"><a href="#representing-linear-transformations">Representing Linear Transformations</a></h3> <p>Working with finite-dimensional linear spaces <code class="language-plaintext highlighter-rouge">$V$</code> and <code class="language-plaintext highlighter-rouge">$W$</code>, let’s choose bases <code class="language-plaintext highlighter-rouge">$e_i$</code> and <code class="language-plaintext highlighter-rouge">$d_j$</code> for them, and let’s consider a linear map <code class="language-plaintext highlighter-rouge">$f: V \to W$</code>.</p> <p>The powerful thing about bases is that we can more compactly express the information content of <code class="language-plaintext highlighter-rouge">$f$</code>. Given any <code class="language-plaintext highlighter-rouge">$v \in V$</code>, we can decompose it into a linear function of the basis (for some coefficients), so we can write</p> <p>```latex render: f(v) = f\left(\sum_i c_i e_i\right) = \sum_i f(c_i e_i) = \sum_i c_i \cdot f(e_i)</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
In other words, to specify `$f$`, we _only_ need to specify what it does to each
of the `$\dim V$` basis elements. But what's more, because `$W$` also has a
basis, we can write

```latex render:
f(e_i) = \sum_j A_{ij} d_j
</code></pre></div></div> <p>Putting these two formulas together, we have an explicit closed form for <code class="language-plaintext highlighter-rouge">$f(v)$</code>, given the coefficients <code class="language-plaintext highlighter-rouge">$A_{ij}$</code> of <code class="language-plaintext highlighter-rouge">$f$</code>, and the coefficients <code class="language-plaintext highlighter-rouge">$c_i$</code> of <code class="language-plaintext highlighter-rouge">$v$</code>:</p> <p>```latex render: f(v) = \sum_{i,j} c_i A_{ij} d_j</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Alternatively, we can express `$v$` and `$f(v)$` as column vectors, and `$f$` as
the `$A$` matrix with entires `$A_{ij}$`. The entries of the resulting column
vector are given by the above explicit formula for `$f(v)$`, fixing the value of
`$j$` in each entry.

```latex render:
\underbrace{\Mat{
  A_{0,0} &amp; A_{1,0} &amp; \cdots &amp; A_{n,0} \\
  A_{1,0} &amp; A_{1,1} &amp; \cdots &amp; A_{n,1} \\
  \vdots  &amp; \vdots  &amp; \ddots &amp; \vdots  \\
  A_{0,m} &amp; A_{1,m} &amp; \cdots &amp; A_{n,m}
}}_A \,
\underbrace{\Mat{c_0 \\ c_1 \\ \vdots \\ c_n}}_v =
\underbrace{\Mat{
  \sum_i c_i A_{i,0} \\
  \sum_i c_i A_{i,1} \\
  \vdots \\
  \sum_i c_i A_{i,m}
}}_{Av}
</code></pre></div></div> <p>(Remember, this is all dependent on the choices of bases <code class="language-plaintext highlighter-rouge">$e_i$</code> and <code class="language-plaintext highlighter-rouge">$d_j$</code>!)</p> <p>Behold, we have derived the matrix-vector multiplication formula: the <code class="language-plaintext highlighter-rouge">$j$</code>th entry of the result is the dot product of the vector and the <code class="language-plaintext highlighter-rouge">$j$</code>th row of the matrix.</p> <p>But it is crucial to keep in mind that we had to choose bases <code class="language-plaintext highlighter-rouge">$e_i$</code> and <code class="language-plaintext highlighter-rouge">$d_j$</code> to be entitled to write down a matrix for <code class="language-plaintext highlighter-rouge">$f$</code>. The values of the coefficients depend on the choice of basis.</p> <p>If your linear space happens to be <code class="language-plaintext highlighter-rouge">$\R^n$</code>, there is an “obvious” choice of basis, but not every linear space over <code class="language-plaintext highlighter-rouge">$\R$</code> is <code class="language-plaintext highlighter-rouge">$\R^n$</code>! Importantly, the actual linear algebra <em>does not</em> change depending on the basis<sup id="fnref:similar" role="doc-noteref"><a href="#fn:similar" class="footnote" rel="footnote">5</a></sup>.</p> <h2 id="matrix-multiplication"><a href="#matrix-multiplication">Matrix Multiplication</a></h2> <p>So, where does matrix multiplication come from? An <code class="language-plaintext highlighter-rouge">$n \times m$</code><sup id="fnref:rc" role="doc-noteref"><a href="#fn:rc" class="footnote" rel="footnote">6</a></sup> matrix <code class="language-plaintext highlighter-rouge">$A$</code> <em>represents</em> some linear map <code class="language-plaintext highlighter-rouge">$f: V \to W$</code>, where <code class="language-plaintext highlighter-rouge">$\dim V = n$</code>, <code class="language-plaintext highlighter-rouge">$\dim W = m$</code>, and appropriate choices of basis (<code class="language-plaintext highlighter-rouge">$e_i$</code>, <code class="language-plaintext highlighter-rouge">$d_j$</code>) have been made.</p> <p>Keeping in mind that linear maps are supreme over matrices, suppose we have a third linear space <code class="language-plaintext highlighter-rouge">$U$</code>, and a map <code class="language-plaintext highlighter-rouge">$g: U \to V$</code>, and let <code class="language-plaintext highlighter-rouge">$\ell = \dim U$</code>. Choosing a basis <code class="language-plaintext highlighter-rouge">$h_k$</code> for <code class="language-plaintext highlighter-rouge">$U$</code>, we can represent <code class="language-plaintext highlighter-rouge">$g$</code> as a matrix <code class="language-plaintext highlighter-rouge">$B$</code> of dimension <code class="language-plaintext highlighter-rouge">$\ell \times n$</code>.</p> <p>Then, we’d like for the matrix product <code class="language-plaintext highlighter-rouge">$AB$</code> to be the same matrix we’d get from representing the composite map <code class="language-plaintext highlighter-rouge">$fg: U \to W$</code> as a matrix, using the aforementioned choices of bases for <code class="language-plaintext highlighter-rouge">$U$</code> and <code class="language-plaintext highlighter-rouge">$W$</code> (the basis choice for <code class="language-plaintext highlighter-rouge">$V$</code> should “cancel out”).</p> <p>Recall our formula for <code class="language-plaintext highlighter-rouge">$f(v)$</code> in terms of its matrix coefficients <code class="language-plaintext highlighter-rouge">$A_{ij}$</code> and the coefficients of the input <code class="language-plaintext highlighter-rouge">$v$</code>, which we call <code class="language-plaintext highlighter-rouge">$c_i$</code>. We can produce a similar formula for <code class="language-plaintext highlighter-rouge">$g(u)$</code>, giving it matrix coefficients <code class="language-plaintext highlighter-rouge">$B_{ki}$</code>, and coefficients <code class="language-plaintext highlighter-rouge">$b_k$</code> for <code class="language-plaintext highlighter-rouge">$u$</code>. (I appologize for the number of indices and coefficients here.)</p> <p>```latex render:align* f(v) &amp;= \sum_{i,j} c_i A_{ij} d_j <br/> g(u) &amp;= \sum_{k,i} b_k B_{ki} e_i</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
If we write `$f(g(u))$`, then `$c_i$` is the coefficient `$e_i$` is multiplied
by; i.e., we fix `$i$`, and drop it from the summation:
`$c_i = \sum_k b_k B_{ki}$`.

Substituting that into the above formula, we now have something like the
following.

```latex render:align*
f(g(u)) &amp;= \sum_{i,j} \sum_{k} b_k B_{ki} A_{ij} d_j \\
f(g(u)) &amp;= \sum_{k,j} b_k \left(\sum_{i} A_{ij} B_{ki} \right) d_j &amp;(\star)
</code></pre></div></div> <p>In <code class="language-plaintext highlighter-rouge">$(\star)$</code>, we’ve rearranged things so that the sum in parenthesis is the <code class="language-plaintext highlighter-rouge">$(k,j)$</code>th matrix coefficient of the composite <code class="language-plaintext highlighter-rouge">$fg$</code>. Because we wanted <code class="language-plaintext highlighter-rouge">$AB$</code> to represent <code class="language-plaintext highlighter-rouge">$fg$</code>, it must be an <code class="language-plaintext highlighter-rouge">$\ell \times m$</code> matrix whose entries are</p> <p>```latex render: (AB)<em>{kj} = \sum</em>{i} A_{ij} B_{ki}</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
_This_ is matrix multiplication. It arises naturally out of composition of
linear maps. In this way, the matrix multiplication formula is not a definition,
but a _theorem_ of linear algebra!

&gt; #### Theorem (Matrix Multiplication)
&gt;
&gt; Given an `$n \times m$` matrix `$A$` and an `$\ell \times n$` matrix `$B$`,
&gt; both with coefficients in `$K$`, then `$AB$` is an `$\ell \times m$` matrix
&gt; with entires
&gt;
&gt; ```latex render:
&gt; (AB)_{kj} = \sum_{i} A_{ij} B_{ki}
&gt; ```

If the matrix dimension is read as `$n \to m$` instead of `$n \times m$`, the
shape requirements are more obvious: two matrices `$A$` and `$B$` can be
multiplied together only when they represent a pair of maps `$V \to W$` and
`$U \to V$`.

### Other Consequences, and Conclusion

The identity matrix is an `$n \times n$` matrix:

```latex render:
I_n = \Mat{
1 \\
&amp; 1 \\
&amp;&amp; \ddots \\
&amp;&amp;&amp; 1
}
</code></pre></div></div> <p>We want it to be such that for any appropriately-sized matrices <code class="language-plaintext highlighter-rouge">$A$</code> and <code class="language-plaintext highlighter-rouge">$B$</code>, it has <code class="language-plaintext highlighter-rouge">$AI_n = A$</code> and <code class="language-plaintext highlighter-rouge">$I_n B = B$</code>. Lifted up to linear maps, this means that <code class="language-plaintext highlighter-rouge">$I_n$</code> should represent the identity map <code class="language-plaintext highlighter-rouge">$V \to V$</code>, when <code class="language-plaintext highlighter-rouge">$\dim V = n$</code>. This map sends each basis element <code class="language-plaintext highlighter-rouge">$e_i$</code> to itself, so the columns of <code class="language-plaintext highlighter-rouge">$I_n$</code> should be the basis vectors, in order:</p> <p>```latex render: \Mat{1 \ 0 \ \vdots \ 0} \Mat{0 \ 1 \ \vdots \ 0} \cdots \Mat{0 \ 0 \ \vdots \ 1}</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
If we shuffle the columns, we'll get a _permutation matrix_, which shuffles the
coefficients of a column vector. For example, consider this matrix.

```latex render:
\Mat{
  0 &amp; 1 &amp; 0 \\
  1 &amp; 0 &amp; 0 \\
  0 &amp; 0 &amp; 1
}
</code></pre></div></div> <p>This is similar to the identity, but we’ve swapped the first two columns. Thus, it will swap the first two coefficients of any column vector.</p> <p>Matrices may seem unintuitive when they’re introduced as a subject of study. Every student encountering matrices for the same time may ask “If they add componentwise, why don’t they multiply componentwise too?”</p> <p>However, approaching matrices as a computational and representational tool shows that the convoluted-looking matrix multiplication formula is a direct consequence of linearity.</p> <p><code class="language-plaintext highlighter-rouge">latex render:gather* f(v + w) = f(v) + f(w) \\ f(cv) = c \cdot f(v) </code></p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:vs-in-generality" role="doc-endnote"> <p>In actual modern mathematics, the objects I describe are still called vector spaces, which I think generates unnecessary confusion in this case. “Linear space” is a bit more on the nose for what I’m going for. <a href="#fnref:vs-in-generality" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:ab-group" role="doc-endnote"> <p>This type of structure (just the addition part) is also called an “abelian group”. <a href="#fnref:ab-group" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:invariant-dim" role="doc-endnote"> <p>This is sometimes called the <a href="https://en.wikipedia.org/wiki/Dimension_theorem_for_vector_spaces"><em>dimension theorem</em></a>, which is somewhat tedious to prove. <a href="#fnref:invariant-dim" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:rq" role="doc-endnote"> <p>An example of a messy infinite-dimensional basis is <code class="language-plaintext highlighter-rouge">$\R$</code> considered as linear space over <code class="language-plaintext highlighter-rouge">$\Q$</code> (in general, every field is a linear space over its subfields). The basis for this space essentially has to be “<code class="language-plaintext highlighter-rouge">$1$</code>, and all irrational numbers” except if we include e.g. <code class="language-plaintext highlighter-rouge">$e$</code> and <code class="language-plaintext highlighter-rouge">$\pi$</code> we can’t include <code class="language-plaintext highlighter-rouge">$e + \frac{1}{2}\pi$</code>, which is a <code class="language-plaintext highlighter-rouge">$\Q$</code>-linear combination of <code class="language-plaintext highlighter-rouge">$e$</code> and <code class="language-plaintext highlighter-rouge">$\pi$</code>.</p> <p>On the other hand, <code class="language-plaintext highlighter-rouge">$\C$</code> is two-dimensional over <code class="language-plaintext highlighter-rouge">$\R$</code>, with basis <code class="language-plaintext highlighter-rouge">$\\{1, i\\}$</code>.</p> <p>Incidentally, this idea of “view a field <code class="language-plaintext highlighter-rouge">$K$</code> as a linear space over its subfield <code class="language-plaintext highlighter-rouge">$F$</code>” is such a useful concept that it is called the “degree of the field extension <code class="language-plaintext highlighter-rouge">$K/F$</code>”, and given the symbol <code class="language-plaintext highlighter-rouge">$[K : F]$</code>.</p> <p>This, <code class="language-plaintext highlighter-rouge">$[\R : \Q] = \infty$</code> and <code class="language-plaintext highlighter-rouge">$[\C : \R] = 2$</code>. <a href="#fnref:rq" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:similar" role="doc-endnote"> <p>You may recall from linear algebra class that two matrices <code class="language-plaintext highlighter-rouge">$A$</code> and <code class="language-plaintext highlighter-rouge">$B$</code> of the same shape are <em>similar</em> if there are two appropriately-sized square matrices <code class="language-plaintext highlighter-rouge">$S$</code> and <code class="language-plaintext highlighter-rouge">$R$</code> such that <code class="language-plaintext highlighter-rouge">$SAR = B$</code>. These matrices <code class="language-plaintext highlighter-rouge">$S$</code> and <code class="language-plaintext highlighter-rouge">$R$</code> represent a <em>change of basis</em>, and indicate that the linear maps <code class="language-plaintext highlighter-rouge">$A, B: V \to W$</code> these matrices come from do “the same thing” to elements of <code class="language-plaintext highlighter-rouge">$V$</code>.</p> <p>Over an algebraically closed field like <code class="language-plaintext highlighter-rouge">$\C$</code> (i.e. all polynomials have solutions), there is an even stronger way to capture the information content of a linear map via <a href="https://en.wikipedia.org/wiki/Jordan_normal_form"><em>Jordan canonicalization</em></a>, which takes any square matrix <code class="language-plaintext highlighter-rouge">$A$</code> and produces an almost-diagonal square matrix that only depends on the eigenvalues of <code class="language-plaintext highlighter-rouge">$A$</code>, which is the same for similar matrices, and thus basis-independent. <a href="#fnref:similar" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:rc" role="doc-endnote"> <p>Here, as always, matrix dimensions are given in RC (row-column) order. You can think of this as being “input dimension” to “output dimension”. <a href="#fnref:rc" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div> </div> </div> <div class="post-preview"> <div class="post-title"> <span class="post-meta"> 2023-08-09 • 2839 words • 15 minutes <br class="show-if-mobile"/> <span class="hide-if-mobile">•</span> <a href="https://mcyoung.xyz/tags.html#dark-arts">#dark-arts</a> • <a href="https://mcyoung.xyz/tags.html#pointers">#pointers</a> • <a href="https://mcyoung.xyz/tags.html#rust">#rust</a> </span> <h1><a href="/2023/08/09/yarns/"> I Wrote A String Type<br/> </a></h1> </div> <div class="post"> <p>I write compilers for fun. I can’t help it. Consequently, I also write a lot of parsers. In systems programming, it’s usually a good idea to try to share memory rather than reuse it, so as such my AST types tend to look like this.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">enum</span> <span class="n">Expr</span><span class="o">&lt;</span><span class="nv">'src</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="nf">Int</span><span class="p">(</span><span class="nb">u32</span><span class="p">)</span>
  <span class="nf">Ident</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'src</span> <span class="nb">str</span><span class="p">),</span>
  <span class="c1">// ...</span>
<span class="p">}</span>
</code></pre></div></div> <p>Whenever we parse an identifier, rather than copy its name into a fresh <code class="language-plaintext highlighter-rouge">String</code>, we borrow from the input source string. This avoids an extra allocation, an extra copy, and saves a word in the representation. Compilers can be memory-hungry, so it helps to pick a lean representation.</p> <p>Unfortunately, it’s not so easy for quoted strings. Most strings, like <code class="language-plaintext highlighter-rouge">"all my jelly babies"</code>, are “literally” in the original source, like an identifier. But strings with escapes aren’t: <code class="language-plaintext highlighter-rouge">\n</code> is encoded in the source code with the bytes <code class="language-plaintext highlighter-rouge">[0x5c, 0x6e]</code>, but the actual “decoded” value of a string literal replaces each escape with a single <code class="language-plaintext highlighter-rouge">0x0a</code>.</p> <p>The usual solution is a <a href="https://doc.rust-lang.org/std/borrow/enum.Cow.html"><code class="language-plaintext highlighter-rouge">Cow&lt;str&gt;</code></a>. In the more common, escape-less verison, we can use <code class="language-plaintext highlighter-rouge">Cow::Borrowed</code>, which avoids the extra allocation and copy, and in the escaped version, we decode the escapes into a <code class="language-plaintext highlighter-rouge">String</code> and wrap it in a <code class="language-plaintext highlighter-rouge">Cow::Owned</code>.</p> <p>For example, suppose that we’re writing a parser for a language that has quoted strings with escapes. The string <code class="language-plaintext highlighter-rouge">"all my jelly babies"</code> can be represented as a byte string that borrows the input source code, so we’d use the <code class="language-plaintext highlighter-rouge">Cow::Borrowed</code> variant. This is most strings in any language: escapes tend to be rare.</p> <p>For example, if we have the string <code class="language-plaintext highlighter-rouge">"not UTF-8 \xff"</code>, the actual byte string value is different from that in the source code.</p> <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// Bytes in the source.
hex:   6e 6f 74 20 55 54 46 2d 38 20 5c 78 66 66
ascii: n  o  t     U  T  F  -  8     \  x  f  f

// Bytes represented by the string.
hex:   6e 6f 74 20 55 54 46 2d 38 20 ff
ascii: n  o  t     U  T  F  -  8
</code></pre></div></div> <p>Escapes are relatively rare, so most strings processed by the parser do not need to pay for an allocation.</p> <p>However, we still pay for that extra word, since <code class="language-plaintext highlighter-rouge">Cow&lt;str&gt;</code> is 24 bytes (unless otherwise specified, all byte counts assume a 64-bit system), which is eight more than our <code class="language-plaintext highlighter-rouge">&amp;str</code>. Even worse, this is bigger than the string data itself, which is 11 bytes.</p> <p>If most of your strings are small (which is not uncommon in an AST parser), you will wind up paying for significant overhead.</p> <p>Over the years I’ve implemented various optimized string types to deal with this use-case, in various contexts. I finally got around to putting all of the tricks I know into a library, which I call <a href="https://docs.rs/byteyarn/latest/byteyarn/"><code class="language-plaintext highlighter-rouge">byteyarn</code></a>. It advertises the following nice properties.</p> <blockquote> <p>A <code class="language-plaintext highlighter-rouge">Yarn</code> is a highly optimized string type that provides a number of useful properties over <code class="language-plaintext highlighter-rouge">String</code>:</p> <ul> <li>Always two pointers wide, so it is always passed into and out of functions in registers.</li> <li>Small string optimization (SSO) up to 15 bytes on 64-bit architectures.</li> <li>Can be either an owned buffer or a borrowed buffer (like <code class="language-plaintext highlighter-rouge">Cow&lt;str&gt;</code>).</li> <li>Can be upcast to <code class="language-plaintext highlighter-rouge">'static</code> lifetime if it was constructed from a known-static string.</li> </ul> </blockquote> <p>I’d like to share how these properties are achieved through careful layout optimization.</p> <h2 id="assumptions"><a href="#assumptions">Assumptions</a></h2> <p>We’re going to start by stating assumptions about how our strings will be used:</p> <ol> <li>Most strings are not mutated most of the time.</li> <li>Most strings are small.</li> <li>Most strings are substrings.</li> </ol> <h3 id="most-strings-are-immutable"><a href="#most-strings-are-immutable">Most Strings are Immutable</a></h3> <p><code class="language-plaintext highlighter-rouge">String</code> is modeled after C++’s <code class="language-plaintext highlighter-rouge">std::string</code>, which is a growable buffer that implements amortized linear-time append. This means that if we are appending <code class="language-plaintext highlighter-rouge">n</code> bytes to the buffer, we only pay for <code class="language-plaintext highlighter-rouge">n</code> bytes of <code class="language-plaintext highlighter-rouge">memcpy</code>.</p> <p>This is a useful but often unnecessary property. For example, Go strings are immutable, and when building up a large string, you are expected to use <code class="language-plaintext highlighter-rouge">strings.Builder</code>, which is implemented as essentially a Rust <code class="language-plaintext highlighter-rouge">String</code>. Java also as a similar story for strings, which allows for highly compact representations of <code class="language-plaintext highlighter-rouge">java.lang.String</code>s.</p> <p>In Rust, this kind of immutable string is represented by a <code class="language-plaintext highlighter-rouge">Box&lt;str&gt;</code>, which is eight bytes smaller than <code class="language-plaintext highlighter-rouge">String</code>. Converting from <code class="language-plaintext highlighter-rouge">String</code> to <code class="language-plaintext highlighter-rouge">Box&lt;str&gt;</code> is just a call to <code class="language-plaintext highlighter-rouge">realloc()</code> to resize the underlying allocation (which is often cheap<sup id="fnref:size-classes" role="doc-noteref"><a href="#fn:size-classes" class="footnote" rel="footnote">1</a></sup>) from being <code class="language-plaintext highlighter-rouge">capacity</code> bytes long to <code class="language-plaintext highlighter-rouge">len</code> bytes long.</p> <p>Thus, this assumption means we only need to store a pointer and a length, which puts our memory footprint floor at 16 bytes.</p> <h3 id="most-strings-are-substrings"><a href="#most-strings-are-substrings">Most Strings are Substrings</a></h3> <p>Suppose again that we’re parsing some textual format. Many structural elements will be verbatim references into the textual input. Not only string literals without escapes, but also identifiers.</p> <p><code class="language-plaintext highlighter-rouge">Box&lt;str&gt;</code> cannot hold borrowed data, because it will always instruct the allocator to free its pointer when it goes out of scope. <code class="language-plaintext highlighter-rouge">Cow&lt;str&gt;</code>, as we saw above, allows us to handle maybe-owned data uniformly, but has a minimum 24 byte overhead. This can’t be made any smaller, because a <code class="language-plaintext highlighter-rouge">Cow&lt;str&gt;</code> can contain a 24-byte <code class="language-plaintext highlighter-rouge">String</code> value.</p> <p>But, we don’t want to store a capacity. Can we avoid the extra word of overhead in <code class="language-plaintext highlighter-rouge">Cow&lt;str&gt;</code>?</p> <h3 id="most-strings-are-small"><a href="#most-strings-are-small">Most Strings are Small</a></h3> <p>Consider a string that is not a substring but which is small. For example, when parsing a string literal like <code class="language-plaintext highlighter-rouge">"Hello, world!\n"</code>, the trailing <code class="language-plaintext highlighter-rouge">\n</code> (bytes <code class="language-plaintext highlighter-rouge">0x5c 0x6e</code>) must be replaced with a newline byte (<code class="language-plaintext highlighter-rouge">0x0a</code>). This means we must handle a tiny heap allocation, 14 bytes long, that is smaller than a <code class="language-plaintext highlighter-rouge">&amp;str</code> referring to it.</p> <p>This is worse for single character<sup id="fnref:character" role="doc-noteref"><a href="#fn:character" class="footnote" rel="footnote">2</a></sup> strings. The overhead for a <code class="language-plaintext highlighter-rouge">Box&lt;str&gt;</code> is large.</p> <ul> <li>The <code class="language-plaintext highlighter-rouge">Box&lt;str&gt;</code> struct itself has a pointer field (eight bytes), and a length field (also eight bytes). Spelled out to show all the stored bits, the length is <code class="language-plaintext highlighter-rouge">0x0000_0000_0000_0001</code>. That’s a lot of zeroes!</li> <li>The pointer itself points to a heap allocation, which will not be a single byte! Allocators are not in the business of handing out such small pieces of memory. Instead, the allocation is likely costing us another eight bytes!</li> </ul> <p>So, the string <code class="language-plaintext highlighter-rouge">"a"</code>, whose data is just a <em>single byte</em>, instead takes up 24 bytes of memory.</p> <p>It turns out that for really small strings we can avoid the allocation altogether, <em>and</em> make effective use of all those zeroes in the <code class="language-plaintext highlighter-rouge">len</code> field.</p> <h2 id="stealing-bits"><a href="#stealing-bits">Stealing Bits</a></h2> <p>Let’s say we want to stick to a budget of 16 bytes for our <code class="language-plaintext highlighter-rouge">Yarn</code> type. Is there any extra space left for data in a <code class="language-plaintext highlighter-rouge">(*mut u8, usize)</code> pair?</p> <p><em>*cracks Fermi estimation knuckles*</em></p> <p>A <code class="language-plaintext highlighter-rouge">usize</code> is 64 bits, which means that the length of an <code class="language-plaintext highlighter-rouge">&amp;str</code> can be anywhere from zero to 18446744073709551615, or around 18 exabytes. For reference, “hundreds of exabytes” is a reasonable ballpark guess for how much RAM exists in 2023 (consider: 4 billion smartphones with 4GB each). More practically, the largest quantity of RAM you can fit in a server blade is measured in terabytes (much more than your measly eight DIMs on your gaming rig).</p> <p>If we instead use one less bit, 63 bits, this halves the maximum representable memory to nine exabytes. If we take another, it’s now four exabytes. Much more memory than you will ever <em>ever</em> want to stick in a string. <a href="https://en.wikipedia.org/wiki/Wikipedia:Size_of_Wikipedia#Size_of_the_English_Wikipedia_database">Wikpedia asserts</a> that Wikimedia Commons contains around 428 terabytes of media (the articles’ text with history is a measly 10 TB).</p> <p>Ah, but you say you’re programming for a 32-bit machine (today, this likely means either a low-end mobile phone, an embedded micro controller, or WASM).</p> <p>On a 32-bit machine it’s a little bit harrier: Now <code class="language-plaintext highlighter-rouge">usize</code> is 32 bits, for a maximum string size of 4 gigabytes (if you remember the 32-bit era, this limit may sound familiar). “Gigabytes” is an amount of memory that you can actually imagine having in a string.</p> <p>Even then, 1 GB of memory (if we steal two bits) on a 32-bit machine is a lot of data. You can only have four strings that big in a single address space, and every 32-bit allocator in the universe will refuse to serve an allocation of that size. If your strings are comparable in size to the whole address space, you should build your own string type.</p> <p>The upshot is that every <code class="language-plaintext highlighter-rouge">&amp;str</code> contains two bits we can reasonably assume are not used. <em>Free real-estate.</em><sup id="fnref:isize" role="doc-noteref"><a href="#fn:isize" class="footnote" rel="footnote">3</a></sup></p> <h3 id="a-hand-written-niche-optimization"><a href="#a-hand-written-niche-optimization">A Hand-Written Niche Optimization</a></h3> <p>Rust has the concept of <em>niches</em>, or invalid bit-patterns of a particular type, which it uses for automatic layout optimization of <code class="language-plaintext highlighter-rouge">enum</code>s. For example, references cannot be null, so the pointer bit-pattern of <code class="language-plaintext highlighter-rouge">0x0000_0000_0000_0000</code> is never used; this bit-pattern is called a “niche”. Consider:</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">enum</span> <span class="n">Foo</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="nf">First</span><span class="p">(</span><span class="o">&amp;</span><span class="nv">'a</span> <span class="n">T</span><span class="p">),</span>
  <span class="n">Second</span>
<span class="p">}</span>
</code></pre></div></div> <p>An <code class="language-plaintext highlighter-rouge">enum</code> of this form will not need any “extra” space to store the value that discriminates between the two variants: if a <code class="language-plaintext highlighter-rouge">Foo</code>’s bits are all zero, it’s <code class="language-plaintext highlighter-rouge">Foo::Second</code>; otherwise it’s a <code class="language-plaintext highlighter-rouge">Foo::First</code> and the payload is formed from <code class="language-plaintext highlighter-rouge">Foo</code>’s bit-pattern. This, incidentally, is what makes <code class="language-plaintext highlighter-rouge">Option&lt;&amp;T&gt;</code> a valid representation for a “nullable pinter”.</p> <p>There are more general forms of this: <code class="language-plaintext highlighter-rouge">bool</code> is represented as a single byte, of which two bit are valid; the other 254 potential bit-patterns are niches. In Recent versions of Rust, <code class="language-plaintext highlighter-rouge">RawFd</code> has a niche for the all-ones bit-pattern, since POSIX file descriptors are always non-negative <code class="language-plaintext highlighter-rouge">int</code>s.</p> <p>By stealing two bits off of the length, we have given ourselves four niches, which essentially means we’ll have a hand-written version of something like this <code class="language-plaintext highlighter-rouge">enum</code>.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">enum</span> <span class="n">Yarn</span> <span class="p">{</span>
  <span class="nf">First</span><span class="p">(</span><span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">u62</span><span class="p">),</span>
  <span class="nf">Second</span><span class="p">(</span><span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">u62</span><span class="p">),</span>
  <span class="nf">Third</span><span class="p">(</span><span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">u62</span><span class="p">),</span>
  <span class="nf">Fourth</span><span class="p">(</span><span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">u62</span><span class="p">),</span>
<span class="p">}</span>
</code></pre></div></div> <p>For reasons that will become clear later, we will specifically steal the <em>high</em> bits of the length, so that to recover the length, we do two shifts<sup id="fnref:two-shifts" role="doc-noteref"><a href="#fn:two-shifts" class="footnote" rel="footnote">4</a></sup> to shift in two high zero bits. Here’s some code that actually implements this for the low level type our string type will be built on.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[repr(C)]</span>
<span class="nd">#[derive(Copy,</span> <span class="nd">Clone)]</span>
<span class="k">struct</span> <span class="n">RawYarn</span> <span class="p">{</span>
  <span class="n">ptr</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">,</span>
  <span class="n">len</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">impl</span> <span class="n">RawYarn</span> <span class="p">{</span>
  <span class="cd">/// Constructs a new RawYarn from raw components: a 2-bit kind,</span>
  <span class="cd">/// a length, and a pointer.</span>
  <span class="k">fn</span> <span class="nf">from_raw_parts</span><span class="p">(</span><span class="n">kind</span><span class="p">:</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">len</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span> <span class="n">ptr</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="k">Self</span> <span class="p">{</span>
    <span class="nd">assert!</span><span class="p">(</span><span class="n">len</span> <span class="o">&lt;=</span> <span class="nn">usize</span><span class="p">::</span><span class="n">MAX</span> <span class="o">/</span> <span class="mi">4</span><span class="p">,</span> <span class="s">"no way you have a string that big"</span><span class="p">);</span>

    <span class="n">RawYarn</span> <span class="p">{</span>
      <span class="n">ptr</span><span class="p">,</span>
      <span class="n">len</span><span class="p">:</span> <span class="p">(</span><span class="n">kind</span> <span class="k">as</span> <span class="nb">usize</span> <span class="o">&amp;</span> <span class="mi">0b11</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="nn">usize</span><span class="p">::</span><span class="n">BITS</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="p">|</span> <span class="n">len</span><span class="p">,</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="cd">/// Extracts the kind back out.</span>
  <span class="k">fn</span> <span class="nf">kind</span><span class="p">(</span><span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">u8</span> <span class="p">{</span>
    <span class="p">(</span><span class="k">self</span><span class="py">.len</span> <span class="o">&gt;&gt;</span> <span class="p">(</span><span class="nn">usize</span><span class="p">::</span><span class="n">BITS</span> <span class="o">-</span> <span class="mi">2</span><span class="p">))</span> <span class="k">as</span> <span class="nb">u8</span>
  <span class="p">}</span>

  <span class="cd">/// Extracts the slice out (regardless of kind).</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">as_slice</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">&amp;</span><span class="p">[</span><span class="nb">u8</span><span class="p">]</span> <span class="p">{</span>
    <span class="nn">slice</span><span class="p">::</span><span class="nf">from_raw_parts</span><span class="p">(</span><span class="k">self</span><span class="py">.ptr</span><span class="p">,</span> <span class="p">(</span><span class="k">self</span><span class="py">.len</span> <span class="o">&lt;&lt;</span> <span class="mi">2</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="mi">2</span><span class="p">)</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>Note that I’ve made this type <code class="language-plaintext highlighter-rouge">Copy</code>, and some functions take it by value. This is for two reasons.</p> <ol> <li> <p>There is a type of <code class="language-plaintext highlighter-rouge">Yarn</code> that is itself <code class="language-plaintext highlighter-rouge">Copy</code>, although I’m not covering it in this article.</p> </li> <li> <p>It is a two-word struct, which means that on most architectures it is eligible to be passed in a pair of registers. Passing it by value in the low-level code helps promote keeping it in registers. This isn’t always possible, as we will see when we discuss “SSO”.</p> </li> </ol> <p>Let’s chose kind <code class="language-plaintext highlighter-rouge">0</code> to mean “this is borrowed data”, and kind <code class="language-plaintext highlighter-rouge">1</code> to be “this is heap-allocated data”. We can use this to remember whether we need to call a destructor.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">pub</span> <span class="k">struct</span> <span class="n">Yarn</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="n">raw</span><span class="p">:</span> <span class="n">RawYarn</span><span class="p">,</span>
  <span class="n">_ph</span><span class="p">:</span> <span class="n">PhantomData</span><span class="o">&lt;&amp;</span><span class="nv">'a</span> <span class="nb">str</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">const</span> <span class="n">BORROWED</span><span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="k">const</span> <span class="n">HEAP</span><span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="k">impl</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="n">Yarn</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="cd">/// Create a new yarn from borrowed data.</span>
  <span class="k">pub</span> <span class="k">fn</span> <span class="nf">borrowed</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">str</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="k">Self</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">len</span> <span class="o">=</span> <span class="n">data</span><span class="nf">.len</span><span class="p">();</span>
    <span class="k">let</span> <span class="n">ptr</span> <span class="o">=</span> <span class="n">data</span><span class="nf">.as_ptr</span><span class="p">()</span><span class="nf">.cast_mut</span><span class="p">();</span>
    <span class="k">Self</span> <span class="p">{</span>
      <span class="n">raw</span><span class="p">:</span> <span class="nn">RawYarn</span><span class="p">::</span><span class="nf">from_raw_parts</span><span class="p">(</span><span class="n">BORROWED</span><span class="p">,</span> <span class="n">len</span><span class="p">,</span> <span class="n">ptr</span><span class="p">),</span>
      <span class="n">_ph</span><span class="p">:</span> <span class="n">PhantomData</span><span class="p">,</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="cd">/// Create a new yarn from owned data.</span>
  <span class="k">pub</span> <span class="k">fn</span> <span class="nf">owned</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="nb">str</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="k">Self</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">len</span> <span class="o">=</span> <span class="n">data</span><span class="nf">.len</span><span class="p">();</span>
    <span class="k">let</span> <span class="n">ptr</span> <span class="o">=</span> <span class="n">data</span><span class="nf">.as_ptr</span><span class="p">()</span><span class="nf">.cast_mut</span><span class="p">();</span>
    <span class="nn">mem</span><span class="p">::</span><span class="nf">forget</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>

    <span class="k">Self</span> <span class="p">{</span>
      <span class="n">raw</span><span class="p">:</span> <span class="nn">RawYarn</span><span class="p">::</span><span class="nf">from_raw_parts</span><span class="p">(</span><span class="n">HEAP</span><span class="p">,</span> <span class="n">len</span><span class="p">,</span> <span class="n">ptr</span><span class="p">),</span>
      <span class="n">_ph</span><span class="p">:</span> <span class="n">PhantomData</span><span class="p">,</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="cd">/// Extracts the data.</span>
  <span class="k">pub</span> <span class="k">fn</span> <span class="nf">as_slice</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">&amp;</span><span class="nb">str</span> <span class="p">{</span>
    <span class="k">unsafe</span> <span class="p">{</span>
      <span class="c1">// SAFETY: initialized either from uniquely-owned data,</span>
      <span class="c1">// or borrowed data of lifetime 'a that outlives self.</span>
      <span class="nn">str</span><span class="p">::</span><span class="nf">from_utf8_unchecked</span><span class="p">(</span><span class="k">self</span><span class="py">.raw</span><span class="nf">.as_slice</span><span class="p">())</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="k">impl</span> <span class="nb">Drop</span> <span class="k">for</span> <span class="n">Yarn</span><span class="o">&lt;</span><span class="nv">'_</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="k">fn</span> <span class="nf">drop</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="k">self</span><span class="py">.raw</span><span class="nf">.kind</span><span class="p">()</span> <span class="o">==</span> <span class="n">HEAP</span> <span class="p">{</span>
      <span class="k">let</span> <span class="n">dropped</span> <span class="o">=</span> <span class="k">unsafe</span> <span class="p">{</span>
        <span class="c1">// SAFETY: This is just reconstituting the box we dismantled</span>
        <span class="c1">// in Yarn::owned().</span>
        <span class="nn">Box</span><span class="p">::</span><span class="nf">from_raw</span><span class="p">(</span><span class="k">self</span><span class="py">.raw</span><span class="nf">.as_mut_slice</span><span class="p">())</span>
      <span class="p">};</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="k">impl</span> <span class="n">RawYarn</span> <span class="p">{</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">as_slice_mut</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="p">[</span><span class="nb">u8</span><span class="p">]</span> <span class="p">{</span>
    <span class="c1">// Same thing as as_slice, basically. This is just to make</span>
    <span class="c1">// Box::from_raw() above typecheck.</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>This gives us a type that strongly resembles <code class="language-plaintext highlighter-rouge">Cow&lt;str&gt;</code> with only half of the bytes. We can even write code to extend the lifetime of a <code class="language-plaintext highlighter-rouge">Yarn</code>:</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">impl</span> <span class="n">Yarn</span><span class="o">&lt;</span><span class="nv">'_</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="cd">/// Removes the bound lifetime from the yarn, allocating if</span>
  <span class="cd">/// necessary.</span>
  <span class="k">pub</span> <span class="k">fn</span> <span class="nf">immortalize</span><span class="p">(</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Yarn</span><span class="o">&lt;</span><span class="k">'static</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">if</span> <span class="k">self</span><span class="py">.raw</span><span class="nf">.kind</span><span class="p">()</span> <span class="o">==</span> <span class="n">BORROWED</span> <span class="p">{</span>
      <span class="k">let</span> <span class="n">copy</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="nb">str</span><span class="o">&gt;</span> <span class="o">=</span> <span class="k">self</span><span class="nf">.as_slice</span><span class="p">()</span><span class="nf">.into</span><span class="p">();</span>
      <span class="k">self</span> <span class="o">=</span> <span class="nn">Yarn</span><span class="p">::</span><span class="nf">owned</span><span class="p">(</span><span class="n">copy</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="c1">// We need to be careful that we discard the old yarn, since its</span>
    <span class="c1">// destructor may run and delete the heap allocation we created</span>
    <span class="c1">// above.</span>
    <span class="k">let</span> <span class="n">raw</span> <span class="o">=</span> <span class="k">self</span><span class="py">.raw</span><span class="p">;</span>
    <span class="nn">mem</span><span class="p">::</span><span class="nf">forget</span><span class="p">(</span><span class="k">self</span><span class="p">);</span>
    <span class="nn">Yarn</span><span class="p">::</span><span class="o">&lt;</span><span class="k">'static</span><span class="o">&gt;</span> <span class="p">{</span>
      <span class="n">raw</span><span class="p">,</span>
      <span class="n">_ph</span><span class="p">:</span> <span class="n">PhantomData</span><span class="p">,</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>The remaining two niches can be put to use for optimizing small strings.</p> <h2 id="small-string-optimization"><a href="#small-string-optimization">Small String Optimization</a></h2> <p>C++’s <code class="language-plaintext highlighter-rouge">std::string</code> also makes the “most strings are small” assumption. In the <code class="language-plaintext highlighter-rouge">libc++</code> implementation of the standard library, <code class="language-plaintext highlighter-rouge">std::string</code>s of up to 23 bytes never hit the heap!</p> <p>C++ implementations do this by using most of the pointer, length, and capacity fields as a storage buffer for small strings, the so-called “small string optimization” (SSO). In <code class="language-plaintext highlighter-rouge">libc++</code>, in SSO mode, a <code class="language-plaintext highlighter-rouge">std::string</code>’s length fits in one byte, so the other 23 bytes can be used as storage. The capacity isn’t stored at all: an SSO string always has a capacity of 23.</p> <p><code class="language-plaintext highlighter-rouge">RawYarn</code> still has another two niches, so let’s dedicate one to a “small” representation. In small mode, the kind will be 2, and only the 16th byte will be the length.</p> <p>This is why we used the two <em>high</em> bits of <code class="language-plaintext highlighter-rouge">len</code> for our scratch space: no matter what mode it’s in, we can easily extract these bits<sup id="fnref:big-endian" role="doc-noteref"><a href="#fn:big-endian" class="footnote" rel="footnote">5</a></sup>. Some of the existing <code class="language-plaintext highlighter-rouge">RawYarn</code> methods need to be updated, though.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[repr(C)]</span>
<span class="nd">#[derive(Copy,</span> <span class="nd">Clone)]</span>
<span class="k">struct</span> <span class="n">RawYarn</span> <span class="p">{</span>
  <span class="n">ptr</span><span class="p">:</span> <span class="n">MaybeUninit</span><span class="o">&lt;*</span><span class="k">mut</span> <span class="nb">u8</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">len</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">const</span> <span class="n">SMALL</span><span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>

<span class="k">impl</span> <span class="n">RawYarn</span> <span class="p">{</span>
  <span class="cd">/// Constructs a new RawYarn from raw components: a 2-bit kind,</span>
  <span class="cd">/// a length, and a pointer.</span>
  <span class="k">fn</span> <span class="nf">from_raw_parts</span><span class="p">(</span><span class="n">kind</span><span class="p">:</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">len</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span> <span class="n">ptr</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="nd">debug_assert!</span><span class="p">(</span><span class="n">kind</span> <span class="o">!=</span> <span class="n">SMALL</span><span class="p">);</span>
    <span class="nd">assert!</span><span class="p">(</span><span class="n">len</span> <span class="o">&lt;=</span> <span class="nn">usize</span><span class="p">::</span><span class="n">MAX</span> <span class="o">/</span> <span class="mi">4</span><span class="p">,</span> <span class="s">"no way you have a string that big"</span><span class="p">);</span>

    <span class="n">RawYarn</span> <span class="p">{</span>
      <span class="n">ptr</span><span class="p">:</span> <span class="nn">MaybeUninit</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">ptr</span><span class="p">),</span>
      <span class="n">len</span><span class="p">:</span> <span class="p">(</span><span class="n">kind</span> <span class="k">as</span> <span class="nb">usize</span> <span class="o">&amp;</span> <span class="mi">0b11</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="nn">usize</span><span class="p">::</span><span class="n">BITS</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="p">|</span> <span class="n">len</span><span class="p">,</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="cd">/// Extracts the slice out (regardless of kind).</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">as_slice</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">&amp;</span><span class="p">[</span><span class="nb">u8</span><span class="p">]</span> <span class="p">{</span>
    <span class="k">let</span> <span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">adjust</span><span class="p">)</span> <span class="o">=</span> <span class="k">match</span> <span class="k">self</span><span class="nf">.kind</span><span class="p">()</span> <span class="p">{</span>
      <span class="n">SMALL</span> <span class="k">=&gt;</span> <span class="p">(</span><span class="k">self</span> <span class="k">as</span> <span class="o">*</span><span class="k">const</span> <span class="k">Self</span> <span class="k">as</span> <span class="o">*</span><span class="k">const</span> <span class="nb">u8</span><span class="p">,</span> <span class="nn">usize</span><span class="p">::</span><span class="n">BITS</span> <span class="o">-</span> <span class="mi">8</span><span class="p">),</span>
      <span class="n">_</span> <span class="k">=&gt;</span> <span class="p">(</span><span class="k">self</span><span class="py">.ptr</span><span class="nf">.assume_init</span><span class="p">(),</span> <span class="mi">0</span><span class="p">),</span>
    <span class="p">};</span>

    <span class="nn">slice</span><span class="p">::</span><span class="nf">from_raw_parts</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="p">(</span><span class="k">self</span><span class="py">.len</span> <span class="o">&lt;&lt;</span> <span class="mi">2</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="p">(</span><span class="mi">2</span> <span class="o">+</span> <span class="n">adjust</span><span class="p">))</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>In the non-<code class="language-plaintext highlighter-rouge">SMALL</code> case, we shift twice as before, but in the <code class="language-plaintext highlighter-rouge">SMALL</code> case, we need to get the high byte of the <code class="language-plaintext highlighter-rouge">len</code> field, so we need to shift down by an additional <code class="language-plaintext highlighter-rouge">usize::BITS - 8</code>. No matter what we’ve scribbled on the low bytes of <code class="language-plaintext highlighter-rouge">len</code>, we will always get just the length this way.</p> <p>We also need to use a different pointer value depending on whether we’re in <code class="language-plaintext highlighter-rouge">SMALL</code> mode. This is why <code class="language-plaintext highlighter-rouge">as_slice</code> needs to take a reference argument, since the slice data may be <em>directly</em> in <code class="language-plaintext highlighter-rouge">self</code>!</p> <p>Also, <code class="language-plaintext highlighter-rouge">ptr</code> is a <code class="language-plaintext highlighter-rouge">MaybeUninit</code> now, which will become clear in the next code listing.</p> <p>We should also provide a way to construct small strings.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">const</span> <span class="n">SSO_LEN</span><span class="p">:</span> <span class="nb">usize</span> <span class="o">=</span> <span class="nn">size_of</span><span class="p">::</span><span class="o">&lt;</span><span class="nb">usize</span><span class="o">&gt;</span><span class="p">()</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>

<span class="k">impl</span> <span class="n">RawYarn</span> <span class="p">{</span>
  <span class="cd">/// Create a new small yarn. `data` must be valid for `len` bytes</span>
  <span class="cd">/// and `len` must be smaller than `SSO_LEN`.</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">from_small</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="o">*</span><span class="k">const</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">len</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">RawYarn</span> <span class="p">{</span>
    <span class="nd">debug_assert!</span><span class="p">(</span><span class="n">len</span> <span class="o">&lt;=</span> <span class="n">SSO_LEN</span><span class="p">);</span>

    <span class="c1">// Create a yarn with an uninitialized pointer value (!!)</span>
    <span class="c1">// and a length whose high byte is packed with `small` and</span>
    <span class="c1">// `len`.</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">yarn</span> <span class="o">=</span> <span class="n">RawYarn</span> <span class="p">{</span>
      <span class="n">ptr</span><span class="p">:</span> <span class="nn">MaybeUninit</span><span class="p">::</span><span class="nf">uninit</span><span class="p">(),</span>
      <span class="n">len</span><span class="p">:</span> <span class="p">(</span><span class="n">SMALL</span> <span class="k">as</span> <span class="nb">usize</span> <span class="o">&lt;&lt;</span> <span class="mi">6</span> <span class="p">|</span> <span class="n">len</span><span class="p">)</span>
          <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="nn">usize</span><span class="p">::</span><span class="n">BITS</span> <span class="o">-</span> <span class="mi">8</span><span class="p">),</span>
    <span class="p">};</span>

    <span class="c1">// Memcpy the data to the new yarn.</span>
    <span class="c1">// We write directly onto the `yarn` variable. We won't</span>
    <span class="c1">// overwrite the high-byte length because `len` will</span>
    <span class="c1">// never be &gt;= 16.</span>
    <span class="nn">ptr</span><span class="p">::</span><span class="nf">copy_nonoverlapping</span><span class="p">(</span>
      <span class="n">data</span><span class="p">,</span>
      <span class="o">&amp;</span><span class="k">mut</span> <span class="n">yarn</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="n">RawYarn</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">,</span>
      <span class="n">data</span><span class="p">,</span>
    <span class="p">);</span>

    <span class="n">yarn</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>The precise maximum size of an SSO string is a bit more subtle than what’s given above, but it captures the spirit. The <code class="language-plaintext highlighter-rouge">RawYarn::from_small</code> illustrates why the pointer value is hidden in a <code class="language-plaintext highlighter-rouge">MaybeUninit</code>: we’re above to overwrite it with garbage, and in that case it won’t be a pointer at all.</p> <p>We can update our public <code class="language-plaintext highlighter-rouge">Yarn</code> type to use the new small representation whenever possible.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">impl</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="n">Yarn</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="cd">/// Create a new yarn from borrowed data.</span>
  <span class="k">pub</span> <span class="k">fn</span> <span class="nf">borrowed</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="o">&amp;</span><span class="nv">'a</span> <span class="nb">str</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="k">Self</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">len</span> <span class="o">=</span> <span class="n">data</span><span class="nf">.len</span><span class="p">();</span>
    <span class="k">let</span> <span class="n">ptr</span> <span class="o">=</span> <span class="n">data</span><span class="nf">.as_ptr</span><span class="p">()</span><span class="nf">.cast_mut</span><span class="p">();</span>

    <span class="k">if</span> <span class="n">len</span> <span class="o">&lt;=</span> <span class="n">SSO_LEN</span> <span class="p">{</span>
      <span class="k">return</span> <span class="k">Self</span> <span class="p">{</span>
        <span class="n">raw</span><span class="p">:</span> <span class="k">unsafe</span> <span class="p">{</span> <span class="nn">RawYarn</span><span class="p">::</span><span class="nf">from_small</span><span class="p">(</span><span class="n">len</span><span class="p">,</span> <span class="n">ptr</span><span class="p">)</span> <span class="p">},</span>
        <span class="n">_ph</span><span class="p">:</span> <span class="n">PhantomData</span><span class="p">,</span>
      <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">Self</span> <span class="p">{</span>
      <span class="n">raw</span><span class="p">:</span> <span class="nn">RawYarn</span><span class="p">::</span><span class="nf">from_raw_parts</span><span class="p">(</span><span class="n">BORROWED</span><span class="p">,</span> <span class="n">len</span><span class="p">,</span> <span class="n">ptr</span><span class="p">),</span>
      <span class="n">_ph</span><span class="p">:</span> <span class="n">PhantomData</span><span class="p">,</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="cd">/// Create a new yarn from owned data.</span>
  <span class="k">pub</span> <span class="k">fn</span> <span class="nf">owned</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="nb">str</span><span class="o">&gt;</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="k">Self</span> <span class="p">{</span>
    <span class="k">if</span> <span class="n">data</span><span class="nf">.len</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">SSO_LEN</span> <span class="p">{</span>
      <span class="k">return</span> <span class="k">Self</span> <span class="p">{</span>
        <span class="n">raw</span><span class="p">:</span> <span class="k">unsafe</span> <span class="p">{</span> <span class="nn">RawYarn</span><span class="p">::</span><span class="nf">from_small</span><span class="p">(</span><span class="n">data</span><span class="nf">.len</span><span class="p">(),</span> <span class="n">data</span><span class="nf">.as_ptr</span><span class="p">())</span> <span class="p">},</span>
        <span class="n">_ph</span><span class="p">:</span> <span class="n">PhantomData</span><span class="p">,</span>
      <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">let</span> <span class="n">len</span> <span class="o">=</span> <span class="n">data</span><span class="nf">.len</span><span class="p">();</span>
    <span class="k">let</span> <span class="n">ptr</span> <span class="o">=</span> <span class="n">data</span><span class="nf">.as_ptr</span><span class="p">()</span><span class="nf">.cast_mut</span><span class="p">();</span>
    <span class="nn">mem</span><span class="p">::</span><span class="nf">forget</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>

    <span class="k">Self</span> <span class="p">{</span>
      <span class="n">raw</span><span class="p">:</span> <span class="nn">RawYarn</span><span class="p">::</span><span class="nf">from_raw_parts</span><span class="p">(</span><span class="n">HEAP</span><span class="p">,</span> <span class="n">len</span><span class="p">,</span> <span class="n">ptr</span><span class="p">),</span>
      <span class="n">_ph</span><span class="p">:</span> <span class="n">PhantomData</span><span class="p">,</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>It’s also possible to construct a <code class="language-plaintext highlighter-rouge">Yarn</code> directly from a character now, too!</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">impl</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="n">Yarn</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="cd">/// Create a new yarn from borrowed data.</span>
  <span class="k">pub</span> <span class="k">fn</span> <span class="nf">from_char</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="nb">char</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="k">Self</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">buf</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0u8</span><span class="p">;</span> <span class="mi">4</span><span class="p">];</span>
    <span class="k">let</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="nf">.encode_utf8</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">buf</span><span class="p">);</span>
    <span class="k">Self</span> <span class="p">{</span>
      <span class="n">raw</span><span class="p">:</span> <span class="k">unsafe</span> <span class="p">{</span> <span class="nn">RawYarn</span><span class="p">::</span><span class="nf">from_small</span><span class="p">(</span><span class="n">len</span><span class="p">,</span> <span class="n">ptr</span><span class="p">)</span> <span class="p">},</span>
      <span class="n">_ph</span><span class="p">:</span> <span class="n">PhantomData</span><span class="p">,</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>(Note that we do not need to update <code class="language-plaintext highlighter-rouge">Yarn::immortalize()</code>; why?)</p> <p>What we have now is a maybe-owned string that does not require an allocation for small strings. However, we still have an extra niche…</p> <h2 id="string-constants"><a href="#string-constants">String Constants</a></h2> <p>String constants in Rust are interesting, because we can actually detect them at compile-time<sup id="fnref:leaks" role="doc-noteref"><a href="#fn:leaks" class="footnote" rel="footnote">6</a></sup>.</p> <p>We can use the last remaining niche, 3, to represent data that came from a string constant, which means that it does not need to be boxed to be immortalized.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">const</span> <span class="n">STATIC</span><span class="p">:</span> <span class="nb">u8</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

<span class="k">impl</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="n">Yarn</span><span class="o">&lt;</span><span class="nv">'a</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="cd">/// Create a new yarn from borrowed data.</span>
  <span class="k">pub</span> <span class="k">fn</span> <span class="nf">from_static</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="o">&amp;</span><span class="k">'static</span> <span class="nb">str</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="k">Self</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">len</span> <span class="o">=</span> <span class="n">data</span><span class="nf">.len</span><span class="p">();</span>
    <span class="k">let</span> <span class="n">ptr</span> <span class="o">=</span> <span class="n">data</span><span class="nf">.as_ptr</span><span class="p">()</span><span class="nf">.cast_mut</span><span class="p">();</span>

    <span class="k">if</span> <span class="n">len</span> <span class="o">&lt;=</span> <span class="n">SSO_LEN</span> <span class="p">{</span>
      <span class="k">return</span> <span class="k">Self</span> <span class="p">{</span>
        <span class="n">raw</span><span class="p">:</span> <span class="k">unsafe</span> <span class="p">{</span> <span class="nn">RawYarn</span><span class="p">::</span><span class="nf">from_small</span><span class="p">(</span><span class="n">len</span><span class="p">,</span> <span class="n">ptr</span><span class="p">)</span> <span class="p">},</span>
        <span class="n">_ph</span><span class="p">:</span> <span class="n">PhantomData</span><span class="p">,</span>
      <span class="p">}</span>
    <span class="p">}</span>

    <span class="k">Self</span> <span class="p">{</span>
      <span class="n">raw</span><span class="p">:</span> <span class="nn">RawYarn</span><span class="p">::</span><span class="nf">from_raw_parts</span><span class="p">(</span><span class="n">STATIC</span><span class="p">,</span> <span class="n">len</span><span class="p">,</span> <span class="n">ptr</span><span class="p">),</span>
      <span class="n">_ph</span><span class="p">:</span> <span class="n">PhantomData</span><span class="p">,</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>This function is identical to <code class="language-plaintext highlighter-rouge">Yarn::borrowed</code>, except that <code class="language-plaintext highlighter-rouge">data</code> most now have a static lifetime, and we pass <code class="language-plaintext highlighter-rouge">STATIC</code> to <code class="language-plaintext highlighter-rouge">RawYarn::from_raw_parts()</code>.</p> <p>Because of how we’ve written all of the prior code, this does not require any special support in <code class="language-plaintext highlighter-rouge">Yarn::immortalize()</code> or in the low-level <code class="language-plaintext highlighter-rouge">RawYarn</code> code.</p> <p>The actual <code class="language-plaintext highlighter-rouge">byteyarn</code> library provides a <code class="language-plaintext highlighter-rouge">yarn!()</code> macro that has the same syntax as <code class="language-plaintext highlighter-rouge">format!()</code>. This is the primary way in which yarns are created. It is has been carefully written so that <code class="language-plaintext highlighter-rouge">yarn!("this is a literal")</code> always produces a <code class="language-plaintext highlighter-rouge">STATIC</code> string, rather than a heap-allocated string.</p> <h2 id="an-extra-niche-as-a-treat"><a href="#an-extra-niche-as-a-treat">An extra niche, as a treat?</a></h2> <p>Unfortunately, because of how we’ve written it, <code class="language-plaintext highlighter-rouge">Option&lt;Yarn&gt;</code> is 24 bytes, a whole word larger than a <code class="language-plaintext highlighter-rouge">Yarn</code>. However, there’s still a little gap where we can fit the <code class="language-plaintext highlighter-rouge">None</code> variant. It turns out that because of how we’ve chosen the discriminants, <code class="language-plaintext highlighter-rouge">len</code> is zero if and only if it is an empty <code class="language-plaintext highlighter-rouge">BORROWED</code> string. But this is not the only zero: if the high byte is <code class="language-plaintext highlighter-rouge">0x80</code>, this is an empty <code class="language-plaintext highlighter-rouge">SMALL</code> string. If we simply require that no other empty string is ever constructed (by marking <code class="language-plaintext highlighter-rouge">RawYarn::from_raw_parts()</code> as unsafe and specifying it should not be passed a length of zero), we can guarantee that <code class="language-plaintext highlighter-rouge">len</code> is <em>never</em> zero.</p> <p>Thus, we can update <code class="language-plaintext highlighter-rouge">len</code> to be a <code class="language-plaintext highlighter-rouge">NonZeroUsize</code>.</p> <div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">#[repr(C)]</span>
<span class="nd">#[derive(Copy,</span> <span class="nd">Clone)]</span>
<span class="k">struct</span> <span class="n">RawYarn</span> <span class="p">{</span>
  <span class="n">ptr</span><span class="p">:</span> <span class="n">MaybeUninit</span><span class="o">&lt;*</span><span class="k">mut</span> <span class="nb">u8</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">len</span><span class="p">:</span> <span class="n">NonZeroUsize</span><span class="p">,</span>  <span class="c1">// (!!)</span>
<span class="p">}</span>

<span class="k">impl</span> <span class="n">RawYarn</span> <span class="p">{</span>
  <span class="cd">/// Constructs a new RawYarn from raw components: a 2-bit kind,</span>
  <span class="cd">/// a *nonzero* length, and a pointer.</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">from_raw_parts</span><span class="p">(</span><span class="n">kind</span><span class="p">:</span> <span class="nb">u8</span><span class="p">,</span> <span class="n">len</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span> <span class="n">ptr</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="nd">debug_assert!</span><span class="p">(</span><span class="n">kind</span> <span class="o">!=</span> <span class="n">SMALL</span><span class="p">);</span>
    <span class="nd">debug_assert!</span><span class="p">(</span><span class="n">len</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">);</span>
    <span class="nd">assert!</span><span class="p">(</span><span class="n">len</span> <span class="o">&lt;=</span> <span class="nn">usize</span><span class="p">::</span><span class="n">MAX</span> <span class="o">/</span> <span class="mi">4</span><span class="p">,</span> <span class="s">"no way you have a string that big"</span><span class="p">);</span>

    <span class="n">RawYarn</span> <span class="p">{</span>
      <span class="n">ptr</span><span class="p">:</span> <span class="nn">MaybeUninit</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">ptr</span><span class="p">),</span>
      <span class="n">len</span><span class="p">:</span> <span class="nn">NonZeroUsize</span><span class="p">::</span><span class="nf">new_unchecked</span><span class="p">(</span>
        <span class="p">(</span><span class="n">kind</span> <span class="k">as</span> <span class="nb">usize</span> <span class="o">&amp;</span> <span class="mi">0b11</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="nn">usize</span><span class="p">::</span><span class="n">BITS</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="p">|</span> <span class="n">len</span><span class="p">),</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>This is a type especially known to the Rust compiler to have a niche bit-pattern of all zeros, which allows <code class="language-plaintext highlighter-rouge">Option&lt;Yarn&gt;</code> to be 16 bytes too. This also has the convenient property that the all zeros bit-pattern for <code class="language-plaintext highlighter-rouge">Option&lt;Yarn&gt;</code> is <code class="language-plaintext highlighter-rouge">None</code>.</p> <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2> <p>The <a href="https://docs.rs/byteyarn/latest/byteyarn/"><code class="language-plaintext highlighter-rouge">byteyarn</code></a> blurb describes what we’ve built:</p> <blockquote> <p>A <code class="language-plaintext highlighter-rouge">Yarn</code> is a highly optimized string type that provides a number of useful properties over <code class="language-plaintext highlighter-rouge">String</code>:</p> <ul> <li>Always two pointers wide, so it is always passed into and out of functions in registers.</li> <li>Small string optimization (SSO) up to 15 bytes on 64-bit architectures.</li> <li>Can be either an owned buffer or a borrowed buffer (like <code class="language-plaintext highlighter-rouge">Cow&lt;str&gt;</code>).</li> <li>Can be upcast to <code class="language-plaintext highlighter-rouge">'static</code> lifetime if it was constructed from a known-static string.</li> </ul> </blockquote> <p>There are, of course, some trade-offs. Not only do we need the assumptions we made originally to hold, but we also need to relatively care more about memory than cycle-count performance, since basic operations like reading the length of the string require more math (but no extra branching).</p> <p>The actual implementation of <code class="language-plaintext highlighter-rouge">Yarn</code> is a bit more complicated, partly to keep all of the low-level book-keeping in one place, and partly to offer an ergonomic API that makes <code class="language-plaintext highlighter-rouge">Yarn</code> into a mostly-drop-in replacement for <code class="language-plaintext highlighter-rouge">Box&lt;str&gt;</code>.</p> <p>I hope this peek under the hood has given you a new appreciation for what can be achieved by clever layout-hacking.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:size-classes" role="doc-endnote"> <p>Allocators rarely serve you memory with precisely the size you asked for. Instead, they will have some notion of a “size class” that allows them to use more efficient allocation techniques, <a href="https://mcyoung.xyz//2022/06/07/alkyne-gc">which I have written about</a>.</p> <p>As a result, if the size change in a <code class="language-plaintext highlighter-rouge">realloc()</code> would not change the size class, it becomes a no-op, especially if the allocator can take advantage of the current-size information Rust provides it. <a href="#fnref:size-classes" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:character" role="doc-endnote"> <p>Here and henceforth “character” means “32-bit Unicode scalar”. <a href="#fnref:character" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:isize" role="doc-endnote"> <p>Now, you might also point out that Rust and C do not allow an allocation whose size is larger than the pointer offset type (<code class="language-plaintext highlighter-rouge">isize</code> and <code class="language-plaintext highlighter-rouge">ptrdiff_t</code>, respectively). In practice this means that the high bit is <em>always</em> zero according to the language’s own rules.</p> <p>This is true, but we need to steal two bits, and I wanted to demonstrate that this is an extremely reasonable desire. 64-bit integers are so comically large. <a href="#fnref:isize" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:two-shifts" role="doc-endnote"> <p>Interestingly, LLVM will compile <code class="language-plaintext highlighter-rouge">(x &lt;&lt; 2) &gt;&gt; 2</code> to</p> <pre><code class="language-x86">movabs rax,0x3fffffffffffffff
and    rax,rdi
ret
</code></pre> <p>If we want to play the byte-for-byte game, this costs 14 bytes when encoded in the Intel variable-length encoding. You would think that two shifts would result in marginally smaller code, but no, since the input comes in in <code class="language-plaintext highlighter-rouge">rdi</code> and needs to wind up in <code class="language-plaintext highlighter-rouge">rax</code>.</p> <p>On RISC-V, though, it seems to decide that two shifts is in fact cheaper, and will even optimize <code class="language-plaintext highlighter-rouge">x &amp; 0x3fff_ffff_ffff_ffff</code> back into two shifts. <a href="#fnref:two-shifts" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:big-endian" role="doc-endnote"> <p>This only works on little endian. Thankfully all computers are little endian. <a href="#fnref:big-endian" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:leaks" role="doc-endnote"> <p>Technically, a <code class="language-plaintext highlighter-rouge">&amp;'static str</code> may also point to leaked memory. For our purposes, there is no essential difference. <a href="#fnref:leaks" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div> </div> </div> </div> <div class="pagination post-footer"> <span class="pagination-item newer">&lt; Prev</span> • <a class="pagination-item older" href="https://mcyoung.xyz/page2">Next &gt;</a> </div></div> <div class="sidebar show-if-mobile footer"> <div class="container sidebar-sticky"> <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA</a> • <a href="https://varz.mcyoung.xyz/">Site Analytics</a> <br> &copy; 2024 Miguel Young de la Sota </div> </div> </body> </html>