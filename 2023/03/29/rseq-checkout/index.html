<!DOCTYPE html> <html lang="en-us"> <head> <link href="http://gmpg.org/xfn/11" rel="profile"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta http-equiv="content-type" content="text/html; charset=utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1"> <title> Atomicless Concurrency &middot; mcyoung </title> <link rel="stylesheet" href="https://mcyoung.xyz/public/css/syntax.css"> <link rel="stylesheet" href="https://mcyoung.xyz/public/css/syntax-overrides.css"> <link rel="stylesheet" href="https://mcyoung.xyz/public/css/style.css"> <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn" crossorigin="anonymous"> <link rel="shortcut icon" href="https://mcyoung.xyz/public/favicon.ico"> <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml"> <script src="https://mcyoung.xyz/public/js/minimap.js"></script> <script data-goatcounter="https://mcy.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:title" content="Atomicless Concurrency &middot; mcyoung"> <meta name="twitter:image" content="https://mcyoung.xyz/og/rseq-checkout-8d9a8ee3888ce8c60c160aff130e7d6f1e18286e.png"> <meta property="og:title" content="Atomicless Concurrency &middot; mcyoung"> <meta property="og:type" content="object"> <meta property="og:image" content="https://mcyoung.xyz/og/rseq-checkout-8d9a8ee3888ce8c60c160aff130e7d6f1e18286e.png"> <meta property="og:height" content="630"> <meta property="og:width" content="1200"> <meta property="og:url" content="https://mcyoung.xyz/2023/03/29/rseq-checkout/"> </head> <body> <div class="sidebar"> <a href="https://mcyoung.xyz/"> <img src="https://mcyoung.xyz/public/avatar.png" alt="Yeah, I drew this. Check out my art blog." class="hide-if-mobile"/> </a> <div class="container sidebar-sticky"> <div class="sidebar-about"> <h1><a href="https://mcyoung.xyz/"> mcyoung </a></h1> <p class="lead hide-if-mobile">I'm Miguel. I write about compilers, performance, and silly computer things. I also draw Pokémon. </p> </div> <hr class="hide-if-mobile"/> <nav class="sidebar-nav"> <a class="sidebar-nav-item" href="https://mcyoung.xyz/">Home</a> • <a class="sidebar-nav-item" href="/about.html">About</a> • <a class="sidebar-nav-item" href="/posts.html">Posts</a> • <a class="sidebar-nav-item" href="/tags.html">Tags</a> </nav> <nav class="sidebar-nav"> <a class="sidebar-nav-item" href="https://art.mcyoung.xyz/">Art</a> • <a class="sidebar-nav-item" href="https://github.com/mcy">GH</a> • <a class="sidebar-nav-item" href="https://mcyoung.xyz/resume">Resumé</a> </nav> <br class="hide-if-mobile"/> <p class="hide-if-mobile">&copy; 2023 Miguel Young de la Sota <br/> <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA</a> • <a href="https://varz.mcyoung.xyz/">Site Analytics</a></p> </div> </div> <div class="content container"><div class="post"> <span class="post-meta"> <span> <a href="https://mcyoung.xyz/tags.html#dark-arts">#dark-arts</a> <a href="https://mcyoung.xyz/tags.html#assembly">#assembly</a> <a href="https://mcyoung.xyz/tags.html#concurrency">#concurrency</a> <a href="https://mcyoung.xyz/tags.html#rust">#rust</a> </span> <span> 2023-03-29 </span> </span> <h1 class="post-title"><a href="/2023/03/29/rseq-checkout/"> Atomicless Concurrency </a></h1> <p>Let’s say we’re building an allocator. Good allocators need to serve many threads simultaneously, and as such any lock they take is going to be highly contended. One way to work around this, pioneered by TCMalloc, is to have thread-local caches of blocks (hence, the “TC” - thread cached).</p> <p>Unfortunately threads can be ephemeral, so book-keeping needs to grow dynamically, and large, complex programs (like the Google Search ranking server) can have tens of thousands of threads, so per-thread cost can add up. Also, any time a thread context-switches and resumes, its CPU cache will contain different cache lines – likely the wrong ones. This is because either another thread doing something compeltely different executed on that CPU, or the switched thread <em>migrated</em> to execute on a different core.</p> <p>These days, instead of caching per-thread, TCMalloc uses <em>per-CPU</em> data. This means that book-keeping is fixed, and this is incredibly friendly to the CPU’s cache: in the steady-state, each piece of the data will only ever be read or written to by a single CPU. It also has the amazing property that <em>there are no atomic operations involved</em> in the fast path, because operations on per-CPU data, by definition, do not need to be synchronized with other cores.</p> <p>This post gives an overview of how to build a CPU-local data structure on modern Linux. The exposition will be for x86, but other than the small bits of assembly you need to write, the technique is architecture-independent.</p> <h2 id="the-kernel-primitive"><a href="#the-kernel-primitive">The Kernel Primitive</a></h2> <p>Concurrency primitives require cooperating with the kernel, which is responsible for global scheduling decisions on the system. However, making syscalls is quite expensive; to alieviate this, there has been a trend in Linux to use shared memory as a kernelspace/userspace communication channel.</p> <p><a href="https://en.wikipedia.org/wiki/Futex">Futexes</a> are the classic “cas-with-the-kernel” syscall (I’m assuming basic knowledge of atomic operations like cas in this article). In the happy path, we just need to cas on some memory to lock a futex, and only make a syscall if we need to go to sleep because of contention. The kernel will perform its own cas on this variable if necessary.</p> <p><em>Restartable sequences</em> are another such proto-primitive, which are used for per-CPUuprogramming. The relevant syscall for us, <code class="language-plaintext highlighter-rouge">rseq(2)</code>, was added in Linux 4.18. Its manpage reads</p> <blockquote> <p>A restartable sequence is a sequence of instructions guaranteed to be executed atomically with respect to other threads and signal handlers on the current CPU. If its execution does not complete atomically, the kernel changes the execution flow by jumping to an abort handler defined by userspace for that restartable sequence.</p> </blockquote> <p>A restartable sequence, or “rseq” is a special kind of critical section that the kernel guarantees executes from start to finish without any kind of preemption. If preemption <em>does</em> happen (because of a signal or whatever), userspace observes this as a jump to a special handler for that critical section. Conceptually it’s like handling an exception:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="k">try</span> <span class="p">{</span>
  <span class="c1">// Per-CPU code here.</span>
<span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">PremptionException</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// Handle having been preempted, which usally just means</span>
  <span class="c1">// "try again".</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">C++</div></div></div> <p>These critical sections are usually of the following form:</p> <ol> <li>Read the current CPU index (the rseq mechanism provides a way to do this).</li> <li>Index into some data structure and do something to it.</li> <li>Complete the operation with a single memory write. This is the “commit”.</li> </ol> <p>All the kernel tells us is that we couldn’t finish successfully. We can always try again, but the critical section needs to be such that executing any prefix of it, up to the commit, has no effect on the data structure. We get no opportunity to perform “partial rollbacks”.</p> <p>In other words, the critical section must be a <em>transaction</em>.</p> <h3 id="enabling-rseq"><a href="#enabling-rseq">Enabling <code class="language-plaintext highlighter-rouge">rseq</code></a></h3> <p>Using rseqs requires turning on support for it for a particular thread; this is what calling <code class="language-plaintext highlighter-rouge">rseq(2)</code> (the syscall) accomplishes.</p> <p>The signature for this syscall looks like this:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="c1">// This type is part of Linux's ABI.</span>
<span class="nd">#[repr(C,</span> <span class="nd">align(</span><span class="mi">32</span><span class="nd">))]</span>
<span class="k">struct</span> <span class="n">Rseq</span> <span class="p">{</span>
  <span class="n">cpu_id_start</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span>
  <span class="n">cpu_id</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span>
  <span class="n">crit_sec</span><span class="p">:</span> <span class="nb">u64</span><span class="p">,</span>
  <span class="n">flags</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1">// Note: this is a syscall, not an actual Rust function.</span>
<span class="k">fn</span> <span class="nf">rseq</span><span class="p">(</span><span class="n">rseq</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Rseq</span><span class="p">,</span> <span class="n">len</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span> <span class="n">flags</span><span class="p">:</span> <span class="nb">i32</span><span class="p">,</span> <span class="n">signature</span><span class="p">:</span> <span class="nb">u32</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">i32</span><span class="p">;</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>The syscall registers “the” <code class="language-plaintext highlighter-rouge">Rseq</code> struct for the current thread; there can be at most one, per thread.</p> <p><code class="language-plaintext highlighter-rouge">rseq</code> is a pointer to this struct. <code class="language-plaintext highlighter-rouge">len</code> should be <code class="language-plaintext highlighter-rouge">size_of::&lt;Rseq&gt;()</code>, and <code class="language-plaintext highlighter-rouge">signature</code> can be any 32-bit integer (more on this later). For our purposes, we can ignore <code class="language-plaintext highlighter-rouge">flags</code> on the struct.</p> <p><code class="language-plaintext highlighter-rouge">flags</code> on the syscall, on the other hand, is used to indicate whether we’re unregistering the struct; this is explained below.</p> <p>In the interest of exposition, we’ll call the syscall directly. If you’ve never seen how a Linux syscall is done (on x86), you load the syscall number into <code class="language-plaintext highlighter-rouge">rax</code>, then up to six arguments in <code class="language-plaintext highlighter-rouge">rdi</code>, <code class="language-plaintext highlighter-rouge">rsi</code>, <code class="language-plaintext highlighter-rouge">rdx</code>, <code class="language-plaintext highlighter-rouge">r10</code>, <code class="language-plaintext highlighter-rouge">r8</code>, <code class="language-plaintext highlighter-rouge">r9</code><sup id="fnref:mnemonic" role="doc-noteref"><a href="#fn:mnemonic" class="footnote" rel="footnote">1</a></sup>. We only need the first four.</p> <p>The return value comes out in <code class="language-plaintext highlighter-rouge">rax</code>, which is 0 on success, and a negative of an <code class="language-plaintext highlighter-rouge">errno</code> code otherwise. In particular, we need to check for <code class="language-plaintext highlighter-rouge">EINTR</code> to deal with syscall interruption. (every Linux syscall can be interrupted).</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">raw_rseq</span><span class="p">(</span><span class="n">rseq</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Rseq</span><span class="p">,</span> <span class="n">unregister</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">signature</span><span class="p">:</span> <span class="nb">u32</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// Perform an open-coded Linux syscall.</span>
  <span class="k">loop</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">rax</span> <span class="o">=</span> <span class="mi">334</span><span class="p">;</span>  <span class="c1">// rseq(2) syscall number; x86-specific.</span>
    <span class="nd">asm!</span> <span class="p">{</span>
      <span class="s">"syscall"</span><span class="p">,</span>
      <span class="nf">inout</span><span class="p">(</span><span class="s">"rax"</span><span class="p">)</span> <span class="n">rax</span><span class="p">,</span>
      <span class="cm">/* rseq:      */</span> <span class="k">in</span><span class="p">(</span><span class="s">"rdi"</span><span class="p">)</span> <span class="n">rseq</span><span class="p">,</span>
      <span class="cm">/* len:       */</span> <span class="k">in</span><span class="p">(</span><span class="s">"rsi"</span><span class="p">)</span> <span class="nn">mem</span><span class="p">::</span><span class="nn">size_of</span><span class="p">::</span><span class="o">&lt;</span><span class="n">Rseq</span><span class="o">&gt;</span><span class="p">(),</span>
      <span class="cm">/* flags:     */</span> <span class="k">in</span><span class="p">(</span><span class="s">"rdx"</span><span class="p">)</span> <span class="n">unregister</span> <span class="k">as</span> <span class="nb">u64</span><span class="p">,</span>
      <span class="cm">/* signature: */</span> <span class="k">in</span><span class="p">(</span><span class="s">"r10"</span><span class="p">)</span> <span class="n">signature</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">match</span> <span class="n">rax</span> <span class="p">{</span>
      <span class="mi">0</span> <span class="k">=&gt;</span> <span class="k">break</span><span class="p">,</span>      <span class="c1">// Success, we're done.</span>
      <span class="o">-</span><span class="mi">4</span> <span class="k">=&gt;</span> <span class="k">continue</span><span class="p">,</span>  <span class="c1">// EINTR, try again.</span>
      <span class="n">errno</span> <span class="k">=&gt;</span> <span class="nd">panic!</span><span class="p">(</span><span class="s">"error calling rseq(2): {}"</span><span class="p">,</span> <span class="o">-</span><span class="n">errno</span><span class="p">),</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Note the <code class="language-plaintext highlighter-rouge">unregister</code> parameter: this is used to tear down <code class="language-plaintext highlighter-rouge">rseq</code> support on the way out of a thread. Generally, <code class="language-plaintext highlighter-rouge">rseq</code> will be a thread-local, and registration happens at thread startup. Glibc will do this and has a mechanism for acquiring the <code class="language-plaintext highlighter-rouge">rseq</code> pointer. Unfortunately, the glibc I have isn’t new enough to know to do this, so I hacked up something to register my own thread local.</p> <p>I had the bright idea of putting my <code class="language-plaintext highlighter-rouge">Rseq</code> struct in a box, which triggered an interesting bug: when a thread exits, it destroys all of the thread local variables, including the box to hold our <code class="language-plaintext highlighter-rouge">Rseq</code>. But if the thread then syscalls to deallocate its stack, when the kernel goes to resume, it will attempt to write the current CPU index to the <code class="language-plaintext highlighter-rouge">rseq.cpu_id</code> field.</p> <p>This presents a problem, because the kernel is probably going to write to a garbage location. This is all but guaranteed to result in a segfault. Debuggers observe this as a segfault on the instruction right after the <code class="language-plaintext highlighter-rouge">syscall</code> instruction; I spent half an hour trying to figure out what was causing a call to <code class="language-plaintext highlighter-rouge">madvise(2)</code> to segfault.</p> <p>Hence, we need to wrap our thread local in something that will call <code class="language-plaintext highlighter-rouge">rseq(2)</code> to unregister the struct. Putting everything together we get something like this.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">fn</span> <span class="nf">current_thread_rseq</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Rseq</span> <span class="p">{</span>
  <span class="c1">// This has to be its own struct so we can run a thread-exit destructor.</span>
  <span class="k">pub</span> <span class="k">struct</span> <span class="nf">RseqBox</span><span class="p">(</span><span class="nb">Box</span><span class="o">&lt;</span><span class="n">UnsafeCell</span><span class="o">&lt;</span><span class="n">Rseq</span><span class="o">&gt;&gt;</span><span class="p">);</span>
  <span class="k">impl</span> <span class="nb">Drop</span> <span class="k">for</span> <span class="n">RseqBox</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">drop</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">unsafe</span> <span class="p">{</span> <span class="nf">raw_rseq</span><span class="p">(</span><span class="k">self</span><span class="na">.0</span><span class="nf">.get</span><span class="p">(),</span> <span class="k">true</span><span class="p">,</span> <span class="n">RSEQ_SIG</span><span class="p">);</span> <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="nd">thread_local!</span> <span class="p">{</span>
    <span class="k">static</span> <span class="n">RSEQ</span><span class="p">:</span> <span class="n">RseqBox</span> <span class="o">=</span> <span class="p">{</span>
      <span class="c1">// Has to be in a box, since we need pointer stability.</span>
      <span class="k">let</span> <span class="n">rseq</span> <span class="o">=</span> <span class="nf">RseqBox</span><span class="p">(</span><span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nn">UnsafeCell</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">Rseq</span> <span class="p">{</span>
        <span class="n">cpu_id_start</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">cpu_id</span><span class="p">:</span> <span class="o">!</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">crit_sec</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">flags</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
      <span class="p">})));</span>

      <span class="c1">// Register it!!!</span>
      <span class="k">unsafe</span> <span class="p">{</span> <span class="nf">raw_rseq</span><span class="p">(</span><span class="n">rseq</span><span class="na">.0</span><span class="nf">.get</span><span class="p">(),</span> <span class="kc">false</span><span class="p">,</span> <span class="n">RSEQ_SIG</span><span class="p">);</span> <span class="p">}</span>
      <span class="n">rseq</span>
    <span class="p">};</span>
  <span class="p">}</span>

  <span class="n">RSEQ</span><span class="nf">.with</span><span class="p">(|</span><span class="n">ra</span><span class="p">|</span> <span class="n">ra</span><span class="na">.0</span><span class="nf">.get</span><span class="p">())</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Per Rust’s semantics, this will execute the first time we access this thread local, instead of at thread startup. Not <em>ideal</em>, since now we pay for an (uncontended) atomic read every time we touch RSEQ, but it will do.</p> <h3 id="creating-a-critical-section"><a href="#creating-a-critical-section">Creating a Critical Section</a></h3> <p>To set up and execute a restartable sequence, we need to assemble a struct that describes it. The following struct is also defined by Linux’s syscall ABI:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="nd">#[repr(C,</span> <span class="nd">align(</span><span class="mi">32</span><span class="nd">))]</span>
<span class="k">struct</span> <span class="n">CritSec</span> <span class="p">{</span>
  <span class="n">version</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span>
  <span class="n">flags</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span>
  <span class="n">start</span><span class="p">:</span> <span class="nb">u64</span><span class="p">,</span>
  <span class="n">len</span><span class="p">:</span> <span class="nb">u64</span><span class="p">,</span>
  <span class="n">abort_handler</span><span class="p">:</span> <span class="nb">u64</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p><code class="language-plaintext highlighter-rouge">start</code> is the address of the first instruction in the sequence, and <code class="language-plaintext highlighter-rouge">len</code> is the length of the sequence in bytes. <code class="language-plaintext highlighter-rouge">abort_handler</code> is the address of the abort handler. <code class="language-plaintext highlighter-rouge">version</code> must be 0 and we can ignore <code class="language-plaintext highlighter-rouge">flags</code>.</p> <p>Once we have a value of this struct (on the stack or as a constant), we grab <code class="language-plaintext highlighter-rouge">RSEQ</code> and atomically store the address of our <code class="language-plaintext highlighter-rouge">CritSec</code> to <code class="language-plaintext highlighter-rouge">RSEQ.crit_sec</code>. This needs to be atomic because the kernel may decide to look at this pointer from a different CPU core, but it likely will not be contended.</p> <p>Note that <code class="language-plaintext highlighter-rouge">RSEQ.crit_sec</code> should be null before we do this; restartable sequences can’t nest.</p> <p>Next time the kernel preempts our thread (and later gets ready to resume it), it will look at <code class="language-plaintext highlighter-rouge">RSEQ.crit_sec</code> to decide if it preempted a restartable sequence and, if so, jump to the abort handler.</p> <p>Once we finish our critical section, we must reset <code class="language-plaintext highlighter-rouge">RSEQ.crit_sec</code> to 0.</p> <blockquote> <h4 id="labels-and-constants-oh-my"><a href="#labels-and-constants-oh-my">Labels and Constants, Oh My</a></h4> <p>There is a wrinkle: we would like for our <code class="language-plaintext highlighter-rouge">CritSec</code> value to be a constant, but Rust doesn’t provide us with a way to initialize the <code class="language-plaintext highlighter-rouge">start</code> and <code class="language-plaintext highlighter-rouge">abort_handler</code> fields directly, since it doesn’t have a way to refer<sup id="fnref:relocations" role="doc-noteref"><a href="#fn:relocations" class="footnote" rel="footnote">2</a></sup> to the labels (jump targets) inside the inline assembly. The simplest way to get around this is to assemble (lol) the <code class="language-plaintext highlighter-rouge">CritSec</code> on the stack, with inline assembly. The overhead is quite minimal.</p> </blockquote> <p>On x86, this is what our boilerplate will look like:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">let</span> <span class="k">mut</span> <span class="n">cs</span> <span class="o">=</span> <span class="nn">MaybeUninit</span><span class="p">::</span><span class="o">&lt;</span><span class="n">CritSec</span><span class="o">&gt;</span><span class="p">::</span><span class="nf">uninit</span><span class="p">();</span>
<span class="k">let</span> <span class="k">mut</span> <span class="n">ok</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="nd">asm!</span> <span class="p">{</span><span class="s">r"
  // We meed to do `rip`-relative loads so that this code is PIC;
  // otherwise we'll get linker errors. Thus, we can't `mov`
  // directly; we need to compute the address with a `lea`
  // first.

  // Initialize the first two fields to zero.
  mov qword ptr [{_cs}], 0

  // Load `90f` into `cs.start`. Note that this is 'forward
  // reference' to the jump target `90:` below.
  lea {_pc}, [90f + rip]
  mov qword ptr [{_cs} + 8], {_pc}

  // We need to get the difference `91f - 90f` into `cs.len`.
  // To do that, we write `-90f` to it, and then add `91f`.
  neg {_pc}
  mov qword ptr [{_cs} + 16], {_pc}
  lea {_pc}, [91f + rip]
  add qword ptr [{_cs} + 16], {_pc}

  // Same as the first line, but loading `cs.abort_handler`.
  lea {_pc}, [92f + rip]
  mov qword ptr [{_cs} + 24], {_pc}

  // Write `&amp;cs` to `RSEQ.crit_sec`. This turns on
  // restartable sequence handling.
  mov qword ptr [{rseq} + 8], {_cs}

90:
  // Do something cool here (coming soon).

91:
  // Jump over the abort handler.
  jmp 93f

  .int 0x53053053  // The signature!
92:
  // Nothing special, just zero `ok` to indicate this was a failure.
  // This is written this way simply because we can't early-return
  // out of inline assembly.
  xor {_ok:e}, {_ok:e}

93:
  // Clear `RSEQ.crit_sec`, regardless of which exit path
  // we took.
  mov qword ptr [{rseq} + 8], 0
  "</span><span class="p">,</span>
  <span class="n">_pc</span> <span class="o">=</span> <span class="nf">out</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="n">_</span><span class="p">,</span>
  <span class="n">_ok</span> <span class="o">=</span> <span class="nf">inout</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="n">ok</span><span class="p">,</span>
  <span class="n">_cs</span> <span class="o">=</span> <span class="k">in</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">cs</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="n">CritSec</span><span class="p">,</span>
  <span class="n">rseq</span> <span class="o">=</span> <span class="k">in</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="nf">current_thread_rseq</span><span class="p">(),</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>A few things to note:</p> <ol> <li>Because this is inline assembly, we need to use numeric labels. I’ve chosen labels in the 90s for no particular reason. <code class="language-plaintext highlighter-rouge">90:</code> declares a jump target, and <code class="language-plaintext highlighter-rouge">90f</code> is a forward reference to that instruction address.</li> <li>Most of this assembly is just initalizing a struct<sup id="fnref:cs-init" role="doc-noteref"><a href="#fn:cs-init" class="footnote" rel="footnote">3</a></sup>. It’s not until the <code class="language-plaintext highlighter-rouge">mov</code> right before <code class="language-plaintext highlighter-rouge">90:</code> (the critical section start) that anything interesting happens.</li> <li>Immediately before <code class="language-plaintext highlighter-rouge">92:</code> (the abort handler) is an <code class="language-plaintext highlighter-rouge">.int</code> directive that emits the same four-byte signature we passed to <code class="language-plaintext highlighter-rouge">rseq(2)</code> into the instruction stream. This <em>must</em> be here, otherwise the kernel will issue a segfault to the thread. This is a very basic control-flow integrity feature.</li> <li>We clear <code class="language-plaintext highlighter-rouge">RSEQ.crit_sec</code> at the very end.</li> </ol> <p>This is a lot of boilerplate. In an ideal world, we could have something like the following:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">fn</span> <span class="nf">run_rseq</span><span class="p">(</span><span class="n">cs</span><span class="p">:</span> <span class="k">extern</span> <span class="s">"C"</span> <span class="k">unsafe</span> <span class="k">fn</span><span class="p">(</span><span class="nb">u32</span><span class="p">));</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Unfortunately, this is very hard to do, because the constraints on restartable sequences are draconian:</p> <ul> <li>Can’t jump out of the critical section until it completes or aborts. This means you can’t call functions or make syscalls!</li> <li>Last instruction must be the commit, which is a memory store operation, <em>not</em> a return.</li> </ul> <p>This means that you can’t have the compiler generating code for you; it might outline things or move things around in ways you don’t want. In something like ASAN mode, it might inject function calls that will completely break the primitive.</p> <p>This means we muyst write our critical section in assembly. That assembly also almost unavoidably needs to be part of the boilerplate given above, and it means it can’t participate in ASAN or TSAN instrumentation.</p> <p>In the interest of exposition, we can build a wrapper over this inline assembly boilerplate that looks something like this:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">let</span> <span class="n">result</span><span class="p">:</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">(),</span> <span class="n">RseqAbort</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nd">rseq!</span> <span class="p">{</span><span class="s">r"
    // Assembly for our critical section...
  "</span><span class="p">,</span>
  <span class="c1">// Inline asm constraints.</span>
<span class="p">};</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>When I wrote the snippet above, I chose numeric labels in the 90s to avoid potential conflicts with whatever assembly gets pasted here. This is also why I used a leading <code class="language-plaintext highlighter-rouge">_</code> on the names of some of the assembly constraints; thise are private to the macro. <code class="language-plaintext highlighter-rouge">rseq</code> isn’t, though, since callers will want to access the CPU id in it.</p> <p>The intent is for the assembly string to be pasted over the <code class="language-plaintext highlighter-rouge">// Do something cool here</code> comment, and for the constraints to be tacked on after the boilerplate’s constraints.</p> <p>But with that we now have access to the full rseq primitive, in slightly sketchy macro form. Let’s use it to build a CPU-local data structure.</p> <h2 id="a-checkout-desk"><a href="#a-checkout-desk">A Checkout Desk</a></h2> <p>Let’s say we have a pool of objects that are needed to perform an allocation, our putative page caches. Let’s say we have the following interface:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">impl</span> <span class="n">FreeList</span> <span class="p">{</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">get_cache</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="n">PageCache</span><span class="p">;</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">return_cache</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">,</span> <span class="o">*</span><span class="k">mut</span> <span class="n">PageCache</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p><code class="language-plaintext highlighter-rouge">get_cache()</code> grabs a cache of pages off the global free list. This requires taking a lock or traversing a lockless linked list, so it’s pretty expensive. <code class="language-plaintext highlighter-rouge">return_cache()</code> returns a cache back to the global free list for re-use; it is a similarly expensive operation. Both of these operations are going to be contended like crazy, so we want to memoize them.</p> <p>To achieve this, we want one slot for every CPU to hold the cache it (or rather, a thread running on it) most recently acquired, so that it can be reused. These slots will have “checkout desk” semantics: if you take a thing, you must put something in its place, even if it’s just a sign that says you took the thing.</p> <figure> <p><img src="https://mcyoung.xyz/public/golden-idol.gif" alt=""/></p> </figure> <p><a href="https://fowles.github.io/">Matthew Kulukundis</a> came up with this idea, and he’d totally put this gif in a slide deck about this data structure.</p> <p>As a function signature, this is what it looks like:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="k">fn</span> <span class="nf">checkout</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">,</span> <span class="n">replacement</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">T</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="n">T</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>We can then use it like this.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">let</span> <span class="n">free_list</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">FreeList</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="k">let</span> <span class="n">per_cpu</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">PageCache</span><span class="o">&gt;</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="k">let</span> <span class="n">iou</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="n">PageCache</span><span class="p">;</span>

<span class="c1">// Check out this CPU's cache pointer, and replace it with</span>
<span class="c1">// an IOU note (a null pointer).</span>
<span class="k">let</span> <span class="k">mut</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">per_cpu</span><span class="nf">.checkout</span><span class="p">(</span><span class="n">iou</span><span class="p">);</span>
<span class="k">if</span> <span class="n">cache</span> <span class="o">==</span> <span class="n">iou</span> <span class="p">{</span>
  <span class="c1">// If we got an IOU ourselves, this means another thread that</span>
  <span class="c1">// was executing on this CPU took the cache and left *us* with</span>
  <span class="c1">// a null, so we need to perform the super-expensive operation</span>
  <span class="c1">// to acquire a new one.</span>
  <span class="n">cache</span> <span class="o">=</span> <span class="n">free_list</span><span class="nf">.get_cache</span><span class="p">();</span>
<span class="p">}</span>

<span class="c1">// Do stuff with `cache` here. We have unique access to it.</span>
<span class="n">cache</span><span class="nf">.alloc_page</span><span class="p">(</span><span class="o">...</span><span class="p">);</span>

<span class="c1">// Return the pointer to the checkout desk.</span>
<span class="n">cache</span> <span class="o">=</span> <span class="n">per_cpu</span><span class="nf">.checkout</span><span class="p">(</span><span class="n">cache</span><span class="p">);</span>
<span class="k">if</span> <span class="n">cache</span> <span class="o">!=</span> <span class="n">iou</span> <span class="p">{</span>
  <span class="c1">// Usually, we expect to get back the IOU we put into the cache.</span>
  <span class="c1">// If we don't, that probably means another thread (or</span>
  <span class="c1">// hundreds) are hammering this slot and fighting for page caches.</span>
  <span class="c1">// If this happens, we need to throw away the cache.</span>
  <span class="n">free_list</span><span class="nf">.return_cache</span><span class="p">(</span><span class="n">cache</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>The semantics of <code class="language-plaintext highlighter-rouge">PerCpu&lt;T&gt;</code> is that it is an array of <code class="language-plaintext highlighter-rouge">nprocs</code> (the number of logical cores on the system) pointers, all initialized to null. <code class="language-plaintext highlighter-rouge">checkout()</code> swaps the pointer stored in the current CPU’s slot in the <code class="language-plaintext highlighter-rouge">PerCpu&lt;T&gt;</code> with the replacement argument.</p> <h3 id="building-the-checkout-desk"><a href="#building-the-checkout-desk">Building the Checkout Desk</a></h3> <p>The implementation of this type is relatively simple, but the devil is in the details. Naively, you’d think you literally want an array of pointers:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">pub</span> <span class="k">struct</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="n">ptrs</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="p">[</span><span class="o">*</span><span class="k">mut</span> <span class="n">T</span><span class="p">]</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">unsafe</span> <span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="nb">Send</span> <span class="k">for</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{}</span>
<span class="k">unsafe</span> <span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="nb">Sync</span> <span class="k">for</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Unfortunately, this is cache-hostile. We expect that (depending on how <code class="language-plaintext highlighter-rouge">ptrs</code> is aligned in memory) for eight CPUs’ checkout pointers to be on the same cache line. This means eight separate cores are going to be writing to the same cache line, which is going to result in a lot of cache thrash. This memory wants to be in L1 cache, but will probably wind up mostly in shared L3 cache.</p> <p>This effect is called “false sharing”, and is a fundamental part of the design of modern processors. We have to adjust for this.</p> <p>Instead, we want to give each core a full cache line (64 bytes aligned to a 64-byte boundary) for it to store its pointer in. This sounds super wasteful (56 of those bytes will go unused), but this is the right call for a perf-sensitive primitive.</p> <p>This amount of memory can add up pretty fast (two whole pages of memory for a 128-core server!), so we’ll want to lazilly initialize them. Our cache-friendly struct will look more like this:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">pub</span> <span class="k">struct</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="n">ptrs</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="p">[</span><span class="n">AtomicPtr</span><span class="o">&lt;</span><span class="n">CacheLine</span><span class="o">&lt;*</span><span class="k">mut</span> <span class="n">T</span><span class="o">&gt;&gt;</span><span class="p">]</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1">// This struct wraps a T and forces it to take up an entire cache line.</span>
<span class="nd">#[repr(C,</span> <span class="nd">align(</span><span class="mi">64</span><span class="nd">))]</span>
<span class="k">struct</span> <span class="n">CacheLine</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">T</span><span class="p">);</span>

<span class="k">unsafe</span> <span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="nb">Send</span> <span class="k">for</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{}</span>
<span class="k">unsafe</span> <span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="nb">Sync</span> <span class="k">for</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Initializing it requires finding out how many cores there are on the machine. This is a… fairly platform-specific affair. Rust <em>does</em> offer a “maximum paralellism” query in its standard library, but it is intended as a hint for how many worker threads to spawn, as opposed to a hard upper bound on the number of CPU indices.</p> <p>Instead, we call <code class="language-plaintext highlighter-rouge">get_nprocs_conf()</code>, which is fine since we’re already extremely non-portable already. This is a GNU libc extension.</p> <p>In code…</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="k">pub</span> <span class="k">fn</span> <span class="nf">new</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="k">Self</span> <span class="p">{</span>
    <span class="k">extern</span> <span class="s">"C"</span> <span class="p">{</span>
      <span class="c1">// #include &lt;sys/sysinfo.h&gt;</span>
      <span class="c1">//</span>
      <span class="c1">// This function returns the maximum number of cores the</span>
      <span class="c1">// kernel knows of for the current machine. This function</span>
      <span class="c1">// is very expensive to call, so we need to cache it.</span>
      <span class="k">fn</span> <span class="nf">get_nprocs_conf</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="nb">i32</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">static</span> <span class="k">mut</span> <span class="n">NPROCS</span><span class="p">:</span> <span class="nb">usize</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">static</span> <span class="n">INIT</span><span class="p">:</span> <span class="n">Once</span> <span class="o">=</span> <span class="nn">Once</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>
    <span class="n">INIT</span><span class="nf">.call_once</span><span class="p">(||</span> <span class="k">unsafe</span> <span class="p">{</span>
      <span class="n">NPROCS</span> <span class="o">=</span> <span class="nf">get_nprocs_conf</span><span class="p">()</span> <span class="k">as</span> <span class="nb">usize</span><span class="p">;</span>
    <span class="p">});</span>

    <span class="k">let</span> <span class="n">len</span> <span class="o">=</span> <span class="k">unsafe</span> <span class="p">{</span> <span class="n">NPROCS</span> <span class="p">};</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">ptrs</span> <span class="o">=</span> <span class="nn">Vec</span><span class="p">::</span><span class="nf">with_capacity</span><span class="p">(</span><span class="n">len</span><span class="p">);</span>
    <span class="k">for</span> <span class="n">_</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="n">len</span> <span class="p">{</span>
      <span class="n">ptrs</span><span class="nf">.push</span><span class="p">(</span><span class="nn">AtomicPtr</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">()));</span>
    <span class="p">}</span>

    <span class="k">Self</span> <span class="p">{</span> <span class="n">ptrs</span><span class="p">:</span> <span class="n">ptrs</span><span class="nf">.into_boxed_slice</span><span class="p">()</span> <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>(I’m not going to implement <code class="language-plaintext highlighter-rouge">Drop</code> for this type. That’s an exercise for the reader.)</p> <h3 id="implementing-checkout"><a href="#implementing-checkout">Implementing <code class="language-plaintext highlighter-rouge">checkout()</code></a></h3> <p>Now’s the moment we’ve all be waiting for: writing our restartable sequence. As critical sections go, this one’s pretty simple:</p> <ol> <li>Index into the <code class="language-plaintext highlighter-rouge">ptrs</code> array to get this CPU’s pointer-to-cache-line.</li> <li>If that pointer is null, bail out of the rseq and initialize a fresh cache line (and then try again).</li> <li>If it’s not null, swap <code class="language-plaintext highlighter-rouge">replacement</code> with the value in the cache line.</li> </ol> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="k">fn</span> <span class="nf">checkout</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">,</span> <span class="k">mut</span> <span class="n">replacement</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">T</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="n">T</span> <span class="p">{</span>
    <span class="c1">// We need to try this operation in a loop, to deal with</span>
    <span class="c1">// rseq aborts.</span>
    <span class="k">loop</span> <span class="p">{</span>
      <span class="k">let</span> <span class="n">ptrs</span> <span class="o">=</span> <span class="k">self</span><span class="py">.ptrs</span><span class="nf">.as_ptr</span><span class="p">();</span>
      <span class="k">let</span> <span class="k">mut</span> <span class="n">vcpu</span><span class="p">:</span> <span class="nb">i32</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
      <span class="k">let</span> <span class="k">mut</span> <span class="n">need_alloc</span><span class="p">:</span> <span class="nb">i32</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
      <span class="k">let</span> <span class="n">result</span><span class="p">:</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">(),</span> <span class="n">RseqAbort</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nd">rseq!</span> <span class="p">{</span><span class="s">r"
        // Load the current CPU number.
        mov {vcpu:e}, dword ptr [{rseq} + 4]

        // Load the `vcpu`th pointer from `ptrs`.
        // On x86, `mov` is atomic. The only threads we might
        // be condending with are those that are trying to
        // initialize this pointer if it's null.
        mov {scratch}, qword ptr [{ptrs} + 8 * {vcpu:r}]

        // If null, exit early and trigger an allocation
        // for this vcpu.
        test {scratch}, {scratch}
        jz 1f

        // Make sure the outer code knows not to allocate
        // a new cache line.
        xor {need_alloc:e}, {need_alloc:e}

        // Commit the checkout by exchanging `replacement`.
        xchg {ptr}, qword ptr [{scratch}]
      1:
        "</span><span class="p">,</span>
        <span class="n">ptrs</span> <span class="o">=</span> <span class="k">in</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="n">ptrs</span><span class="p">,</span>
        <span class="n">scratch</span> <span class="o">=</span> <span class="nf">out</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="n">_</span><span class="p">,</span>
        <span class="n">ptr</span> <span class="o">=</span> <span class="nf">inout</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="n">replacement</span><span class="p">,</span>
        <span class="n">vcpu</span> <span class="o">=</span> <span class="nf">out</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="n">vcpu</span><span class="p">,</span>
        <span class="n">need_alloc</span> <span class="o">=</span> <span class="nf">inout</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="n">need_alloc</span><span class="p">,</span>
      <span class="p">};</span>

      <span class="c1">// We got preempted, so it's time to try again.</span>
      <span class="k">if</span> <span class="n">result</span><span class="nf">.is_err</span><span class="p">()</span> <span class="p">{</span> <span class="k">continue</span> <span class="p">}</span>

      <span class="c1">// If we don't need to allocate, we're done.</span>
      <span class="k">if</span> <span class="n">need_alloc</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span> <span class="k">return</span> <span class="n">replacement</span> <span class="p">}</span>

      <span class="c1">// Otherwise, allocate a new cache line and cas it into</span>
      <span class="c1">// place. This is Atomics 101, nothing fancy.</span>
      <span class="k">let</span> <span class="k">mut</span> <span class="n">cache_line</span> <span class="o">=</span> <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nf">CacheLine</span><span class="p">(</span><span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">()));</span>
      <span class="k">loop</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">cas</span> <span class="o">=</span> <span class="k">self</span><span class="py">.ptrs</span><span class="p">[</span><span class="n">vcpu</span> <span class="k">as</span> <span class="nb">usize</span><span class="p">]</span><span class="nf">.compare_exchange_weak</span><span class="p">(</span>
          <span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">(),</span> <span class="n">cache_line</span><span class="nf">.as_mut</span><span class="p">(),</span>
          <span class="nn">Ordering</span><span class="p">::</span><span class="n">AcqRel</span><span class="p">,</span> <span class="nn">Ordering</span><span class="p">::</span><span class="n">Relaxed</span><span class="p">,</span>
        <span class="p">);</span>

        <span class="k">match</span> <span class="n">cas</span> <span class="p">{</span>
          <span class="nf">Ok</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="p">{</span>
            <span class="c1">// Successful allocation.</span>
            <span class="nd">debug_assert!</span><span class="p">(</span><span class="n">p</span><span class="nf">.is_null</span><span class="p">());</span>
            <span class="c1">// Make sure to stop `cache_line`'s memory</span>
            <span class="c1">// from being freed by `Box`'s dtor.</span>
            <span class="nn">mem</span><span class="p">::</span><span class="nf">forget</span><span class="p">(</span><span class="n">cache_line</span><span class="p">);</span>
            <span class="k">break</span><span class="p">;</span>
          <span class="p">}</span>
          <span class="c1">// Try again: this is a spurious failure.</span>
          <span class="nf">Err</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">if</span> <span class="n">p</span><span class="nf">.is_null</span><span class="p">()</span> <span class="k">=&gt;</span> <span class="k">continue</span><span class="p">,</span>
          <span class="c1">// Someone got here first; we can just discard</span>
          <span class="c1">// `Box`.</span>
          <span class="nf">Err</span><span class="p">(</span><span class="n">_</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="k">break</span><span class="p">,</span>
        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>This code listing is a lot to take in. It can be broken into two parts: the restartable sequence itself, and the allocation fallback if the pointer-to-cache-line happens to be null.</p> <p>The restartable sequence is super short. It looks at the pointer-to-cache-line, bails if its null (this triggers the later part of the function) and then does an <code class="language-plaintext highlighter-rouge">xchg</code> between the actual <code class="language-plaintext highlighter-rouge">*mut T</code> in the per-CPU cache line, and the replacement.</p> <p>If the rseq aborts, we just try again. This is short enough that preemption in the middle of the rseq is quite rare. Then, if <code class="language-plaintext highlighter-rouge">need_alloc</code> was zeroed, that means we successfully committed, so we’re done.</p> <p>Otherwise we need to allocate a cache line for this CPU. We’re now outside of the rseq, so we’re back to needing atomics. Many threads might be racing to be the thread that initializes the pointer-to-cache-line; we use a basic cas loop to make sure that we only initialize from null, and if someone beats us to it, we don’t leak the memory we had just allocated. This is an RMW operation, so we want both acquire and release ordering. Atomics 101!</p> <p>Then, we try again. Odds are good we won’t have migrated CPUs when we execute again, so we won’t need to allocate again. Eventually all of the pointers in the <code class="language-plaintext highlighter-rouge">ptrs</code> array will be non-null, so in the steady state this <code class="language-plaintext highlighter-rouge">needs_alloc</code> case doesn’t need to happen.</p> <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2> <p>This is just a glimpse of what per-CPU concurrent programming looks like. I’m pretty new to it myself, and this post was motivated by building an end-to-end example in Rust. You can read more about how TCMalloc makes use of restartable sequences <a href="https://google.github.io/tcmalloc/rseq.html">here</a>. ◼</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:mnemonic" role="doc-endnote"> <p>This is annoyingly <em>different</em> from the function calling convention, which passes arguments in <code class="language-plaintext highlighter-rouge">rdi</code>, <code class="language-plaintext highlighter-rouge">rsi</code>, <code class="language-plaintext highlighter-rouge">rdx</code>, <code class="language-plaintext highlighter-rouge">rcx</code>, <code class="language-plaintext highlighter-rouge">r8</code>, <code class="language-plaintext highlighter-rouge">r9</code>, with the mnemonic “Diana’s silk dress cost $89.” I don’t know a cute mnemonic for the syscall registers. <a href="#fnref:mnemonic" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:relocations" role="doc-endnote"> <p>It’s actually worse than that. You’d think you could do</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-cpp" data-lang="cpp"><span class="n">jmp</span> <span class="n">foo</span>
<span class="n">pointers</span><span class="o">:</span>
  <span class="p">.</span><span class="kt">int</span> <span class="n">foo</span>

<span class="n">foo</span><span class="o">:</span>
  <span class="n">mov</span> <span class="n">qword</span> <span class="n">ptr</span> <span class="p">[</span><span class="n">rax</span><span class="p">],</span> <span class="n">pointers</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">x86 Assembly</div></div></div> <p>but this makes the resulting code non-position-independent on x86. What this means is that the code must know at link time what address it will be loaded at, which breaks the position-independent requirement of many modern platforms.</p> <p>Indeed, this code will produce a linker error like the following:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-text" data-lang="text">= note: /usr/bin/ld: /home/mcyoung/projects/cpulocal/target/debug/deps/cpulocal-a7eeabaf0b1f2c43.2l48u2rfiak1q1ik.rcgu.o:
      relocation R_X86_64_32 against `.text._ZN8cpulocal15PerCpu$LT$T$GT$8checkout17h42fde3ce3bd0180aE'
      can not be used when making a PIE object; recompile with -fPIE
      collect2: error: ld returned 1 exit status</code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Plaintext</div></div></div> <p>Not only is <code class="language-plaintext highlighter-rouge">.int foo</code> a problem, but so is referring to <code class="language-plaintext highlighter-rouge">pointers</code>. Instead we must write</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-cpp" data-lang="cpp"><span class="n">lea</span> <span class="n">rcx</span><span class="p">,</span> <span class="n">qword</span> <span class="n">ptr</span> <span class="p">[</span><span class="n">pointers</span> <span class="o">+</span> <span class="n">rip</span><span class="p">]</span>
<span class="n">mov</span> <span class="n">qword</span> <span class="n">ptr</span> <span class="p">[</span><span class="n">rax</span><span class="p">],</span> <span class="n">rcx</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">x86 Assembly</div></div></div> <p>to be able to load the address of <code class="language-plaintext highlighter-rouge">pointers</code> at all. This <em>can</em> be worked around if you’re smart; after all, it is possible to put the addresses of functions into static variables and not have the linker freak out. It’s too hard to do in inline assembly tho. <a href="#fnref:relocations" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:cs-init" role="doc-endnote"> <p>Basically this code, which can’t be properly-expressed in Rust.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">let</span> <span class="n">cs</span> <span class="o">=</span> <span class="n">CrtiticalSection</span> <span class="p">{</span>
  <span class="n">version</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
  <span class="n">flags</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
  <span class="n">start</span><span class="p">:</span> <span class="cm">/* &amp;90f */</span><span class="p">,</span>
  <span class="n">len</span><span class="p">:</span> <span class="cm">/* &amp;91f - &amp;90f */</span><span class="p">,</span>
  <span class="n">abort</span><span class="p">:</span> <span class="cm">/* &amp;92f */</span><span class="p">,</span>
<span class="p">};</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p><a href="#fnref:cs-init" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div> </div> <div class="related post-footer"> <h2>Related Posts</h2> <ul class="related-posts"> <li> <a href="/2023/11/27/simd-base64/"> <small class="post-meta-flat">2023-11-27</small> Designing a SIMD Algorithm from Scratch </a> <li> <a href="/2023/09/29/what-is-a-matrix/"> <small class="post-meta-flat">2023-09-29</small> What is a Matrix? A Miserable Pile of Coefficients! </a> <li> <a href="/2023/08/09/yarns/"> <small class="post-meta-flat">2023-08-09</small> I Wrote A String Type </a> </ul> </div> <div class="minimap"> <div class="minimap-size"></div> <div class="minimap-controller"></div> <div class="minimap-content"> <div class="content container"> <div class="post"> <span class="post-meta"> <span> <a href="https://mcyoung.xyz/tags.html#dark-arts">#dark-arts</a> <a href="https://mcyoung.xyz/tags.html#assembly">#assembly</a> <a href="https://mcyoung.xyz/tags.html#concurrency">#concurrency</a> <a href="https://mcyoung.xyz/tags.html#rust">#rust</a> </span> <span> 2023-03-29 </span> </span> <h1 class="post-title"><a href="/2023/03/29/rseq-checkout/"> Atomicless Concurrency </a></h1> <p>Let’s say we’re building an allocator. Good allocators need to serve many threads simultaneously, and as such any lock they take is going to be highly contended. One way to work around this, pioneered by TCMalloc, is to have thread-local caches of blocks (hence, the “TC” - thread cached).</p> <p>Unfortunately threads can be ephemeral, so book-keeping needs to grow dynamically, and large, complex programs (like the Google Search ranking server) can have tens of thousands of threads, so per-thread cost can add up. Also, any time a thread context-switches and resumes, its CPU cache will contain different cache lines – likely the wrong ones. This is because either another thread doing something compeltely different executed on that CPU, or the switched thread <em>migrated</em> to execute on a different core.</p> <p>These days, instead of caching per-thread, TCMalloc uses <em>per-CPU</em> data. This means that book-keeping is fixed, and this is incredibly friendly to the CPU’s cache: in the steady-state, each piece of the data will only ever be read or written to by a single CPU. It also has the amazing property that <em>there are no atomic operations involved</em> in the fast path, because operations on per-CPU data, by definition, do not need to be synchronized with other cores.</p> <p>This post gives an overview of how to build a CPU-local data structure on modern Linux. The exposition will be for x86, but other than the small bits of assembly you need to write, the technique is architecture-independent.</p> <h2 id="the-kernel-primitive"><a href="#the-kernel-primitive">The Kernel Primitive</a></h2> <p>Concurrency primitives require cooperating with the kernel, which is responsible for global scheduling decisions on the system. However, making syscalls is quite expensive; to alieviate this, there has been a trend in Linux to use shared memory as a kernelspace/userspace communication channel.</p> <p><a href="https://en.wikipedia.org/wiki/Futex">Futexes</a> are the classic “cas-with-the-kernel” syscall (I’m assuming basic knowledge of atomic operations like cas in this article). In the happy path, we just need to cas on some memory to lock a futex, and only make a syscall if we need to go to sleep because of contention. The kernel will perform its own cas on this variable if necessary.</p> <p><em>Restartable sequences</em> are another such proto-primitive, which are used for per-CPUuprogramming. The relevant syscall for us, <code class="language-plaintext highlighter-rouge">rseq(2)</code>, was added in Linux 4.18. Its manpage reads</p> <blockquote> <p>A restartable sequence is a sequence of instructions guaranteed to be executed atomically with respect to other threads and signal handlers on the current CPU. If its execution does not complete atomically, the kernel changes the execution flow by jumping to an abort handler defined by userspace for that restartable sequence.</p> </blockquote> <p>A restartable sequence, or “rseq” is a special kind of critical section that the kernel guarantees executes from start to finish without any kind of preemption. If preemption <em>does</em> happen (because of a signal or whatever), userspace observes this as a jump to a special handler for that critical section. Conceptually it’s like handling an exception:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="k">try</span> <span class="p">{</span>
  <span class="c1">// Per-CPU code here.</span>
<span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="n">PremptionException</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// Handle having been preempted, which usally just means</span>
  <span class="c1">// "try again".</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">C++</div></div></div> <p>These critical sections are usually of the following form:</p> <ol> <li>Read the current CPU index (the rseq mechanism provides a way to do this).</li> <li>Index into some data structure and do something to it.</li> <li>Complete the operation with a single memory write. This is the “commit”.</li> </ol> <p>All the kernel tells us is that we couldn’t finish successfully. We can always try again, but the critical section needs to be such that executing any prefix of it, up to the commit, has no effect on the data structure. We get no opportunity to perform “partial rollbacks”.</p> <p>In other words, the critical section must be a <em>transaction</em>.</p> <h3 id="enabling-rseq"><a href="#enabling-rseq">Enabling <code class="language-plaintext highlighter-rouge">rseq</code></a></h3> <p>Using rseqs requires turning on support for it for a particular thread; this is what calling <code class="language-plaintext highlighter-rouge">rseq(2)</code> (the syscall) accomplishes.</p> <p>The signature for this syscall looks like this:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="c1">// This type is part of Linux's ABI.</span>
<span class="nd">#[repr(C,</span> <span class="nd">align(</span><span class="mi">32</span><span class="nd">))]</span>
<span class="k">struct</span> <span class="n">Rseq</span> <span class="p">{</span>
  <span class="n">cpu_id_start</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span>
  <span class="n">cpu_id</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span>
  <span class="n">crit_sec</span><span class="p">:</span> <span class="nb">u64</span><span class="p">,</span>
  <span class="n">flags</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1">// Note: this is a syscall, not an actual Rust function.</span>
<span class="k">fn</span> <span class="nf">rseq</span><span class="p">(</span><span class="n">rseq</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Rseq</span><span class="p">,</span> <span class="n">len</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span> <span class="n">flags</span><span class="p">:</span> <span class="nb">i32</span><span class="p">,</span> <span class="n">signature</span><span class="p">:</span> <span class="nb">u32</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">i32</span><span class="p">;</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>The syscall registers “the” <code class="language-plaintext highlighter-rouge">Rseq</code> struct for the current thread; there can be at most one, per thread.</p> <p><code class="language-plaintext highlighter-rouge">rseq</code> is a pointer to this struct. <code class="language-plaintext highlighter-rouge">len</code> should be <code class="language-plaintext highlighter-rouge">size_of::&lt;Rseq&gt;()</code>, and <code class="language-plaintext highlighter-rouge">signature</code> can be any 32-bit integer (more on this later). For our purposes, we can ignore <code class="language-plaintext highlighter-rouge">flags</code> on the struct.</p> <p><code class="language-plaintext highlighter-rouge">flags</code> on the syscall, on the other hand, is used to indicate whether we’re unregistering the struct; this is explained below.</p> <p>In the interest of exposition, we’ll call the syscall directly. If you’ve never seen how a Linux syscall is done (on x86), you load the syscall number into <code class="language-plaintext highlighter-rouge">rax</code>, then up to six arguments in <code class="language-plaintext highlighter-rouge">rdi</code>, <code class="language-plaintext highlighter-rouge">rsi</code>, <code class="language-plaintext highlighter-rouge">rdx</code>, <code class="language-plaintext highlighter-rouge">r10</code>, <code class="language-plaintext highlighter-rouge">r8</code>, <code class="language-plaintext highlighter-rouge">r9</code><sup id="fnref:mnemonic" role="doc-noteref"><a href="#fn:mnemonic" class="footnote" rel="footnote">1</a></sup>. We only need the first four.</p> <p>The return value comes out in <code class="language-plaintext highlighter-rouge">rax</code>, which is 0 on success, and a negative of an <code class="language-plaintext highlighter-rouge">errno</code> code otherwise. In particular, we need to check for <code class="language-plaintext highlighter-rouge">EINTR</code> to deal with syscall interruption. (every Linux syscall can be interrupted).</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">raw_rseq</span><span class="p">(</span><span class="n">rseq</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Rseq</span><span class="p">,</span> <span class="n">unregister</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">signature</span><span class="p">:</span> <span class="nb">u32</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// Perform an open-coded Linux syscall.</span>
  <span class="k">loop</span> <span class="p">{</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">rax</span> <span class="o">=</span> <span class="mi">334</span><span class="p">;</span>  <span class="c1">// rseq(2) syscall number; x86-specific.</span>
    <span class="nd">asm!</span> <span class="p">{</span>
      <span class="s">"syscall"</span><span class="p">,</span>
      <span class="nf">inout</span><span class="p">(</span><span class="s">"rax"</span><span class="p">)</span> <span class="n">rax</span><span class="p">,</span>
      <span class="cm">/* rseq:      */</span> <span class="k">in</span><span class="p">(</span><span class="s">"rdi"</span><span class="p">)</span> <span class="n">rseq</span><span class="p">,</span>
      <span class="cm">/* len:       */</span> <span class="k">in</span><span class="p">(</span><span class="s">"rsi"</span><span class="p">)</span> <span class="nn">mem</span><span class="p">::</span><span class="nn">size_of</span><span class="p">::</span><span class="o">&lt;</span><span class="n">Rseq</span><span class="o">&gt;</span><span class="p">(),</span>
      <span class="cm">/* flags:     */</span> <span class="k">in</span><span class="p">(</span><span class="s">"rdx"</span><span class="p">)</span> <span class="n">unregister</span> <span class="k">as</span> <span class="nb">u64</span><span class="p">,</span>
      <span class="cm">/* signature: */</span> <span class="k">in</span><span class="p">(</span><span class="s">"r10"</span><span class="p">)</span> <span class="n">signature</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">match</span> <span class="n">rax</span> <span class="p">{</span>
      <span class="mi">0</span> <span class="k">=&gt;</span> <span class="k">break</span><span class="p">,</span>      <span class="c1">// Success, we're done.</span>
      <span class="o">-</span><span class="mi">4</span> <span class="k">=&gt;</span> <span class="k">continue</span><span class="p">,</span>  <span class="c1">// EINTR, try again.</span>
      <span class="n">errno</span> <span class="k">=&gt;</span> <span class="nd">panic!</span><span class="p">(</span><span class="s">"error calling rseq(2): {}"</span><span class="p">,</span> <span class="o">-</span><span class="n">errno</span><span class="p">),</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Note the <code class="language-plaintext highlighter-rouge">unregister</code> parameter: this is used to tear down <code class="language-plaintext highlighter-rouge">rseq</code> support on the way out of a thread. Generally, <code class="language-plaintext highlighter-rouge">rseq</code> will be a thread-local, and registration happens at thread startup. Glibc will do this and has a mechanism for acquiring the <code class="language-plaintext highlighter-rouge">rseq</code> pointer. Unfortunately, the glibc I have isn’t new enough to know to do this, so I hacked up something to register my own thread local.</p> <p>I had the bright idea of putting my <code class="language-plaintext highlighter-rouge">Rseq</code> struct in a box, which triggered an interesting bug: when a thread exits, it destroys all of the thread local variables, including the box to hold our <code class="language-plaintext highlighter-rouge">Rseq</code>. But if the thread then syscalls to deallocate its stack, when the kernel goes to resume, it will attempt to write the current CPU index to the <code class="language-plaintext highlighter-rouge">rseq.cpu_id</code> field.</p> <p>This presents a problem, because the kernel is probably going to write to a garbage location. This is all but guaranteed to result in a segfault. Debuggers observe this as a segfault on the instruction right after the <code class="language-plaintext highlighter-rouge">syscall</code> instruction; I spent half an hour trying to figure out what was causing a call to <code class="language-plaintext highlighter-rouge">madvise(2)</code> to segfault.</p> <p>Hence, we need to wrap our thread local in something that will call <code class="language-plaintext highlighter-rouge">rseq(2)</code> to unregister the struct. Putting everything together we get something like this.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">fn</span> <span class="nf">current_thread_rseq</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Rseq</span> <span class="p">{</span>
  <span class="c1">// This has to be its own struct so we can run a thread-exit destructor.</span>
  <span class="k">pub</span> <span class="k">struct</span> <span class="nf">RseqBox</span><span class="p">(</span><span class="nb">Box</span><span class="o">&lt;</span><span class="n">UnsafeCell</span><span class="o">&lt;</span><span class="n">Rseq</span><span class="o">&gt;&gt;</span><span class="p">);</span>
  <span class="k">impl</span> <span class="nb">Drop</span> <span class="k">for</span> <span class="n">RseqBox</span> <span class="p">{</span>
    <span class="k">fn</span> <span class="nf">drop</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">unsafe</span> <span class="p">{</span> <span class="nf">raw_rseq</span><span class="p">(</span><span class="k">self</span><span class="na">.0</span><span class="nf">.get</span><span class="p">(),</span> <span class="k">true</span><span class="p">,</span> <span class="n">RSEQ_SIG</span><span class="p">);</span> <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="nd">thread_local!</span> <span class="p">{</span>
    <span class="k">static</span> <span class="n">RSEQ</span><span class="p">:</span> <span class="n">RseqBox</span> <span class="o">=</span> <span class="p">{</span>
      <span class="c1">// Has to be in a box, since we need pointer stability.</span>
      <span class="k">let</span> <span class="n">rseq</span> <span class="o">=</span> <span class="nf">RseqBox</span><span class="p">(</span><span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nn">UnsafeCell</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">Rseq</span> <span class="p">{</span>
        <span class="n">cpu_id_start</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">cpu_id</span><span class="p">:</span> <span class="o">!</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">crit_sec</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">flags</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
      <span class="p">})));</span>

      <span class="c1">// Register it!!!</span>
      <span class="k">unsafe</span> <span class="p">{</span> <span class="nf">raw_rseq</span><span class="p">(</span><span class="n">rseq</span><span class="na">.0</span><span class="nf">.get</span><span class="p">(),</span> <span class="kc">false</span><span class="p">,</span> <span class="n">RSEQ_SIG</span><span class="p">);</span> <span class="p">}</span>
      <span class="n">rseq</span>
    <span class="p">};</span>
  <span class="p">}</span>

  <span class="n">RSEQ</span><span class="nf">.with</span><span class="p">(|</span><span class="n">ra</span><span class="p">|</span> <span class="n">ra</span><span class="na">.0</span><span class="nf">.get</span><span class="p">())</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Per Rust’s semantics, this will execute the first time we access this thread local, instead of at thread startup. Not <em>ideal</em>, since now we pay for an (uncontended) atomic read every time we touch RSEQ, but it will do.</p> <h3 id="creating-a-critical-section"><a href="#creating-a-critical-section">Creating a Critical Section</a></h3> <p>To set up and execute a restartable sequence, we need to assemble a struct that describes it. The following struct is also defined by Linux’s syscall ABI:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="nd">#[repr(C,</span> <span class="nd">align(</span><span class="mi">32</span><span class="nd">))]</span>
<span class="k">struct</span> <span class="n">CritSec</span> <span class="p">{</span>
  <span class="n">version</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span>
  <span class="n">flags</span><span class="p">:</span> <span class="nb">u32</span><span class="p">,</span>
  <span class="n">start</span><span class="p">:</span> <span class="nb">u64</span><span class="p">,</span>
  <span class="n">len</span><span class="p">:</span> <span class="nb">u64</span><span class="p">,</span>
  <span class="n">abort_handler</span><span class="p">:</span> <span class="nb">u64</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p><code class="language-plaintext highlighter-rouge">start</code> is the address of the first instruction in the sequence, and <code class="language-plaintext highlighter-rouge">len</code> is the length of the sequence in bytes. <code class="language-plaintext highlighter-rouge">abort_handler</code> is the address of the abort handler. <code class="language-plaintext highlighter-rouge">version</code> must be 0 and we can ignore <code class="language-plaintext highlighter-rouge">flags</code>.</p> <p>Once we have a value of this struct (on the stack or as a constant), we grab <code class="language-plaintext highlighter-rouge">RSEQ</code> and atomically store the address of our <code class="language-plaintext highlighter-rouge">CritSec</code> to <code class="language-plaintext highlighter-rouge">RSEQ.crit_sec</code>. This needs to be atomic because the kernel may decide to look at this pointer from a different CPU core, but it likely will not be contended.</p> <p>Note that <code class="language-plaintext highlighter-rouge">RSEQ.crit_sec</code> should be null before we do this; restartable sequences can’t nest.</p> <p>Next time the kernel preempts our thread (and later gets ready to resume it), it will look at <code class="language-plaintext highlighter-rouge">RSEQ.crit_sec</code> to decide if it preempted a restartable sequence and, if so, jump to the abort handler.</p> <p>Once we finish our critical section, we must reset <code class="language-plaintext highlighter-rouge">RSEQ.crit_sec</code> to 0.</p> <blockquote> <h4 id="labels-and-constants-oh-my"><a href="#labels-and-constants-oh-my">Labels and Constants, Oh My</a></h4> <p>There is a wrinkle: we would like for our <code class="language-plaintext highlighter-rouge">CritSec</code> value to be a constant, but Rust doesn’t provide us with a way to initialize the <code class="language-plaintext highlighter-rouge">start</code> and <code class="language-plaintext highlighter-rouge">abort_handler</code> fields directly, since it doesn’t have a way to refer<sup id="fnref:relocations" role="doc-noteref"><a href="#fn:relocations" class="footnote" rel="footnote">2</a></sup> to the labels (jump targets) inside the inline assembly. The simplest way to get around this is to assemble (lol) the <code class="language-plaintext highlighter-rouge">CritSec</code> on the stack, with inline assembly. The overhead is quite minimal.</p> </blockquote> <p>On x86, this is what our boilerplate will look like:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">let</span> <span class="k">mut</span> <span class="n">cs</span> <span class="o">=</span> <span class="nn">MaybeUninit</span><span class="p">::</span><span class="o">&lt;</span><span class="n">CritSec</span><span class="o">&gt;</span><span class="p">::</span><span class="nf">uninit</span><span class="p">();</span>
<span class="k">let</span> <span class="k">mut</span> <span class="n">ok</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

<span class="nd">asm!</span> <span class="p">{</span><span class="s">r"
  // We meed to do `rip`-relative loads so that this code is PIC;
  // otherwise we'll get linker errors. Thus, we can't `mov`
  // directly; we need to compute the address with a `lea`
  // first.

  // Initialize the first two fields to zero.
  mov qword ptr [{_cs}], 0

  // Load `90f` into `cs.start`. Note that this is 'forward
  // reference' to the jump target `90:` below.
  lea {_pc}, [90f + rip]
  mov qword ptr [{_cs} + 8], {_pc}

  // We need to get the difference `91f - 90f` into `cs.len`.
  // To do that, we write `-90f` to it, and then add `91f`.
  neg {_pc}
  mov qword ptr [{_cs} + 16], {_pc}
  lea {_pc}, [91f + rip]
  add qword ptr [{_cs} + 16], {_pc}

  // Same as the first line, but loading `cs.abort_handler`.
  lea {_pc}, [92f + rip]
  mov qword ptr [{_cs} + 24], {_pc}

  // Write `&amp;cs` to `RSEQ.crit_sec`. This turns on
  // restartable sequence handling.
  mov qword ptr [{rseq} + 8], {_cs}

90:
  // Do something cool here (coming soon).

91:
  // Jump over the abort handler.
  jmp 93f

  .int 0x53053053  // The signature!
92:
  // Nothing special, just zero `ok` to indicate this was a failure.
  // This is written this way simply because we can't early-return
  // out of inline assembly.
  xor {_ok:e}, {_ok:e}

93:
  // Clear `RSEQ.crit_sec`, regardless of which exit path
  // we took.
  mov qword ptr [{rseq} + 8], 0
  "</span><span class="p">,</span>
  <span class="n">_pc</span> <span class="o">=</span> <span class="nf">out</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="n">_</span><span class="p">,</span>
  <span class="n">_ok</span> <span class="o">=</span> <span class="nf">inout</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="n">ok</span><span class="p">,</span>
  <span class="n">_cs</span> <span class="o">=</span> <span class="k">in</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="n">cs</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="n">CritSec</span><span class="p">,</span>
  <span class="n">rseq</span> <span class="o">=</span> <span class="k">in</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="nf">current_thread_rseq</span><span class="p">(),</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>A few things to note:</p> <ol> <li>Because this is inline assembly, we need to use numeric labels. I’ve chosen labels in the 90s for no particular reason. <code class="language-plaintext highlighter-rouge">90:</code> declares a jump target, and <code class="language-plaintext highlighter-rouge">90f</code> is a forward reference to that instruction address.</li> <li>Most of this assembly is just initalizing a struct<sup id="fnref:cs-init" role="doc-noteref"><a href="#fn:cs-init" class="footnote" rel="footnote">3</a></sup>. It’s not until the <code class="language-plaintext highlighter-rouge">mov</code> right before <code class="language-plaintext highlighter-rouge">90:</code> (the critical section start) that anything interesting happens.</li> <li>Immediately before <code class="language-plaintext highlighter-rouge">92:</code> (the abort handler) is an <code class="language-plaintext highlighter-rouge">.int</code> directive that emits the same four-byte signature we passed to <code class="language-plaintext highlighter-rouge">rseq(2)</code> into the instruction stream. This <em>must</em> be here, otherwise the kernel will issue a segfault to the thread. This is a very basic control-flow integrity feature.</li> <li>We clear <code class="language-plaintext highlighter-rouge">RSEQ.crit_sec</code> at the very end.</li> </ol> <p>This is a lot of boilerplate. In an ideal world, we could have something like the following:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">fn</span> <span class="nf">run_rseq</span><span class="p">(</span><span class="n">cs</span><span class="p">:</span> <span class="k">extern</span> <span class="s">"C"</span> <span class="k">unsafe</span> <span class="k">fn</span><span class="p">(</span><span class="nb">u32</span><span class="p">));</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Unfortunately, this is very hard to do, because the constraints on restartable sequences are draconian:</p> <ul> <li>Can’t jump out of the critical section until it completes or aborts. This means you can’t call functions or make syscalls!</li> <li>Last instruction must be the commit, which is a memory store operation, <em>not</em> a return.</li> </ul> <p>This means that you can’t have the compiler generating code for you; it might outline things or move things around in ways you don’t want. In something like ASAN mode, it might inject function calls that will completely break the primitive.</p> <p>This means we muyst write our critical section in assembly. That assembly also almost unavoidably needs to be part of the boilerplate given above, and it means it can’t participate in ASAN or TSAN instrumentation.</p> <p>In the interest of exposition, we can build a wrapper over this inline assembly boilerplate that looks something like this:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">let</span> <span class="n">result</span><span class="p">:</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">(),</span> <span class="n">RseqAbort</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nd">rseq!</span> <span class="p">{</span><span class="s">r"
    // Assembly for our critical section...
  "</span><span class="p">,</span>
  <span class="c1">// Inline asm constraints.</span>
<span class="p">};</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>When I wrote the snippet above, I chose numeric labels in the 90s to avoid potential conflicts with whatever assembly gets pasted here. This is also why I used a leading <code class="language-plaintext highlighter-rouge">_</code> on the names of some of the assembly constraints; thise are private to the macro. <code class="language-plaintext highlighter-rouge">rseq</code> isn’t, though, since callers will want to access the CPU id in it.</p> <p>The intent is for the assembly string to be pasted over the <code class="language-plaintext highlighter-rouge">// Do something cool here</code> comment, and for the constraints to be tacked on after the boilerplate’s constraints.</p> <p>But with that we now have access to the full rseq primitive, in slightly sketchy macro form. Let’s use it to build a CPU-local data structure.</p> <h2 id="a-checkout-desk"><a href="#a-checkout-desk">A Checkout Desk</a></h2> <p>Let’s say we have a pool of objects that are needed to perform an allocation, our putative page caches. Let’s say we have the following interface:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">impl</span> <span class="n">FreeList</span> <span class="p">{</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">get_cache</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="n">PageCache</span><span class="p">;</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">return_cache</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">,</span> <span class="o">*</span><span class="k">mut</span> <span class="n">PageCache</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p><code class="language-plaintext highlighter-rouge">get_cache()</code> grabs a cache of pages off the global free list. This requires taking a lock or traversing a lockless linked list, so it’s pretty expensive. <code class="language-plaintext highlighter-rouge">return_cache()</code> returns a cache back to the global free list for re-use; it is a similarly expensive operation. Both of these operations are going to be contended like crazy, so we want to memoize them.</p> <p>To achieve this, we want one slot for every CPU to hold the cache it (or rather, a thread running on it) most recently acquired, so that it can be reused. These slots will have “checkout desk” semantics: if you take a thing, you must put something in its place, even if it’s just a sign that says you took the thing.</p> <figure> <p><img src="https://mcyoung.xyz/public/golden-idol.gif" alt=""/></p> </figure> <p><a href="https://fowles.github.io/">Matthew Kulukundis</a> came up with this idea, and he’d totally put this gif in a slide deck about this data structure.</p> <p>As a function signature, this is what it looks like:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="k">fn</span> <span class="nf">checkout</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">,</span> <span class="n">replacement</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">T</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="n">T</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>We can then use it like this.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">let</span> <span class="n">free_list</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">FreeList</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="k">let</span> <span class="n">per_cpu</span><span class="p">:</span> <span class="o">&amp;</span><span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">PageCache</span><span class="o">&gt;</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>
<span class="k">let</span> <span class="n">iou</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="n">PageCache</span><span class="p">;</span>

<span class="c1">// Check out this CPU's cache pointer, and replace it with</span>
<span class="c1">// an IOU note (a null pointer).</span>
<span class="k">let</span> <span class="k">mut</span> <span class="n">cache</span> <span class="o">=</span> <span class="n">per_cpu</span><span class="nf">.checkout</span><span class="p">(</span><span class="n">iou</span><span class="p">);</span>
<span class="k">if</span> <span class="n">cache</span> <span class="o">==</span> <span class="n">iou</span> <span class="p">{</span>
  <span class="c1">// If we got an IOU ourselves, this means another thread that</span>
  <span class="c1">// was executing on this CPU took the cache and left *us* with</span>
  <span class="c1">// a null, so we need to perform the super-expensive operation</span>
  <span class="c1">// to acquire a new one.</span>
  <span class="n">cache</span> <span class="o">=</span> <span class="n">free_list</span><span class="nf">.get_cache</span><span class="p">();</span>
<span class="p">}</span>

<span class="c1">// Do stuff with `cache` here. We have unique access to it.</span>
<span class="n">cache</span><span class="nf">.alloc_page</span><span class="p">(</span><span class="o">...</span><span class="p">);</span>

<span class="c1">// Return the pointer to the checkout desk.</span>
<span class="n">cache</span> <span class="o">=</span> <span class="n">per_cpu</span><span class="nf">.checkout</span><span class="p">(</span><span class="n">cache</span><span class="p">);</span>
<span class="k">if</span> <span class="n">cache</span> <span class="o">!=</span> <span class="n">iou</span> <span class="p">{</span>
  <span class="c1">// Usually, we expect to get back the IOU we put into the cache.</span>
  <span class="c1">// If we don't, that probably means another thread (or</span>
  <span class="c1">// hundreds) are hammering this slot and fighting for page caches.</span>
  <span class="c1">// If this happens, we need to throw away the cache.</span>
  <span class="n">free_list</span><span class="nf">.return_cache</span><span class="p">(</span><span class="n">cache</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>The semantics of <code class="language-plaintext highlighter-rouge">PerCpu&lt;T&gt;</code> is that it is an array of <code class="language-plaintext highlighter-rouge">nprocs</code> (the number of logical cores on the system) pointers, all initialized to null. <code class="language-plaintext highlighter-rouge">checkout()</code> swaps the pointer stored in the current CPU’s slot in the <code class="language-plaintext highlighter-rouge">PerCpu&lt;T&gt;</code> with the replacement argument.</p> <h3 id="building-the-checkout-desk"><a href="#building-the-checkout-desk">Building the Checkout Desk</a></h3> <p>The implementation of this type is relatively simple, but the devil is in the details. Naively, you’d think you literally want an array of pointers:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">pub</span> <span class="k">struct</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="n">ptrs</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="p">[</span><span class="o">*</span><span class="k">mut</span> <span class="n">T</span><span class="p">]</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">unsafe</span> <span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="nb">Send</span> <span class="k">for</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{}</span>
<span class="k">unsafe</span> <span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="nb">Sync</span> <span class="k">for</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Unfortunately, this is cache-hostile. We expect that (depending on how <code class="language-plaintext highlighter-rouge">ptrs</code> is aligned in memory) for eight CPUs’ checkout pointers to be on the same cache line. This means eight separate cores are going to be writing to the same cache line, which is going to result in a lot of cache thrash. This memory wants to be in L1 cache, but will probably wind up mostly in shared L3 cache.</p> <p>This effect is called “false sharing”, and is a fundamental part of the design of modern processors. We have to adjust for this.</p> <p>Instead, we want to give each core a full cache line (64 bytes aligned to a 64-byte boundary) for it to store its pointer in. This sounds super wasteful (56 of those bytes will go unused), but this is the right call for a perf-sensitive primitive.</p> <p>This amount of memory can add up pretty fast (two whole pages of memory for a 128-core server!), so we’ll want to lazilly initialize them. Our cache-friendly struct will look more like this:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">pub</span> <span class="k">struct</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="n">ptrs</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="p">[</span><span class="n">AtomicPtr</span><span class="o">&lt;</span><span class="n">CacheLine</span><span class="o">&lt;*</span><span class="k">mut</span> <span class="n">T</span><span class="o">&gt;&gt;</span><span class="p">]</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1">// This struct wraps a T and forces it to take up an entire cache line.</span>
<span class="nd">#[repr(C,</span> <span class="nd">align(</span><span class="mi">64</span><span class="nd">))]</span>
<span class="k">struct</span> <span class="n">CacheLine</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">T</span><span class="p">);</span>

<span class="k">unsafe</span> <span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="nb">Send</span> <span class="k">for</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{}</span>
<span class="k">unsafe</span> <span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="nb">Sync</span> <span class="k">for</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Initializing it requires finding out how many cores there are on the machine. This is a… fairly platform-specific affair. Rust <em>does</em> offer a “maximum paralellism” query in its standard library, but it is intended as a hint for how many worker threads to spawn, as opposed to a hard upper bound on the number of CPU indices.</p> <p>Instead, we call <code class="language-plaintext highlighter-rouge">get_nprocs_conf()</code>, which is fine since we’re already extremely non-portable already. This is a GNU libc extension.</p> <p>In code…</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="k">pub</span> <span class="k">fn</span> <span class="nf">new</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="k">Self</span> <span class="p">{</span>
    <span class="k">extern</span> <span class="s">"C"</span> <span class="p">{</span>
      <span class="c1">// #include &lt;sys/sysinfo.h&gt;</span>
      <span class="c1">//</span>
      <span class="c1">// This function returns the maximum number of cores the</span>
      <span class="c1">// kernel knows of for the current machine. This function</span>
      <span class="c1">// is very expensive to call, so we need to cache it.</span>
      <span class="k">fn</span> <span class="nf">get_nprocs_conf</span><span class="p">()</span> <span class="k">-&gt;</span> <span class="nb">i32</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">static</span> <span class="k">mut</span> <span class="n">NPROCS</span><span class="p">:</span> <span class="nb">usize</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">static</span> <span class="n">INIT</span><span class="p">:</span> <span class="n">Once</span> <span class="o">=</span> <span class="nn">Once</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>
    <span class="n">INIT</span><span class="nf">.call_once</span><span class="p">(||</span> <span class="k">unsafe</span> <span class="p">{</span>
      <span class="n">NPROCS</span> <span class="o">=</span> <span class="nf">get_nprocs_conf</span><span class="p">()</span> <span class="k">as</span> <span class="nb">usize</span><span class="p">;</span>
    <span class="p">});</span>

    <span class="k">let</span> <span class="n">len</span> <span class="o">=</span> <span class="k">unsafe</span> <span class="p">{</span> <span class="n">NPROCS</span> <span class="p">};</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">ptrs</span> <span class="o">=</span> <span class="nn">Vec</span><span class="p">::</span><span class="nf">with_capacity</span><span class="p">(</span><span class="n">len</span><span class="p">);</span>
    <span class="k">for</span> <span class="n">_</span> <span class="k">in</span> <span class="mi">0</span><span class="o">..</span><span class="n">len</span> <span class="p">{</span>
      <span class="n">ptrs</span><span class="nf">.push</span><span class="p">(</span><span class="nn">AtomicPtr</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">()));</span>
    <span class="p">}</span>

    <span class="k">Self</span> <span class="p">{</span> <span class="n">ptrs</span><span class="p">:</span> <span class="n">ptrs</span><span class="nf">.into_boxed_slice</span><span class="p">()</span> <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>(I’m not going to implement <code class="language-plaintext highlighter-rouge">Drop</code> for this type. That’s an exercise for the reader.)</p> <h3 id="implementing-checkout"><a href="#implementing-checkout">Implementing <code class="language-plaintext highlighter-rouge">checkout()</code></a></h3> <p>Now’s the moment we’ve all be waiting for: writing our restartable sequence. As critical sections go, this one’s pretty simple:</p> <ol> <li>Index into the <code class="language-plaintext highlighter-rouge">ptrs</code> array to get this CPU’s pointer-to-cache-line.</li> <li>If that pointer is null, bail out of the rseq and initialize a fresh cache line (and then try again).</li> <li>If it’s not null, swap <code class="language-plaintext highlighter-rouge">replacement</code> with the value in the cache line.</li> </ol> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">impl</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="n">PerCpu</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="k">fn</span> <span class="nf">checkout</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">,</span> <span class="k">mut</span> <span class="n">replacement</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">T</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="n">T</span> <span class="p">{</span>
    <span class="c1">// We need to try this operation in a loop, to deal with</span>
    <span class="c1">// rseq aborts.</span>
    <span class="k">loop</span> <span class="p">{</span>
      <span class="k">let</span> <span class="n">ptrs</span> <span class="o">=</span> <span class="k">self</span><span class="py">.ptrs</span><span class="nf">.as_ptr</span><span class="p">();</span>
      <span class="k">let</span> <span class="k">mut</span> <span class="n">vcpu</span><span class="p">:</span> <span class="nb">i32</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
      <span class="k">let</span> <span class="k">mut</span> <span class="n">need_alloc</span><span class="p">:</span> <span class="nb">i32</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
      <span class="k">let</span> <span class="n">result</span><span class="p">:</span> <span class="nb">Result</span><span class="o">&lt;</span><span class="p">(),</span> <span class="n">RseqAbort</span><span class="o">&gt;</span> <span class="o">=</span> <span class="nd">rseq!</span> <span class="p">{</span><span class="s">r"
        // Load the current CPU number.
        mov {vcpu:e}, dword ptr [{rseq} + 4]

        // Load the `vcpu`th pointer from `ptrs`.
        // On x86, `mov` is atomic. The only threads we might
        // be condending with are those that are trying to
        // initialize this pointer if it's null.
        mov {scratch}, qword ptr [{ptrs} + 8 * {vcpu:r}]

        // If null, exit early and trigger an allocation
        // for this vcpu.
        test {scratch}, {scratch}
        jz 1f

        // Make sure the outer code knows not to allocate
        // a new cache line.
        xor {need_alloc:e}, {need_alloc:e}

        // Commit the checkout by exchanging `replacement`.
        xchg {ptr}, qword ptr [{scratch}]
      1:
        "</span><span class="p">,</span>
        <span class="n">ptrs</span> <span class="o">=</span> <span class="k">in</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="n">ptrs</span><span class="p">,</span>
        <span class="n">scratch</span> <span class="o">=</span> <span class="nf">out</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="n">_</span><span class="p">,</span>
        <span class="n">ptr</span> <span class="o">=</span> <span class="nf">inout</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="n">replacement</span><span class="p">,</span>
        <span class="n">vcpu</span> <span class="o">=</span> <span class="nf">out</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="n">vcpu</span><span class="p">,</span>
        <span class="n">need_alloc</span> <span class="o">=</span> <span class="nf">inout</span><span class="p">(</span><span class="n">reg</span><span class="p">)</span> <span class="n">need_alloc</span><span class="p">,</span>
      <span class="p">};</span>

      <span class="c1">// We got preempted, so it's time to try again.</span>
      <span class="k">if</span> <span class="n">result</span><span class="nf">.is_err</span><span class="p">()</span> <span class="p">{</span> <span class="k">continue</span> <span class="p">}</span>

      <span class="c1">// If we don't need to allocate, we're done.</span>
      <span class="k">if</span> <span class="n">need_alloc</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span> <span class="k">return</span> <span class="n">replacement</span> <span class="p">}</span>

      <span class="c1">// Otherwise, allocate a new cache line and cas it into</span>
      <span class="c1">// place. This is Atomics 101, nothing fancy.</span>
      <span class="k">let</span> <span class="k">mut</span> <span class="n">cache_line</span> <span class="o">=</span> <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="nf">CacheLine</span><span class="p">(</span><span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">()));</span>
      <span class="k">loop</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">cas</span> <span class="o">=</span> <span class="k">self</span><span class="py">.ptrs</span><span class="p">[</span><span class="n">vcpu</span> <span class="k">as</span> <span class="nb">usize</span><span class="p">]</span><span class="nf">.compare_exchange_weak</span><span class="p">(</span>
          <span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">(),</span> <span class="n">cache_line</span><span class="nf">.as_mut</span><span class="p">(),</span>
          <span class="nn">Ordering</span><span class="p">::</span><span class="n">AcqRel</span><span class="p">,</span> <span class="nn">Ordering</span><span class="p">::</span><span class="n">Relaxed</span><span class="p">,</span>
        <span class="p">);</span>

        <span class="k">match</span> <span class="n">cas</span> <span class="p">{</span>
          <span class="nf">Ok</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="p">{</span>
            <span class="c1">// Successful allocation.</span>
            <span class="nd">debug_assert!</span><span class="p">(</span><span class="n">p</span><span class="nf">.is_null</span><span class="p">());</span>
            <span class="c1">// Make sure to stop `cache_line`'s memory</span>
            <span class="c1">// from being freed by `Box`'s dtor.</span>
            <span class="nn">mem</span><span class="p">::</span><span class="nf">forget</span><span class="p">(</span><span class="n">cache_line</span><span class="p">);</span>
            <span class="k">break</span><span class="p">;</span>
          <span class="p">}</span>
          <span class="c1">// Try again: this is a spurious failure.</span>
          <span class="nf">Err</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">if</span> <span class="n">p</span><span class="nf">.is_null</span><span class="p">()</span> <span class="k">=&gt;</span> <span class="k">continue</span><span class="p">,</span>
          <span class="c1">// Someone got here first; we can just discard</span>
          <span class="c1">// `Box`.</span>
          <span class="nf">Err</span><span class="p">(</span><span class="n">_</span><span class="p">)</span> <span class="k">=&gt;</span> <span class="k">break</span><span class="p">,</span>
        <span class="p">}</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>This code listing is a lot to take in. It can be broken into two parts: the restartable sequence itself, and the allocation fallback if the pointer-to-cache-line happens to be null.</p> <p>The restartable sequence is super short. It looks at the pointer-to-cache-line, bails if its null (this triggers the later part of the function) and then does an <code class="language-plaintext highlighter-rouge">xchg</code> between the actual <code class="language-plaintext highlighter-rouge">*mut T</code> in the per-CPU cache line, and the replacement.</p> <p>If the rseq aborts, we just try again. This is short enough that preemption in the middle of the rseq is quite rare. Then, if <code class="language-plaintext highlighter-rouge">need_alloc</code> was zeroed, that means we successfully committed, so we’re done.</p> <p>Otherwise we need to allocate a cache line for this CPU. We’re now outside of the rseq, so we’re back to needing atomics. Many threads might be racing to be the thread that initializes the pointer-to-cache-line; we use a basic cas loop to make sure that we only initialize from null, and if someone beats us to it, we don’t leak the memory we had just allocated. This is an RMW operation, so we want both acquire and release ordering. Atomics 101!</p> <p>Then, we try again. Odds are good we won’t have migrated CPUs when we execute again, so we won’t need to allocate again. Eventually all of the pointers in the <code class="language-plaintext highlighter-rouge">ptrs</code> array will be non-null, so in the steady state this <code class="language-plaintext highlighter-rouge">needs_alloc</code> case doesn’t need to happen.</p> <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2> <p>This is just a glimpse of what per-CPU concurrent programming looks like. I’m pretty new to it myself, and this post was motivated by building an end-to-end example in Rust. You can read more about how TCMalloc makes use of restartable sequences <a href="https://google.github.io/tcmalloc/rseq.html">here</a>. ◼</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:mnemonic" role="doc-endnote"> <p>This is annoyingly <em>different</em> from the function calling convention, which passes arguments in <code class="language-plaintext highlighter-rouge">rdi</code>, <code class="language-plaintext highlighter-rouge">rsi</code>, <code class="language-plaintext highlighter-rouge">rdx</code>, <code class="language-plaintext highlighter-rouge">rcx</code>, <code class="language-plaintext highlighter-rouge">r8</code>, <code class="language-plaintext highlighter-rouge">r9</code>, with the mnemonic “Diana’s silk dress cost $89.” I don’t know a cute mnemonic for the syscall registers. <a href="#fnref:mnemonic" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:relocations" role="doc-endnote"> <p>It’s actually worse than that. You’d think you could do</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-cpp" data-lang="cpp"><span class="n">jmp</span> <span class="n">foo</span>
<span class="n">pointers</span><span class="o">:</span>
  <span class="p">.</span><span class="kt">int</span> <span class="n">foo</span>

<span class="n">foo</span><span class="o">:</span>
  <span class="n">mov</span> <span class="n">qword</span> <span class="n">ptr</span> <span class="p">[</span><span class="n">rax</span><span class="p">],</span> <span class="n">pointers</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">x86 Assembly</div></div></div> <p>but this makes the resulting code non-position-independent on x86. What this means is that the code must know at link time what address it will be loaded at, which breaks the position-independent requirement of many modern platforms.</p> <p>Indeed, this code will produce a linker error like the following:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-text" data-lang="text">= note: /usr/bin/ld: /home/mcyoung/projects/cpulocal/target/debug/deps/cpulocal-a7eeabaf0b1f2c43.2l48u2rfiak1q1ik.rcgu.o:
      relocation R_X86_64_32 against `.text._ZN8cpulocal15PerCpu$LT$T$GT$8checkout17h42fde3ce3bd0180aE'
      can not be used when making a PIE object; recompile with -fPIE
      collect2: error: ld returned 1 exit status</code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Plaintext</div></div></div> <p>Not only is <code class="language-plaintext highlighter-rouge">.int foo</code> a problem, but so is referring to <code class="language-plaintext highlighter-rouge">pointers</code>. Instead we must write</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-cpp" data-lang="cpp"><span class="n">lea</span> <span class="n">rcx</span><span class="p">,</span> <span class="n">qword</span> <span class="n">ptr</span> <span class="p">[</span><span class="n">pointers</span> <span class="o">+</span> <span class="n">rip</span><span class="p">]</span>
<span class="n">mov</span> <span class="n">qword</span> <span class="n">ptr</span> <span class="p">[</span><span class="n">rax</span><span class="p">],</span> <span class="n">rcx</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">x86 Assembly</div></div></div> <p>to be able to load the address of <code class="language-plaintext highlighter-rouge">pointers</code> at all. This <em>can</em> be worked around if you’re smart; after all, it is possible to put the addresses of functions into static variables and not have the linker freak out. It’s too hard to do in inline assembly tho. <a href="#fnref:relocations" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:cs-init" role="doc-endnote"> <p>Basically this code, which can’t be properly-expressed in Rust.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">let</span> <span class="n">cs</span> <span class="o">=</span> <span class="n">CrtiticalSection</span> <span class="p">{</span>
  <span class="n">version</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
  <span class="n">flags</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
  <span class="n">start</span><span class="p">:</span> <span class="cm">/* &amp;90f */</span><span class="p">,</span>
  <span class="n">len</span><span class="p">:</span> <span class="cm">/* &amp;91f - &amp;90f */</span><span class="p">,</span>
  <span class="n">abort</span><span class="p">:</span> <span class="cm">/* &amp;92f */</span><span class="p">,</span>
<span class="p">};</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p><a href="#fnref:cs-init" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div> </div> <div class="related post-footer"> <h2>Related Posts</h2> <ul class="related-posts"> <li> <a href="/2023/11/27/simd-base64/"> <small class="post-meta-flat">2023-11-27</small> Designing a SIMD Algorithm from Scratch </a> <li> <a href="/2023/09/29/what-is-a-matrix/"> <small class="post-meta-flat">2023-09-29</small> What is a Matrix? A Miserable Pile of Coefficients! </a> <li> <a href="/2023/08/09/yarns/"> <small class="post-meta-flat">2023-08-09</small> I Wrote A String Type </a> </ul> </div> </div> </div> </div></div> </body> <div class="sidebar show-if-mobile"> <div class="container sidebar-sticky"> &copy; 2023 Miguel Young de la Sota <br/> <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA</a> • <a href="https://varz.mcyoung.xyz/">Site Analytics</a> </div> </div> </html>