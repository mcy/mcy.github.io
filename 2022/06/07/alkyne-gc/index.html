<!DOCTYPE html> <html lang="en-us"> <head> <link href="https://gmpg.org/xfn/11" rel="profile"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta http-equiv="content-type" content="text/html; charset=utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1"> <title> The Alkyne GC &middot; mcyoung </title> <link rel="stylesheet" href="https://mcyoung.xyz/public/css/syntax.css"> <link rel="stylesheet" href="https://mcyoung.xyz/public/css/syntax-overrides.css"> <link rel="stylesheet" href="https://mcyoung.xyz/public/css/style.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn" crossorigin="anonymous"> <link rel="preload" href="https://mcyoung.xyz/public/fonts/abril-fatface.woff2" as="font" type="font/woff2" crossorigin> <link rel="preload" href="https://mcyoung.xyz/public/fonts/rokkitt.woff2" as="font" type="font/woff2" crossorigin> <link rel="preload" href="https://mcyoung.xyz/public/fonts/rokkitt-italic.woff2" as="font" type="font/woff2" crossorigin> <link rel="preload" href="https://mcyoung.xyz/public/fonts/spline-mono.woff2" as="font" type="font/woff2" crossorigin> <link rel="preload" href="https://mcyoung.xyz/public/fonts/spline-mono-italic.woff2" as="font" type="font/woff2" crossorigin> <link rel="shortcut icon" href="https://mcyoung.xyz/public/favicon.ico"> <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml"> <script src="https://mcyoung.xyz/public/js/minimap.js"></script> <script data-goatcounter="https://mcy.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:title" content="The Alkyne GC &middot; mcyoung"> <meta name="twitter:image" content="https://mcyoung.xyz/og/alkyne-gc-3b7d0d11ef3ceb94de3e2d41deb3e0e8df60c84f.png"> <meta property="og:title" content="The Alkyne GC &middot; mcyoung"> <meta property="og:type" content="object"> <meta property="og:image" content="https://mcyoung.xyz/og/alkyne-gc-3b7d0d11ef3ceb94de3e2d41deb3e0e8df60c84f.png"> <meta property="og:height" content="630"> <meta property="og:width" content="1200"> <meta property="og:url" content="https://mcyoung.xyz/2022/06/07/alkyne-gc/"> </head> <body> <div class="sidebar"> <div class="sidebar-avatar hide-if-mobile"> <a href="https://mcyoung.xyz"> <img class="sidebar-avatar" src="https://mcyoung.xyz/public/images/avatar.png" alt="Yeah, I drew this. Check out my art blog."></a> </div> <div class="container sidebar-sticky"> <div class="sidebar-about"> <h1><a href="https://mcyoung.xyz"> mcyoung </a></h1> <div class="lead hide-if-mobile">I'm Miguel. I write about compilers, performance, and silly computer things. I also draw Pokémon. </div> </div> <hr class="hide-if-mobile"/> <nav class="sidebar-nav"> <a class="sidebar-nav-item" href="https://mcyoung.xyz">Home</a> • <a class="sidebar-nav-item" href="https://mcyoung.xyz/about">About</a> • <a class="sidebar-nav-item" href="https://mcyoung.xyz/posts">Posts</a> • <a class="sidebar-nav-item" href="https://mcyoung.xyz/tags">Tags</a> </nav> <nav class="sidebar-nav"> <a class="sidebar-nav-item " href="https://art.mcyoung.xyz">Art</a> • <a class="sidebar-nav-item" href="https://github.com/mcy">GitHub</a> • <a class="sidebar-nav-item" href="https://mcyoung.xyz/resume">Resumé</a> • <a class="sidebar-nav-item" href="https://mcyoung.xyz/syllabus">Syllabus</a> </nav> <br class="hide-if-mobile"/> <span class="hide-if-mobile"> <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA</a> • <a href="https://varz.mcyoung.xyz/">Site Analytics</a> <br> &copy; 2024 Miguel Young de la Sota</span> </div> </div> <div class="content container"><div class="post-title"> <span class="post-meta"> 2022-06-07 • 5329 words • 44 minutes <br class="show-if-mobile"/> <span class="hide-if-mobile">•</span> <a href="https://mcyoung.xyz/tags.html#dark-arts">#dark-arts</a> • <a href="https://mcyoung.xyz/tags.html#pointers">#pointers</a> </span> <h1><a href="/2022/06/07/alkyne-gc/"> The Alkyne GC </a></h1> </div> <div class="post"> <p><a href="https://github.com/mcy/alkyne">Alkyne</a> is a scripting language I built a couple of years ago for generating configuration blobs. Its interpreter is a naive AST walker<sup id="fnref:ast-walker" role="doc-noteref"><a href="#fn:ast-walker" class="footnote" rel="footnote">1</a></sup> that uses ARC<sup id="fnref:arc" role="doc-noteref"><a href="#fn:arc" class="footnote" rel="footnote">2</a></sup> for memory management, so it’s pretty slow, and I’ve been gradually writing a <a href="https://github.com/mcy/alkyne/tree/new-engine">new evaluation engine</a> for it.</p> <p>This post isn’t about Alkyne itself, that’s for another day. For now, I’d like to write down some notes for the GC I wrote<sup id="fnref:src" role="doc-noteref"><a href="#fn:src" class="footnote" rel="footnote">3</a></sup> for it, and more generally provide an introduction to memory allocators (especially those that would want to collude with a GC).</p> <p>This post is intended for people familiar with the basics of low-level programming, such as pointers and syscalls. Alkyne’s GC is intended to be simple while still having reasonable performance. This means that the design contains all the allocator “tropes,” but none of the hairy stuff.</p> <p>My hope is readers new to allocators or GCs will come away with an understanding of these tropes and the roles they play in a modern allocator.</p> <blockquote> <p>Thank you to James Farrell, Manish Goregaokar, Matt Kulukundis, JeanHeyd Meneide, Skye Thompson, and Paul Wankadia for providing feedback on various drafts of this article. This was a tough one to get right. :)</p> </blockquote> <h2 id="trailhead"><a href="#trailhead">Trailhead</a></h2> <p>The Alkyne GC is solving a very specific problem, which allows us to limit what it actually needs to do. Alkyne is an “embeddable” language like JavaScript, so its heap is not intended to be big; in fact, for the benefit of memory usage optimizations, it’s ideal to use 32-bit pointers (a 4 gigabyte address space).</p> <p>The heap needs to be able to manage arbitrarily-large allocations (for lists), and allocations as small as eight bytes (for floats<sup id="fnref:nan-boxing" role="doc-noteref"><a href="#fn:nan-boxing" class="footnote" rel="footnote">4</a></sup>). Allocation should be reasonably quick, but due to the size of the heap, walking the entire heap is totally acceptable.</p> <p>Because we’re managing a fixed-size heap, we can simply ask the operating system for a contiguous block of that size up-front using the <code class="language-plaintext highlighter-rouge">mmap()</code> syscall. An Alkyne pointer is simply a 32-bit offset into this giant allocation, which can be converted to and from a genuine CPU pointer by adding or subtracting the base address of the heap.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-text" data-lang="text"> 4GB Heap
 +-------------------------------------------------+
 |                x                                |
 +-------------------------------------------------+
 ^                ^
 base             base + ptr_to_x</code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Plaintext</div></div></div> <p>The OS won’t actually reserve 4GB of memory for us; it will only allocate one system page (4KB) at a time. If we read or write to a particular page in the heap for the first time, the OS will only then find physical RAM to back it<sup id="fnref:os-allocator" role="doc-noteref"><a href="#fn:os-allocator" class="footnote" rel="footnote">5</a></sup>.</p> <p>Throughout, we’ll be working with this fixed-size heap, and won’t think too hard about where it came from. For our purposes, it is essentially a <code class="language-plaintext highlighter-rouge">Box&lt;[u8]&gt;</code>, but we’ll call it a <code class="language-plaintext highlighter-rouge">Heap&lt;[u8]&gt;</code> to make it clear this memory we got from the operating system (but, to be clear, the entire discussion applies just as well to an ordinary gigantic <code class="language-plaintext highlighter-rouge">Box&lt;[u8]&gt;</code>)</p> <p>The Alkyne language does not have threads, so we can eschew concurrency. This significantly reduces the problems we will need to solve. Most modern allocators and garbage collectors are violently concurrent by nature, and unfortunately, much too advanced for one article. There are links below to fancier GCs you can poke around in.</p> <h2 id="a-heap-of-trouble"><a href="#a-heap-of-trouble">A Heap of Trouble</a></h2> <p>To build a garbage collector, we first need an allocator. We could “just”<sup id="fnref:load-bearing" role="doc-noteref"><a href="#fn:load-bearing" class="footnote" rel="footnote">6</a></sup> use the system heap as a source of pages, but most garbage collectors collude with the allocator, since they will want to use similar data structures. Thus, if we are building a garbage collector, we might as well build the allocator too.</p> <p>An allocator, or “memory heap” (not to be confused with a min-heap, an unrelated but <em>wicked</em> data structure), services requests for <em>allocations</em>: unique leases of space in the managed heap of various sizes, which last for lifetimes not known until runtime. These allocations may also be called <em>objects</em>, and a heap may be viewed as a general-purpose object pool.</p> <p>The most common API for a heap is:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">trait</span> <span class="n">Allocator</span> <span class="p">{</span>
  <span class="c1">// Returns a *unique pointer* managed by this allocator</span>
  <span class="c1">// to memory as large as requested, and as aligned</span>
  <span class="c1">// as we'd like.</span>
  <span class="c1">// </span>
  <span class="c1">// Returns null on failure.</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">alloc</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">;</span>
  <span class="c1">// Frees a pointer returned by `Alloc` may be called at</span>
  <span class="c1">// most once.</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">free</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">ptr</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <blockquote> <p>Originally the examples were in C++, which I feel is more accessible (lol) but given that Alkyne itself is written in Rust I felt that would make the story flow better.</p> </blockquote> <p>This is the “malloc” API, which is actually very deficient; ideally, we would do something like Rust’s <a href="https://doc.rust-lang.org/std/alloc/trait.Allocator.html"><code class="language-plaintext highlighter-rouge">Allocator</code></a>, which requires providing size <em>and</em> alignment to both the allocation <em>and</em> deallocation functions.</p> <p>Unfortunately<sup id="fnref:i-tried" role="doc-noteref"><a href="#fn:i-tried" class="footnote" rel="footnote">7</a></sup>, this means I need to explain alignment.</p> <h3 id="good-pointers-evil-pointers-lawful-pointers-chaotic-pointers"><a href="#good-pointers-evil-pointers-lawful-pointers-chaotic-pointers">Good Pointers, Evil Pointers, Lawful Pointers, Chaotic Pointers</a></h3> <p>“Alignment” is a somewhat annoying property of a pointer. A pointer is aligned to N bytes (always a power of 2) if its address is divisible by N. A pointer is “well-aligned” (or just “aligned”) if its address is aligned to the natural alignment of the thing it points to. For ints, this is <em>usually</em> their size; for structs, it is the maximum alignment among the alignments of the fields of that struct.</p> <p>Performing operations on a pointer requires that it be aligned<sup id="fnref:unaligned" role="doc-noteref"><a href="#fn:unaligned" class="footnote" rel="footnote">8</a></sup>. This is annoying because it requires some math. Specifically we need three functions:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="cd">/// Checks that `ptr` is aligned to an alignment.</span>
<span class="k">fn</span> <span class="nf">is_aligned</span><span class="p">(</span><span class="n">ptr</span><span class="p">:</span> <span class="n">Int</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">bool</span> <span class="p">{</span>
  <span class="n">ptr</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">align</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
<span class="p">}</span>

<span class="cd">/// Rounds `ptr` down to a multiple of `align`.</span>
<span class="k">fn</span> <span class="nf">align_down</span><span class="p">(</span><span class="n">ptr</span><span class="p">:</span> <span class="n">Int</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Int</span> <span class="p">{</span>
  <span class="n">ptr</span> <span class="o">&amp;</span> <span class="o">!</span><span class="p">(</span><span class="n">align</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">}</span>

<span class="cd">/// Rounds `ptr` up to a multiple of `align`.</span>
<span class="k">fn</span> <span class="nf">align_up</span><span class="p">(</span><span class="n">ptr</span><span class="p">:</span> <span class="n">Int</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Int</span> <span class="p">{</span>
  <span class="c1">// (I always look this one up. &gt;_&gt;)</span>
  <span class="nf">align_down</span><span class="p">(</span><span class="n">ptr</span> <span class="o">+</span> <span class="n">align</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">align</span><span class="p">)</span>
<span class="p">}</span>

<span class="cd">/// Computes how much needs to be added to `ptr` to align it.</span>
<span class="k">fn</span> <span class="nf">misalign</span><span class="p">(</span><span class="n">ptr</span><span class="p">:</span> <span class="n">Int</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">usize</span> <span class="p">{</span>
  <span class="nf">align_up</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">align</span><span class="p">)</span> <span class="o">-</span> <span class="n">ptr</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>(Exercise: prove these formulas.)</p> <p>For the rest of the article I will assume I have these three functions available at any time for whatever type of integer I’d like (including raw pointers which are just boutique<sup id="fnref:provenance" role="doc-noteref"><a href="#fn:provenance" class="footnote" rel="footnote">9</a></sup> integers).</p> <p>Also we will treat the <code class="language-plaintext highlighter-rouge">Heap&lt;[u8]&gt;</code> holding our entire heap as being infinitely aligned; i.e. as a pointer it is aligned to all possible alignments that could matter (i.e. page-aligned, 4KB as always). (For an ordinary <code class="language-plaintext highlighter-rouge">Box&lt;[u8]&gt;</code>, this is not true.)</p> <h3 id="the-trivial-heap"><a href="#the-trivial-heap">The Trivial Heap</a></h3> <p>Allocating memory is actually very easy. <em>Arenas</em> are the leanest and meanest in the allocator food chain; they simply don’t bother to free any memory.</p> <p>This means allocation is just incrementing a cursor indicating where the hitherto-unallocated memory is.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-text" data-lang="text"> +-------------------------------------------------+
 | Allocated        | Free                         |
 +-------------------------------------------------+
                    ^
                    cursor</code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Plaintext</div></div></div> <p>Our allocator is as simple as <code class="language-plaintext highlighter-rouge">return ptr++;</code>.</p> <p>This is straightforward to implement in code:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">struct</span> <span class="n">Arena</span> <span class="p">{</span>
  <span class="n">heap</span><span class="p">:</span> <span class="n">Heap</span><span class="o">&lt;</span><span class="p">[</span><span class="nb">u8</span><span class="p">]</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">cursor</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">impl</span> <span class="n">Allocator</span> <span class="k">for</span> <span class="n">Arena</span> <span class="p">{</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">alloc</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span> <span class="p">{</span>
    <span class="c1">// To get an aligned pointer, we need to burn some "alignment</span>
    <span class="c1">// padding". This is one of the places where alignment is</span>
    <span class="c1">// annoying.</span>
    <span class="k">let</span> <span class="n">needed</span> <span class="o">=</span> <span class="n">size</span> <span class="o">+</span> <span class="nf">misalign</span><span class="p">(</span><span class="k">self</span><span class="py">.heap</span><span class="nf">.as_ptr</span><span class="p">(),</span> <span class="n">align</span><span class="p">);</span>

    <span class="c1">// Check that we're not out of memory.</span>
    <span class="k">if</span> <span class="k">self</span><span class="py">.heap</span><span class="nf">.len</span><span class="p">()</span> <span class="o">-</span> <span class="k">self</span><span class="py">.cursor</span> <span class="o">&lt;</span> <span class="n">needed</span> <span class="p">{</span>
      <span class="k">return</span> <span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">();</span>
    <span class="p">}</span>

    <span class="c1">// Advance the cursor and cut off the end of the allocated</span>
    <span class="c1">// section.</span>
    <span class="k">self</span><span class="py">.cursor</span> <span class="o">+=</span> <span class="n">needed</span><span class="p">;</span>
    <span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="py">.heap</span><span class="p">[</span><span class="k">self</span><span class="py">.cursor</span> <span class="o">-</span> <span class="n">size</span><span class="p">]</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">free</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">ptr</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// ayy lmao</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Arenas are very simple, but far from useless! They’re great for holding onto data that exists for the context of a “session”, such as for software that does lots of computations and then exits (a compiler) or software that handles requests from clients, where lots of data lives for the duration of the request and no longer (a webserver).</p> <p>They are not, however, good for long-running systems. Eventually the heap will be exhausted if objects are not recycled.</p> <p>Making this work turns out to be hard<sup>[citation-needed]</sup>. This is the “fundamental theorem” of allocators:</p> <blockquote> <h4 id="fundamental-theorem-of-allocators"><a href="#fundamental-theorem-of-allocators">Fundamental “Theorem” of Allocators</a></h4> <p>Handing out memory is easy. Handing it out <em>repeatedly</em> is hard.</p> </blockquote> <p>Thankfully, over the last fifty years we’ve mostly figured this out. Allocator designs can get pretty gnarly.</p> <h2 id="four-tropes"><a href="#four-tropes">Four Tropes</a></h2> <p>From here, we will gradually augment our allocator with more features to allow it to service all kinds of requests. For this, we will implement four common allocator features:</p> <ol> <li>Blocks and a block cache.</li> <li>Free lists.</li> <li>Block merging and splitting.</li> <li>Slab allocation.</li> </ol> <p>All four of these are present in some form in most modern allocators.</p> <h3 id="blocks"><a href="#blocks">Blocks</a></h3> <p>The first thing we should do is to deal in fixed-size blocks of memory of some minimum size. If you ask <code class="language-plaintext highlighter-rouge">malloc()</code> for a single byte, it will probably give you like 8 bytes on most systems. No one is asking <code class="language-plaintext highlighter-rouge">malloc()</code> for single bytes, so we can quietly round up and not have people care. (Also, Alkyne’s smallest heap objects are eight bytes, anyways.)</p> <p>Blocks are also convenient, because we can keep per-block metadata on each one, as a header before the user’s data:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="nd">#[repr(C)]</span>
<span class="k">struct</span> <span class="n">Block</span> <span class="p">{</span>
  <span class="n">header</span><span class="p">:</span> <span class="n">Header</span><span class="p">,</span>
  <span class="n">data</span><span class="p">:</span> <span class="p">[</span><span class="nb">u8</span><span class="p">;</span> <span class="n">BLOCK_SIZE</span><span class="p">],</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>To allow blocks to be re-used, we can keep a cache of recently freed blocks. The easiest way to do this is with a stack. Note that the heap is now made of <code class="language-plaintext highlighter-rouge">Block</code>s, not plain bytes.</p> <p>To allocate storage, first we check the stack. If the stack is empty, we revert to being an arena and increment the cursor. To free, we push the block onto the stack, so <code class="language-plaintext highlighter-rouge">alloc()</code> can return it on the next call.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">struct</span> <span class="n">BlockCache</span> <span class="p">{</span>
  <span class="n">heap</span><span class="p">:</span> <span class="n">Heap</span><span class="o">&lt;</span><span class="p">[</span><span class="n">Block</span><span class="p">]</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">cursor</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span>
  <span class="n">free_stack</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;*</span><span class="k">mut</span> <span class="n">Block</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">impl</span> <span class="n">Allocator</span> <span class="k">for</span> <span class="n">BlockCache</span> <span class="p">{</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">alloc</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span> <span class="p">{</span>
    <span class="c1">// Check that the size isn't too big. We don't need to</span>
    <span class="c1">// bother with alignment, because every block is</span>
    <span class="c1">// infinitely-aligned, just like the heap itself.</span>
    <span class="k">if</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="n">BLOCK_SIZE</span> <span class="p">{</span>
      <span class="k">return</span> <span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">();</span>
    <span class="p">}</span>

    <span class="c1">// Try to serve a block from the stack.</span>
    <span class="k">if</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="o">=</span> <span class="k">self</span><span class="py">.free_stack</span><span class="nf">.pop</span><span class="p">()</span> <span class="p">{</span>
      <span class="k">return</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="n">block</span><span class="py">.data</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// Fall back to arena mode.</span>
    <span class="k">if</span> <span class="k">self</span><span class="py">.cursor</span> <span class="o">==</span> <span class="k">self</span><span class="py">.heap</span><span class="nf">.len</span><span class="p">()</span> <span class="p">{</span>
      <span class="k">return</span> <span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="k">self</span><span class="py">.cursor</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="py">.heap</span><span class="p">[</span><span class="k">self</span><span class="py">.cursor</span><span class="p">]</span><span class="py">.data</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span>
  <span class="p">}</span>

  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">free</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">ptr</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Use pointer subtraction to find the start of the block.</span>
    <span class="k">let</span> <span class="n">block</span> <span class="o">=</span> <span class="n">ptr</span><span class="nf">.sub</span><span class="p">(</span><span class="nn">size_of</span><span class="p">::</span><span class="o">&lt;</span><span class="n">Header</span><span class="o">&gt;</span><span class="p">())</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Block</span><span class="p">;</span>
    <span class="k">self</span><span class="py">.free_stack</span><span class="nf">.push</span><span class="p">(</span><span class="n">block</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>This allocator has a problem: it relies on the system allocator! <code class="language-plaintext highlighter-rouge">Heap</code> came directly from the OS, but <code class="language-plaintext highlighter-rouge">Vec</code> talks to <code class="language-plaintext highlighter-rouge">malloc()</code> (or something like it). It also adds some pretty big overhead: the <code class="language-plaintext highlighter-rouge">Vec</code> needs to be able to resize, since it grows as more and more things are freed. This can lead to long pauses during <code class="language-plaintext highlighter-rouge">free()</code> as the vector resizes.</p> <p>Cutting out the middleman gives us more control over this overhead.</p> <h3 id="free-lists"><a href="#free-lists">Free Lists</a></h3> <p>Of course, no one has ever heard of a “free stack”; everyone uses free lists! A free list is the cache idea but implemented as an <em>intrusive linked list</em>.</p> <p>A linked list is this data structure:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">enum</span> <span class="n">Node</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="nb">Nil</span><span class="p">,</span>
  <span class="nf">Cons</span><span class="p">(</span><span class="nb">Box</span><span class="o">&lt;</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">Node</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">)</span><span class="o">&gt;</span><span class="p">),</span>
  <span class="c1">//   ^~~ oops I allocated again</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>This has the same problem of needing to find an allocator to store the nodes. An intrusive list avoids that by making the nodes <em>part</em> of the elements. The <code class="language-plaintext highlighter-rouge">Header</code> we reserved for ourselves earlier is the perfect place to put it:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">struct</span> <span class="n">Header</span> <span class="p">{</span>
  <span class="cd">/// Pointer to the next and previous blocks in whatever</span>
  <span class="cd">/// list the block is in.</span>
  <span class="n">next</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Block</span><span class="p">,</span>
  <span class="n">prev</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Block</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>In particular we want to make sure block are in doubly-linked lists, which have the property that any element can be removed from them without walking the list.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-text" data-lang="text">   list.root
     |
     v
 +-&gt; Block--------------------------+
 |   | next | null | data data data |
 |   +------------------------------+
 +-----/------+
      /       |
     v        |
 +-&gt; Block--------------------------+
 |   | next | prev | data data data |
 |   +------------------------------+
 +-----/------+
      /       |
     v        |
 +-&gt; Block--------------------------+
 |   | next | prev | data data data |
 |   +------------------------------+
 +-----/------+
      /       |
     v        |
     Block--------------------------+
     | null | prev | data data data |
     +------------------------------+</code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Plaintext</div></div></div> <p>We also introduce a <code class="language-plaintext highlighter-rouge">List</code> container type that holds the root node of a list of blocks, to give us a convenient container-like API. This type looks like this:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">struct</span> <span class="n">List</span> <span class="p">{</span>
  <span class="cd">/// The root is actually a sacrificial block that exists only to</span>
  <span class="cd">/// make it possible to unlink blocks in the middle of a list. This</span>
  <span class="cd">/// needs to exist so that calling unlink() on the "first" element</span>
  <span class="cd">/// of the list has a predecessor to replace itself with.</span>
  <span class="n">root</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Block</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">impl</span> <span class="n">List</span> <span class="p">{</span>
  <span class="cd">/// Pushes a block onto the list.</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">push</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">block</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Block</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">block</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="n">block</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">root</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="k">self</span><span class="py">.root</span><span class="p">;</span>
    <span class="k">if</span> <span class="o">!</span><span class="n">root</span><span class="py">.header.next</span><span class="nf">.is_null</span><span class="p">()</span> <span class="p">{</span>
      <span class="k">let</span> <span class="n">first</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="n">root</span><span class="py">.header.next</span><span class="p">;</span>
      <span class="n">block</span><span class="py">.header.next</span> <span class="o">=</span> <span class="n">first</span><span class="p">;</span>
      <span class="n">first</span><span class="py">.header.prev</span> <span class="o">=</span> <span class="n">block</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">root</span><span class="py">.header.next</span> <span class="o">=</span> <span class="n">block</span><span class="p">;</span>
    <span class="n">block</span><span class="py">.header.prev</span> <span class="o">=</span> <span class="n">root</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="cd">/// Gets the first element of the list, if any.</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">first</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Option</span><span class="o">&lt;&amp;</span><span class="k">mut</span> <span class="n">Block</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">root</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="k">self</span><span class="py">.root</span><span class="p">;</span>
    <span class="n">root</span><span class="py">.header.next</span><span class="nf">.as_mut</span><span class="p">()</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>We should also make it possible to ask a block whether it is in any list, and if so, remove it.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">impl</span> <span class="n">Block</span> <span class="p">{</span>
  <span class="cd">/// Checks if this block is part of a list.</span>
  <span class="k">fn</span> <span class="nf">is_linked</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">bool</span> <span class="p">{</span>
    <span class="c1">// Only the prev link is guaranteed to exist; next is</span>
    <span class="c1">// null for the last element in a list. Sacrificial</span>
    <span class="c1">// nodes will never have prev non-null, and can't be</span>
    <span class="c1">// unlinked.</span>
    <span class="o">!</span><span class="k">self</span><span class="py">.header.prev</span><span class="nf">.is_null</span><span class="p">()</span>
  <span class="p">}</span>

  <span class="cd">/// Unlinks this linked block from whatever list it's in.</span>
  <span class="k">fn</span> <span class="nf">unlink</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="nd">assert!</span><span class="p">(</span><span class="k">self</span><span class="nf">.is_linked</span><span class="p">());</span>
    <span class="k">if</span> <span class="o">!</span><span class="k">self</span><span class="py">.header.next</span><span class="nf">.is_null</span><span class="p">()</span> <span class="p">{</span>
      <span class="k">let</span> <span class="n">next</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="k">self</span><span class="py">.header.next</span><span class="p">;</span>
      <span class="n">next</span><span class="py">.header.prev</span> <span class="o">=</span> <span class="k">self</span><span class="py">.header.prev</span><span class="p">;</span> 
    <span class="p">}</span>

    <span class="c1">// This is why we need the sacrificial node.</span>
    <span class="k">let</span> <span class="n">prev</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="k">self</span><span class="py">.header.prev</span><span class="p">;</span>
    <span class="n">prev</span><span class="py">.header.next</span> <span class="o">=</span> <span class="k">self</span><span class="py">.header.next</span><span class="p">;</span>

    <span class="k">self</span><span class="py">.header.prev</span> <span class="o">=</span> <span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">();</span>
    <span class="k">self</span><span class="py">.header.next</span> <span class="o">=</span> <span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">();</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Using these abstractions we can upgrade <code class="language-plaintext highlighter-rouge">BlockCache</code> to <code class="language-plaintext highlighter-rouge">FreeList</code>. We only need to rename <code class="language-plaintext highlighter-rouge">free_stack</code> to <code class="language-plaintext highlighter-rouge">free_list</code>, and make a one-line change:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="o">-</span> <span class="k">if</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="o">=</span> <span class="k">self</span><span class="py">.free_stack</span><span class="nf">.pop</span><span class="p">()</span> <span class="p">{</span>
<span class="o">+</span> <span class="k">if</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="o">=</span> <span class="k">self</span><span class="py">.free_list</span><span class="nf">.first</span><span class="p">()</span> <span class="p">{</span>
<span class="o">+</span>   <span class="n">block</span><span class="nf">.unlink</span><span class="p">();</span>
    <span class="k">return</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="n">block</span><span class="py">.data</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">;</span>
 <span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Hooray for encapsulation!</p> <p>This is a very early <code class="language-plaintext highlighter-rouge">malloc()</code> design, similar to the one described in the K&amp;R C book. It does have big blind spot: it can only serve up blocks up to a fixed size! It’s also quite wasteful, because all allocations are served the same size blocks: the bigger we make the maximum request, the more wasteful <code class="language-plaintext highlighter-rouge">alloc(8)</code> gets.</p> <h3 id="block-splitting-alkynes-way"><a href="#block-splitting-alkynes-way">Block Splitting (Alkyne’s Way)</a></h3> <p>The next step is to use a block splitting/merging scheme, such as the <a href="https://en.wikipedia.org/wiki/Buddy_memory_allocation"><em>buddy system</em></a>. Alkyne does not precisely use a buddy system, but it does something similar.</p> <p>Alkyne does not have fixed-size blocks. Like many allocators, it defines a “page” of memory as the atom that it keeps its data structures. Alkyne defines a page to be 4KB, but other choices are possible: TCMalloc uses 8KB pages.</p> <p>In Alkyne, pages come together to form contiguous, variable-size <em>reams</em> (get it?). These take the place of blocks.</p> <h4 id="page-descriptors"><a href="#page-descriptors">Page Descriptors</a></h4> <p>Merging and splitting makes it hard to keep headers at the start of reams, so Alkyne puts them all in a giant array somewhere else. Each page gets its own “header” called a page descriptor, or <a href="https://github.com/mcy/alkyne/blob/a62ad3b7ee70268625da640c1edeea8ff7116512/src/eval2/gc.rs#L416"><code class="language-plaintext highlighter-rouge">Pd</code></a>.</p> <p>The array of page descriptors lives at the beginning of the heap, and the actual pages follow after that. It turns out that this array has a maximum size, which we can use to pre-compute where the array ends.</p> <p>Currently, each <code class="language-plaintext highlighter-rouge">Pd</code> is 32 bytes, in addition to the 4KB it describes. If we divide 4GB by 32 + 4K, it comes out to around four million pages (4067203 to be precise). Rounded up to the next page boundary, this means that pages begin at the 127102nd 4K boundary after the <code class="language-plaintext highlighter-rouge">Heap&lt;[u8]&gt;</code> base address, or an offset of <code class="language-plaintext highlighter-rouge">0x7c1f400</code> bytes.</p> <p>Having them all in a giant array is also very useful, because it means the GC can trivially find <em>every allocation</em> in the whole heap: just iterate the <code class="language-plaintext highlighter-rouge">Pd</code> array!</p> <p>So! This is our heap:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-text" data-lang="text">+---------------------------------------+  &lt;-- mmap(2)'d region base
| Pd | Pd | Pd | Pd | Pd | Pd | Pd | Pd | \
+---------------------------------------+ |--- Page Descriptors
| Pd | Pd | Pd | Pd | Pd | Pd | Pd | Pd | |    for every page we can
+---------------------------------------+ |    ever allocate.
: ...                                   : |
+---------------------------------------+ |
| Pd | Pd | Pd | Pd | Pd | Pd | Pd | Pd | /
+---------------------------------------+  &lt;-- Heap base address
| Page 0                                | \    = region + 0x7c1f400
|                                       | |
|                                       | |--- 4K pages corresponding
+---------------------------------------+ |    to the Pds above.
| Page 1                                | |    (not to scale)
|                                       | |
|                                       | |
+---------------------------------------+ |
: ...                                   | |
+---------------------------------------+ |
| Page N                                | |
|                                       | |
|                                       | /
+---------------------------------------+
  (not to scale by a factor of about 4)</code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Plaintext</div></div></div> <p>Each one of those little <code class="language-plaintext highlighter-rouge">Pd</code>s looks something like this:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="nd">#[repr(C)]</span>
<span class="k">struct</span> <span class="n">Pd</span> <span class="p">{</span>
  <span class="n">gc_bits</span><span class="p">:</span> <span class="nb">u64</span><span class="p">,</span>
  <span class="n">prev</span><span class="p">:</span> <span class="nb">Option</span><span class="o">&lt;</span><span class="nb">u32</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">next</span><span class="p">:</span> <span class="nb">Option</span><span class="o">&lt;</span><span class="nb">u32</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">len</span><span class="p">:</span> <span class="nb">u16</span><span class="p">,</span>
  <span class="n">class</span><span class="p">:</span> <span class="n">SizeClass</span><span class="p">,</span>
  <span class="c1">// More fields...</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p><code class="language-plaintext highlighter-rouge">prev</code> and <code class="language-plaintext highlighter-rouge">next</code> are the intrusive linked list pointers used for the free lists, but now they are indices into the <code class="language-plaintext highlighter-rouge">Pd</code> array. The other fields will be used for this and the trope that follows.</p> <p>Given a pointer into a page, we can get the corresponding <code class="language-plaintext highlighter-rouge">Pd</code> by <code class="language-plaintext highlighter-rouge">align_down()</code>‘ing to a page boundary, computing the index of the page (relative to the heap base), and then index into the <code class="language-plaintext highlighter-rouge">Pd</code> array. This process can be reversed to convert a pointer to a <code class="language-plaintext highlighter-rouge">Pd</code> into a pointer to a page, so going between the two is very easy.</p> <blockquote> <p>I won’t cover this here, but Alkyne actually wraps <code class="language-plaintext highlighter-rouge">Pd</code> pointers in a special <code class="language-plaintext highlighter-rouge">PdRef</code> type that also carries a reference to the <code class="language-plaintext highlighter-rouge">Heap</code>; this allows implementing functions like <code class="language-plaintext highlighter-rouge">is_linked()</code>, <code class="language-plaintext highlighter-rouge">unlink()</code>, and <code class="language-plaintext highlighter-rouge">data()</code> directly.</p> <p>I won’t show how this is implemented, since it’s mostly boilerplate.</p> </blockquote> <h4 id="reams-of-pages"><a href="#reams-of-pages">Reams of Pages</a></h4> <p>There is one giant free list that contains all of the reams. Reams use their first page’s descriptor to track all of their metadata, including the list pointers for the free list. The <code class="language-plaintext highlighter-rouge">len</code> field additionally tracks how many <em>additional</em> pages are in the ream. <code class="language-plaintext highlighter-rouge">gc_bits</code> is set to 1 if the page is in use and 0 otherwise.</p> <p>To allocate N continuous pages from the free ream list:</p> <ol> <li>We walk through the free ream list, and pick the first one with at least N pages.</li> <li>We “split” it: the first N pages are returned to fulfill the request.</li> <li>The rest of the ream is put back into the free list.</li> <li>If no such ream exists, we allocate a max-sized ream<sup id="fnref:max-size" role="doc-noteref"><a href="#fn:max-size" class="footnote" rel="footnote">10</a></sup> (65536 pages), and split that as above.</li> </ol> <p>In a sense, each ream is an arena that we allocate smaller reams out of; those reams cannot be “freed” back to the ream they came from. Instead, to free a ream, we just stick it back on the main free list.</p> <p>If we ever run out, we turn back into an arena and initialize the next uninitialized <code class="language-plaintext highlighter-rouge">Pd</code> in the big ol’ <code class="language-plaintext highlighter-rouge">Pd</code> array.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">struct</span> <span class="n">ReamAlloc</span> <span class="p">{</span>
  <span class="n">heap</span><span class="p">:</span> <span class="n">Heap</span><span class="o">&lt;</span><span class="p">[</span><span class="n">Page</span><span class="p">]</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">cursor</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span>
  <span class="n">free_list</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span>
<span class="p">}</span>

<span class="cd">/// The offset to the end of the maximally-large Pd array.</span>
<span class="cd">/// This can be computed ahead of time.</span>
<span class="k">const</span> <span class="n">PAGES_START</span><span class="p">:</span> <span class="nb">usize</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>

<span class="k">impl</span> <span class="n">Allocator</span> <span class="k">for</span> <span class="n">ReamAlloc</span> <span class="p">{</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">alloc</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span> <span class="p">{</span>
    <span class="c1">// We don't need to bother with alignment, because every page is</span>
    <span class="c1">// already infinitely aligned; we only allocate at the page</span>
    <span class="c1">// boundary.</span>
    <span class="k">let</span> <span class="n">page_count</span> <span class="o">=</span> <span class="nf">align_up</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span> <span class="o">/</span> <span class="mi">4096</span><span class="p">;</span>

    <span class="c1">// Find the first page in the list that's big enough.</span>
    <span class="c1">// (Making `List` iterable is an easy exercise.)</span>
    <span class="k">for</span> <span class="n">pd</span> <span class="k">in</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="py">.list</span> <span class="p">{</span>
      <span class="k">if</span> <span class="n">pd</span><span class="py">.len</span> <span class="o">&lt;</span> <span class="n">page_count</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">{</span>
        <span class="k">continue</span>
      <span class="p">}</span>
      <span class="k">if</span> <span class="n">pd</span><span class="py">.len</span> <span class="o">==</span> <span class="n">page_count</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">{</span>
        <span class="c1">// No need to split here.</span>
        <span class="n">pd</span><span class="nf">.unlink</span><span class="p">();</span>
        <span class="k">return</span> <span class="n">pd</span><span class="nf">.data</span><span class="p">();</span>
      <span class="p">}</span>

      <span class="c1">// We can chop off the *end* of the ream to avoid needing</span>
      <span class="c1">// to update any pointers.</span>
      <span class="k">let</span> <span class="n">new_ream</span> <span class="o">=</span> <span class="n">pd</span><span class="nf">.add</span><span class="p">(</span><span class="n">page_count</span><span class="p">);</span>
      <span class="n">new_ream</span><span class="py">.len</span> <span class="o">=</span> <span class="n">page_count</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>
      <span class="n">pd</span><span class="py">.len</span> <span class="o">-=</span> <span class="n">page_count</span><span class="p">;</span>

      <span class="k">return</span> <span class="n">new_ream</span><span class="nf">.data</span><span class="p">();</span>
    <span class="p">}</span>

    <span class="c1">// Allocate a new ream. This is more of the same arena stuff.</span>
  <span class="p">}</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">free</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">ptr</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Find the Pd corresponding to this page's pointer. This</span>
    <span class="c1">// will always be a ream's first Pd assuming the user</span>
    <span class="c1">// didn't give us a bad pointer.</span>
    <span class="k">let</span> <span class="n">pd</span> <span class="o">=</span> <span class="nn">Pd</span><span class="p">::</span><span class="nf">from_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">);</span>
    <span class="k">self</span><span class="py">.free_list</span><span class="nf">.push</span><span class="p">(</span><span class="n">pd</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>This presents a problem: over time, reams will shrink and never grow, and eventually there will be nothing left but single pages.</p> <p>Top fix this, we can merge reams (not yet implemented in Alkyne). Thus:</p> <ol> <li>Find two adjacent, unallocated reams.</li> <li>Unlink the second ream from the free list.</li> <li>Increase the length of the first ream by the number of pages in the second.</li> </ol> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="c1">// `reams()` returns an iterator that walks the `Pd` array using</span>
<span class="c1">// the `len` fields to find the next ream each time.</span>
<span class="k">for</span> <span class="n">pd</span> <span class="k">in</span> <span class="k">self</span><span class="nf">.reams</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">if</span> <span class="n">pd</span><span class="py">.gc_bits</span> <span class="o">!=</span> <span class="mi">0</span> <span class="p">{</span> <span class="k">continue</span> <span class="p">}</span>
  <span class="k">loop</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">next</span> <span class="o">=</span> <span class="n">pd</span><span class="nf">.add</span><span class="p">(</span><span class="n">pd</span><span class="py">.len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
    <span class="k">if</span> <span class="n">next</span><span class="py">.gc_bits</span> <span class="o">!=</span> <span class="mi">0</span> <span class="p">{</span> <span class="k">break</span> <span class="p">}</span>
    <span class="n">next</span><span class="nf">.unlink</span><span class="p">();</span>
    <span class="n">pd</span><span class="py">.len</span> <span class="o">+=</span> <span class="n">next</span><span class="py">.len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>We don’t need to do anything to the second ream’s <code class="language-plaintext highlighter-rouge">Pd</code>; by becoming part of the first ream, it is subsumed. Walking the heap requires using reams’ lengths to skip over currently-invalid <code class="language-plaintext highlighter-rouge">Pd</code>s, anyways.</p> <p>We have two options for finding mergeable reams. Either we can walk the entire heap, as above, or, when a ream is freed, we can check that the previous and following reams are mergeable (finding the previous ream would require storing the length of a ream at its first <em>and</em> last <code class="language-plaintext highlighter-rouge">Pd</code>).</p> <p>Which merging strategy we use depends on whether we’re implementing an ordinary <code class="language-plaintext highlighter-rouge">malloc</code>-like heap or a garbage collector; in the <code class="language-plaintext highlighter-rouge">malloc</code> case, merging on free makes more sense, but merging in one shot makes more sense for Alkyne’s GC (we’ll see why in a bit).</p> <h3 id="slabs-and-size-classes"><a href="#slabs-and-size-classes">Slabs and Size Classes</a></h3> <p>A <em>slab allocator</em> is a specialized allocator that allocates a single type of object; they are quite popular in kernels as pools of commonly-used object. The crux of a slab allocator is that, because everything is the same size, we <em>don’t</em> need to implement splitting and merging. The <code class="language-plaintext highlighter-rouge">BlockCache</code> above is actually a very primitive slab allocator.</p> <p>Our <code class="language-plaintext highlighter-rouge">Pd</code> array is also kind of like a slab allocator; instead of mixing them in with the variably-sized blocks, they all live together with no gaps in between; entire pages are dedicated just to <code class="language-plaintext highlighter-rouge">Pd</code>s.</p> <p>The Alkyne page allocator cannot allocate pages smaller than 4K, and making them any smaller increases the relative overhead of a <code class="language-plaintext highlighter-rouge">Pd</code>. To cut down on book-keeping, we slab-allocate small objects by defining <em>size classes</em>.</p> <p>A size class is size of smaller-than-a-page object that Alkyne will allocate; other sizes are rounded up to the next size class. Entire pages are dedicated to holding just objects of the same size; these are called small object pages, or simply <em>slabs</em>. The size class is tracked with the <code class="language-plaintext highlighter-rouge">class</code> field of the <code class="language-plaintext highlighter-rouge">Pd</code>.</p> <p>Each size class has its own free list of partially-filled slabs of that size. For slabs, <code class="language-plaintext highlighter-rouge">gc_bits</code> field becomes a bitset that tracks which slots in the page are currently in-use, reducing the overhead for small objects to only a little over a single bit each!</p> <p>In the diagram below, bits set in the 32-bit, little-endian bitset indicate which slots in the slab (no to scale!) are filled with three-letter words. (The user likes cats.)</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-text" data-lang="text">  Pd--------------------------------------------+
  | gc_bits: 0b01010011111010100110000010101011 |
  +---------------------------------------------+

 Page--------------------------------------------+
 | cat | ink |     | hat |     | jug |     | fig |
 +-----------------------------------------------+
 |     |     |     |     |     | zip | net |     |
 +-----------------------------------------------+
 |     | aid |     | yes |     | war | cat | van |
 +-----------------------------------------------+
 | can | cat |     |     | rat |     | urn |     |
 +-----------------------------------------------+</code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Plaintext</div></div></div> <p>Allocating an object is a bit more complicated now, but now we have a really, really short fast path for small objects:</p> <ol> <li>Round up to the next highest size class, or else to the next page boundary.</li> <li>If a slab size class… a. Check the pertinent slab list for a partially-filled slab. i. If there isn’t one, allocate a page per the instructions below and initialize it as a slab page. b. Find the next available slot with <code class="language-plaintext highlighter-rouge">(!gc_bits).count_trailing_zeros()</code>, and set that bit. c. Return <code class="language-plaintext highlighter-rouge">page_addr + slab_slot_size * slot</code>.</li> <li>Else, if a single page, allocate from the single-page list. a. If there isn’t one, allocate from the ream list as usual.</li> <li>Else, multiple pages, allocate a ream as usual.</li> </ol> <p>Allocating small objects is very fast, since the slab free lists, if not empty, will always have a spot to fill in <code class="language-plaintext highlighter-rouge">gc_bits</code>. Finding the empty spot in the bitset is a few instructions (a <code class="language-plaintext highlighter-rouge">not</code> plust a <code class="language-plaintext highlighter-rouge">ctz</code> or equivalent on most hardware).</p> <p>Alkyne maintains a separate free list for single free pages to speed up finding such pages to turn into fresh slabs. This also minimizes the need to allocate single pages off of large reams, which limits fragmentation.</p> <p>Alkyne’s size classes are the powers of two from 8 (the smallest possible object) to 2048. For the classes 8, 16, and 32, which would have more than 64 slots in the page, we use up to 56 bytes on the page itself to extend <code class="language-plaintext highlighter-rouge">gc_bits</code>; 8-byte pages can only hold 505 objects, instead of the full 512, a 1% overhead.</p> <p>Directly freeing an object via is now tricky, since we do not a priori know the size.</p> <ol> <li>Round the pointer up to the next page boundary, and obtain that page’s <code class="language-plaintext highlighter-rouge">Pd</code>.</li> <li>If this is a start-of-ream page, stick it into the appropriate free list (single page or ream, depending on the size of the ream).</li> <li>Else, we can look at <code class="language-plaintext highlighter-rouge">class</code> to find the size class, and from that, and the offset of the original pointer into the page, the index of the slot.</li> <li>Clear the slot’s index in <code class="language-plaintext highlighter-rouge">gc_bits</code>.</li> <li>If the page was full before, place it onto the correct slab free list; if it becomes empty, place it into the page free list.</li> </ol> <p>At this point, we know whether the page just became partially full or empty, and can move it to the correct free list.</p> <p>Size classes are an important allocator optimization. TCMalloc takes this to an . These constants are generated by some crazy script based on profiling data.</p> <h2 id="intermission"><a href="#intermission">Intermission</a></h2> <p>Before continuing to the GC part of the article, it’s useful to go over what we learned.</p> <p>A neat thing about this is that most of these tricks are somewhat independent. While giving feedback for an early draft, Matt Kulukundis shared <a href="https://www.youtube.com/watch?v=LIb3L4vKZ7U">this awesome talk</a> that describes how to build complex allocators out of simple ones, and covers many of the same tropes as we did here. This perspective on allocators actually blew my mind.</p> <p>Good allocators don’t just use one strategy; the use many and pick and chose the best one for the job based on expected workloads. For example, Alkyne expects to allocate many small objects; the slab pages were originally only for float objects, but it turned out to simplify a lot of the code to make <em>all</em> small objects be slab-allocated.</p> <p>Even size classes are a deep topic: TCMalloc uses <a href="https://research.google/pubs/pub36575/">GWP telemetry</a> from Google’s fleet to inform its <em>many</em> tuning parameters, including its <a href="https://github.com/google/tcmalloc/blob/master/tcmalloc/size_classes.cc">comically large</a> tables of size classes.</p> <p>At this point, we have a pretty solid allocator. Now, let’s get rid of the free function.</p> <h2 id="throwing-out-the-trash"><a href="#throwing-out-the-trash">Throwing out the Trash</a></h2> <p>Garbage collection is very different from manual memory management in that frees are performed in <em>batches</em> without cue from the user. There are no calls to <code class="language-plaintext highlighter-rouge">free()</code>; instead, we need to figure out which calls to <code class="language-plaintext highlighter-rouge">free()</code> we <em>can</em> make on the user’s behalf that they won’t notice (i.e., without quietly freeing pointers the user can still reach, resulting in a use-after-free bug). We need to do this as fast as we can.</p> <p>Alkyne is a “tracing GC”. Tracing GCs walk the “object graph” from a root set of known-reachable objects. Given an object <code class="language-plaintext highlighter-rouge">a</code>, it will <em>trace</em> through any data in the object that it knows is actually a GC pointer. In the object graph, <code class="language-plaintext highlighter-rouge">b</code> is reachable from <code class="language-plaintext highlighter-rouge">a</code> if one can repeatedly trace through GC pointers to get from <code class="language-plaintext highlighter-rouge">a</code> to <code class="language-plaintext highlighter-rouge">b</code>.</p> <p>Alkyne uses tracing to implement garbage collection in a two-step process, commonly called “mark-and-sweep”.</p> <p><em>Marking</em> consists of traversing the entire graph from a collection of reachable-by-definition values, such as things on the stack, and recording each object that is visited. Every object <em>not</em> so marked must therefore be definitely unreachable and can be reclaimed; this reclamation is called <em>sweeping</em>.</p> <p>Alkyne reverses the order of operations somewhat: it “sweeps” first and then marks, i.e., it marks every value as dead and then, as it walks the graph, marks every block as alive. It then rebuilds the free lists to reflect the new marks, allowing the blocks to be reallocated. This is sometimes called “mark and don’t sweep”, but fixing up the free lists is effectively a sweeping step.</p> <figure> <img src="https://upload.wikimedia.org/wikipedia/commons/4/4a/Animation_of_the_Naive_Mark_and_Sweep_Garbage_Collector_Algorithm.gif"/> <figcaption>Marking and sweeping! (via Wikipedia, CC0)</figcaption> </figure> <p>Alkyne is a “stop-the-world” (STW) GC. It needs to pause all program execution while cleaning out the heap. It is possible to build GCs that do not do this (I believe modern HotSpot GCs very rarely stop the world), but also very difficult. Most GCs are world-stopping to some degree.</p> <p>One thing we do not touch on is <em>when</em> to sweep. This is a more complicated and somewhat hand-wavy tuning topic that I’m going to quietly sweep under the rug by pointing you to <a href="https://cs.opensource.google/go/go/+/master:src/runtime/mgcpacer.go">how Go does it</a>.</p> <h3 id="heap-armageddon-and-resurrection"><a href="#heap-armageddon-and-resurrection">Heap Armageddon and Resurrection</a></h3> <p>Delicate freeing of individual objects is quite difficult, but scorching the earth is very easy. To do this, we walk the whole <code class="language-plaintext highlighter-rouge">Pd</code> array (see, I said this would be useful!) and blow away every <code class="language-plaintext highlighter-rouge">gc_bits</code>. This leaves the heap in a broken state where every pointer appears to be dangling. This is “armageddon”.</p> <p>To fix this up, we need to “resurrect” any objects we shouldn’t have killed (oops). The roots are objects in the Alkyne interpreter stack<sup id="fnref:stack-roots" role="doc-noteref"><a href="#fn:stack-roots" class="footnote" rel="footnote">11</a></sup>. To mark an object, we convert a pointer to it into a <code class="language-plaintext highlighter-rouge">Pd</code> via the page-<code class="language-plaintext highlighter-rouge">Pd</code> correspondence, and mark it as alive by “allocating” it.</p> <p>We then use our knowledge<sup id="fnref:interpreter-knowledge" role="doc-noteref"><a href="#fn:interpreter-knowledge" class="footnote" rel="footnote">12</a></sup> of Alkyne objects’ heap layout to find pointers to other objects in the heap (for example, the intepreter <em>knows</em> it’s looking at a list and can <em>just find</em> the list elements within, which are likely pointers themselves). If we trace into an object and find it has been marked as allocated, we don’t recurse; this avoids infinite recursion when encountering cycles.</p> <blockquote> <p>It’s a big hard to give a code example for this, because the “mark” part that’s part of the GC is mixed up with interpreter code, so there isn’t much to show in this case. :(</p> </blockquote> <p>At the end of this process, every reachable object will once again be alive, but anything we couldn’t reach stays dead.</p> <h3 id="instant-apocalypse"><a href="#instant-apocalypse">Instant Apocalypse</a></h3> <p>(Alkyne currently does not make this optimization, but really should.)</p> <p>Rather than flipping every bit, we flip the global <em>convention</em> for whether 0 or 1 means “alive”, implemented by having a global <code class="language-plaintext highlighter-rouge">bool</code> specifying which is which at any given time; this would alternate from sweep to sweep. Thus, killing every living object is now a single operation.</p> <p>This works if the allocated bit of objects in the free lists is never read, and only ever overwritten with the “alive” value when allocated, so that all of the dead objects suddenly becoming alive isn’t noticed. This does not work with slab-allocated small objects: pages may be in a mixed state where they are partially allocated and partially freed.</p> <p>We can still make this optimization by adding a second bit that tracks whether the page contains <em>any</em> living objects, using the same convention. This allows delaying the clear of the allocated bits for small objects to when the page is visited, which also marks the whole page as alive.</p> <p>Pages that were never visited (i.e., still marked as dead) can be reclaimed as usual, ignoring the allocated bits.</p> <h3 id="free-list-reconciliation"><a href="#free-list-reconciliation">Free List Reconciliation</a></h3> <p>At this point, no pointers are dangling, but newly emptied out pages are not in the free lists they should be in. To fix this, we can walk over all <code class="language-plaintext highlighter-rouge">Pd</code>s and put them where they need to go if they’re not full. This is the kinda-but-not-really sweep phase.</p> <p>The code for this is simpler to show than explaining it:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">for</span> <span class="n">pd</span> <span class="k">in</span> <span class="k">self</span><span class="nf">.reams</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">if</span> <span class="n">pd</span><span class="py">.gc_bits</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
    <span class="n">pd</span><span class="nf">.unlink</span><span class="p">();</span>
    <span class="k">if</span> <span class="n">pd</span><span class="py">.len</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
      <span class="k">unsafe</span> <span class="p">{</span> <span class="k">self</span><span class="py">.page_free_list</span><span class="nf">.push</span><span class="p">(</span><span class="n">pd</span><span class="p">)</span> <span class="p">}</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="k">unsafe</span> <span class="p">{</span> <span class="k">self</span><span class="py">.ream_free_list</span><span class="nf">.push</span><span class="p">(</span><span class="n">pd</span><span class="p">)</span> <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="n">pd</span><span class="nf">.is_full</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">// GC can't make a not-full-list become full, so we don't</span>
    <span class="c1">// need to move it.</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="c1">// Non-empty, non-full lists cannot be reams.</span>
    <span class="nd">debug_assert!</span><span class="p">(</span><span class="n">pd</span><span class="py">.class</span> <span class="o">!=</span> <span class="nn">SizeClass</span><span class="p">::</span><span class="n">Ream</span><span class="p">);</span>

    <span class="n">pd</span><span class="nf">.unlink</span><span class="p">();</span>
    <span class="k">unsafe</span> <span class="p">{</span>
      <span class="k">self</span><span class="py">.slab_free_lists</span><span class="p">[</span><span class="n">pd</span><span class="py">.class</span><span class="p">]</span><span class="nf">.push</span><span class="p">(</span><span class="n">pd</span><span class="p">)</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Of course, this will also shuffle around all pages that did not become partially empty or empty while marking. If the “instant apocalypse” optimization is used, this step must still inspect every <code class="language-plaintext highlighter-rouge">Pd</code> and modify the free lists.</p> <p>However, it is a completely separate phase: all it does is find pages that did not survive the previous mark phase. This means that user code can run between the phases, reducing latency. If it turns out to be very expensive to sweep the whole heap, it can even be run less often than mark phases<sup id="fnref:if-quick-kill" role="doc-noteref"><a href="#fn:if-quick-kill" class="footnote" rel="footnote">13</a></sup>.</p> <p>This is also a great chance to merge reams, because we’re inspecting every page anyways; this is why the merging strategy depends on wanting to be a GC’s allocator rather than a normal <code class="language-plaintext highlighter-rouge">malloc()</code>/<code class="language-plaintext highlighter-rouge">free()</code> allocator.</p> <p>…and that’s it! That’s garbage collection. The setup of completely owning the layout of blocks in the allocator allows us to cut down significantly on memory needed to track objects in the heap, while keeping the mark and sweep steps short and sweet. A garbage collector is like any other data structure: you pack in a lot of complexity into the invariants to make the actual operations very quick.</p> <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2> <p>Alkyne’s GC is intended to be super simple because I didn’t want to think too hard about it (even though I clearly did lmao). The GC layouts are a whole ‘nother story I have been swirling around in my head for months, which is described <a href="https://github.com/mcy/alkyne/blob/a62ad3b7ee70268625da640c1edeea8ff7116512/src/eval2/value.rs#L78">here</a>. The choices made there influenced the design of the GC itself.</p> <p>There are still many optimizations to make, but it’s a really simple but realistic GC design, and I’m pretty happy with it!</p> <h3 id="a-note-on-finalizers-tools-of-the-devil"><a href="#a-note-on-finalizers-tools-of-the-devil">A Note on Finalizers (Tools of the Devil!)</a></h3> <p>Alkyne also does not provide finalizers. A finalizer is the GC equivalent of a destructor: it gets run after the GC declares an object dead. Finalizers complicate a GC significantly by their very nature; they are called in unspecified orders and can witness broken GC state; they can stall the entire program (if they are implemented to run during the GC pause in a multi-threaded GC) or else need to be called with a zombie argument that either can’t escape the finalizer or, worse, must be resurrected if it does!</p> <p>If finalizers depend on each other, they can’t be run at all, for the same reason an ARC cycle cannot be broken; this weakness of ARC is one of the major benefits of an omniscient GC.</p> <p>Java’s <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#finalize()">documentation for <code class="language-plaintext highlighter-rouge">Object.finalize()</code></a> is a wall of text of lies, damned lies, and ghost stories.</p> <p>I learned earlier (the week before I started writing this article) that Go ALSO has finalizers and that they are <a href="https://pkg.go.dev/runtime#SetFinalizer">similarly cursed</a>. Go does behave somewhat more nicely than Java (finalizers are per-value and avoid zombie problems by unconditionally resurrecting objects with a finalizer).</p> <h3 id="further-reading"><a href="#further-reading">Further Reading</a></h3> <p>Here are some other allocators that I find interesting and worth reading about, some of which have inspired elements of Alkyne’s design.</p> <p><a href="https://google.github.io/tcmalloc/design.html">TCMalloc</a> is Google’s crazy thread-caching allocator. It’s really fast and really cool, but I work for Google, so I’m biased. But it uses radix trees! Radix trees are cool!!!</p> <p>Go <a href="https://cs.opensource.google/go/go/+/master:src/runtime/mgc.go">has a garbage collector</a> that has well-known performance properties but does not perform any wild optimizations like moving, and is a world-stopping, incremental GC.</p> <p><a href="https://chromium.googlesource.com/chromium/src/+/master/third_party/blink/renderer/platform/heap/BlinkGCAPIReference.md">Oilpan</a> is the Chronimum renderer’s GC (you know, for DOM elements). It’s actually grafted onto C++ and has a very complex API reflective of the subtleties of GCs as a result.</p> <p><a href="https://www.hboehm.info/gc/">libboehm</a> is another C/C++ GC written by Hans Boehm, one of the world’s top experts on concurrency.</p> <p><a href="https://v8.dev/blog/trash-talk">Orinoco</a> is V8’s GC for the JavaScript heap (i.e., Chronimum’s <em>other</em> GC). It is a <em>generational</em> or <em>moving GC</em> that can defragment the heap over time by moving things around (and updating pointers). It also has a separate sub-GC just for short-lived objects.</p> <p><a href="https://arxiv.org/abs/1902.04738">Mesh</a> is a non-GC allocator that can do compacting via clever use of <code class="language-plaintext highlighter-rouge">mmap(2)</code>.</p> <p><a href="https://github.com/protocolbuffers/upb/blob/1cf8214e4daa1d0dd9777c987697e82c2a3c6584/upb/upb.c#L117"><code class="language-plaintext highlighter-rouge">upb_Arena</code></a> is an arena allocator that uses free-lists to allows fusing arenas together. This part of the μpb Protobuf runtime.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:ast-walker" role="doc-endnote"> <p>In other words, it uses recursion along a syntax tree, instead of a more efficient approach that compiles the program down to bytecode. <a href="#fnref:ast-walker" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:arc" role="doc-endnote"> <p><em>A</em>utomatic <em>R</em>eference <em>C</em>ounting is an automatic memory management technique where every heap allocation contains a counter of how many pointers currently point to it; once pointers go out of scope, they decrement the counter; when the counter hits zero the memory is freed.</p> <p>This is used by Python and Swift as the core memory management strategy, and provided by C++ and Rust via the <code class="language-plaintext highlighter-rouge">std::shared_ptr&lt;T&gt;</code> and <code class="language-plaintext highlighter-rouge">Arc&lt;T&gt;</code> types, respectively. <a href="#fnref:arc" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:src" role="doc-endnote"> <p><a href="https://github.com/mcy/alkyne/blob/a62ad3b7ee70268625da640c1edeea8ff7116512/src/eval2/gc.rs">This is the file.</a> It’s got fairly complete comments, but they’re written for an audience familiar with allocators and garbage collectors. <a href="#fnref:src" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:nan-boxing" role="doc-endnote"> <p>This is a tangent, but I should point out that Alkyne does not do <a href="https://leonardschuetz.ch/blog/nan-boxing/">“NaN boxing”</a>. This is a technique used by some JavaScript runtimes, like Spidermonkey, which represent dynamically typed values as either ordinary floats, or pointers hidden in the mantissas of 64-bit IEEE 754 signaling NaNs.</p> <p>Alkyne instead uses something like V8’s <a href="https://v8.dev/blog/pointer-compression">Smi pointer compression</a>, so our heap values are four bytes, not eight. Non-Smi values that aren’t on the stack (which uses a completely different representation) can only exist as elements of lists or objects. Alkyne’s slab allocator design (described below) is focused on trying to minimize the overhead of all floats being in their own little allocations. <a href="#fnref:nan-boxing" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:os-allocator" role="doc-endnote"> <p>The operating system’s own physical page allocator is actually solving the same problem: given a vast range of memory (in this case, physical RAM), allocate it. The algorithms in this article apply to those, too.</p> <p>Operating system allocators can be slightly fussier because they need to deal with virtual memory mappings, but that is a topic for another time. <a href="#fnref:os-allocator" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:load-bearing" role="doc-endnote"> <p>As you might expect, these scare-quotes are load-bearing. <a href="#fnref:load-bearing" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:i-tried" role="doc-endnote"> <p>I tried leaving this out of the first draft, and failed. So many things would be simpler without fussing around with alignment. <a href="#fnref:i-tried" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:unaligned" role="doc-endnote"> <p>Yes yes most architectures can cope with unaligned loads and stores but compilers rather like to pretend that’s not true. <a href="#fnref:unaligned" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:provenance" role="doc-endnote"> <p>Boutique means <a href="https://llvm.org/docs/LangRef.html#pointer-aliasing-rules">provenance</a> in French. <a href="#fnref:provenance" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:max-size" role="doc-endnote"> <p>Currently Alkyne has a rather small max ream size. A better way to approach this would be to treat the entire heap as one gigantic ream at the start, which is always at the bottom of the free list. <a href="#fnref:max-size" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:stack-roots" role="doc-endnote"> <p>In GC terms, these are often called “stack roots”. <a href="#fnref:stack-roots" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:interpreter-knowledge" role="doc-endnote"> <p>The interpreter simply <em>knows</em> this and can instruct the GC appropriately.</p> <p>In any tracing GC, the compiler or interpreter must be keenly aware of the layouts of types so that it can generate the appropriate tracing code for each.</p> <p>This is why grafting GCs to non-GC’d languages is non-trivial, even though people have totally done it: <a href="https://www.hboehm.info/gc/">libboehm</a> and <a href="https://chromium.googlesource.com/chromium/src/+/master/third_party/blink/renderer/platform/heap/BlinkGCAPIReference.md">Oilpan</a> are good (albeit sometimes controversial) examples of how this can be done. <a href="#fnref:interpreter-knowledge" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:if-quick-kill" role="doc-endnote"> <p>With “instant apocalypse”, this isn’t quite true; after two mark phases, pages from the first mark phase will appear to be alive, since the global “alive” convention has changed twice. Thus, only pages condemned in every other mark phase will be swept; sweeping is most optimal after an odd number of marks. <a href="#fnref:if-quick-kill" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div> </div> <div class="related post-footer"> <h2>Related Posts</h2> <ul class="related-posts"> <li> <span class="post-meta">2024-12-16</span> / <h6 style="display:inline"><a href="/2024/12/16/rangefuncs/">Go's Weird Little Iterators</a></h6> <li> <span class="post-meta">2024-12-12</span> / <h6 style="display:inline"><a href="/2024/12/12/go-abi/">Things You Never Wanted To Know About Go Interfaces</a></h6> <li> <span class="post-meta">2024-12-10</span> / <h6 style="display:inline"><a href="/2024/12/10/json-sucks/">Nobody Gets Fired for Picking JSON, but Maybe They Should?</a></h6> </ul> </div> <div class="minimap"> <div class="minimap-size"></div> <div class="minimap-controller"></div> <div class="minimap-content"> <div class="content container"> <div class="post-title"> <span class="post-meta"> 2022-06-07 • 5329 words • 44 minutes <br class="show-if-mobile"/> <span class="hide-if-mobile">•</span> <a href="https://mcyoung.xyz/tags.html#dark-arts">#dark-arts</a> • <a href="https://mcyoung.xyz/tags.html#pointers">#pointers</a> </span> <h1><a href="/2022/06/07/alkyne-gc/"> The Alkyne GC </a></h1> </div> <div class="post"> <p><a href="https://github.com/mcy/alkyne">Alkyne</a> is a scripting language I built a couple of years ago for generating configuration blobs. Its interpreter is a naive AST walker<sup id="fnref:ast-walker" role="doc-noteref"><a href="#fn:ast-walker" class="footnote" rel="footnote">1</a></sup> that uses ARC<sup id="fnref:arc" role="doc-noteref"><a href="#fn:arc" class="footnote" rel="footnote">2</a></sup> for memory management, so it’s pretty slow, and I’ve been gradually writing a <a href="https://github.com/mcy/alkyne/tree/new-engine">new evaluation engine</a> for it.</p> <p>This post isn’t about Alkyne itself, that’s for another day. For now, I’d like to write down some notes for the GC I wrote<sup id="fnref:src" role="doc-noteref"><a href="#fn:src" class="footnote" rel="footnote">3</a></sup> for it, and more generally provide an introduction to memory allocators (especially those that would want to collude with a GC).</p> <p>This post is intended for people familiar with the basics of low-level programming, such as pointers and syscalls. Alkyne’s GC is intended to be simple while still having reasonable performance. This means that the design contains all the allocator “tropes,” but none of the hairy stuff.</p> <p>My hope is readers new to allocators or GCs will come away with an understanding of these tropes and the roles they play in a modern allocator.</p> <blockquote> <p>Thank you to James Farrell, Manish Goregaokar, Matt Kulukundis, JeanHeyd Meneide, Skye Thompson, and Paul Wankadia for providing feedback on various drafts of this article. This was a tough one to get right. :)</p> </blockquote> <h2 id="trailhead"><a href="#trailhead">Trailhead</a></h2> <p>The Alkyne GC is solving a very specific problem, which allows us to limit what it actually needs to do. Alkyne is an “embeddable” language like JavaScript, so its heap is not intended to be big; in fact, for the benefit of memory usage optimizations, it’s ideal to use 32-bit pointers (a 4 gigabyte address space).</p> <p>The heap needs to be able to manage arbitrarily-large allocations (for lists), and allocations as small as eight bytes (for floats<sup id="fnref:nan-boxing" role="doc-noteref"><a href="#fn:nan-boxing" class="footnote" rel="footnote">4</a></sup>). Allocation should be reasonably quick, but due to the size of the heap, walking the entire heap is totally acceptable.</p> <p>Because we’re managing a fixed-size heap, we can simply ask the operating system for a contiguous block of that size up-front using the <code class="language-plaintext highlighter-rouge">mmap()</code> syscall. An Alkyne pointer is simply a 32-bit offset into this giant allocation, which can be converted to and from a genuine CPU pointer by adding or subtracting the base address of the heap.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-text" data-lang="text"> 4GB Heap
 +-------------------------------------------------+
 |                x                                |
 +-------------------------------------------------+
 ^                ^
 base             base + ptr_to_x</code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Plaintext</div></div></div> <p>The OS won’t actually reserve 4GB of memory for us; it will only allocate one system page (4KB) at a time. If we read or write to a particular page in the heap for the first time, the OS will only then find physical RAM to back it<sup id="fnref:os-allocator" role="doc-noteref"><a href="#fn:os-allocator" class="footnote" rel="footnote">5</a></sup>.</p> <p>Throughout, we’ll be working with this fixed-size heap, and won’t think too hard about where it came from. For our purposes, it is essentially a <code class="language-plaintext highlighter-rouge">Box&lt;[u8]&gt;</code>, but we’ll call it a <code class="language-plaintext highlighter-rouge">Heap&lt;[u8]&gt;</code> to make it clear this memory we got from the operating system (but, to be clear, the entire discussion applies just as well to an ordinary gigantic <code class="language-plaintext highlighter-rouge">Box&lt;[u8]&gt;</code>)</p> <p>The Alkyne language does not have threads, so we can eschew concurrency. This significantly reduces the problems we will need to solve. Most modern allocators and garbage collectors are violently concurrent by nature, and unfortunately, much too advanced for one article. There are links below to fancier GCs you can poke around in.</p> <h2 id="a-heap-of-trouble"><a href="#a-heap-of-trouble">A Heap of Trouble</a></h2> <p>To build a garbage collector, we first need an allocator. We could “just”<sup id="fnref:load-bearing" role="doc-noteref"><a href="#fn:load-bearing" class="footnote" rel="footnote">6</a></sup> use the system heap as a source of pages, but most garbage collectors collude with the allocator, since they will want to use similar data structures. Thus, if we are building a garbage collector, we might as well build the allocator too.</p> <p>An allocator, or “memory heap” (not to be confused with a min-heap, an unrelated but <em>wicked</em> data structure), services requests for <em>allocations</em>: unique leases of space in the managed heap of various sizes, which last for lifetimes not known until runtime. These allocations may also be called <em>objects</em>, and a heap may be viewed as a general-purpose object pool.</p> <p>The most common API for a heap is:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">trait</span> <span class="n">Allocator</span> <span class="p">{</span>
  <span class="c1">// Returns a *unique pointer* managed by this allocator</span>
  <span class="c1">// to memory as large as requested, and as aligned</span>
  <span class="c1">// as we'd like.</span>
  <span class="c1">// </span>
  <span class="c1">// Returns null on failure.</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">alloc</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">;</span>
  <span class="c1">// Frees a pointer returned by `Alloc` may be called at</span>
  <span class="c1">// most once.</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">free</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">ptr</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <blockquote> <p>Originally the examples were in C++, which I feel is more accessible (lol) but given that Alkyne itself is written in Rust I felt that would make the story flow better.</p> </blockquote> <p>This is the “malloc” API, which is actually very deficient; ideally, we would do something like Rust’s <a href="https://doc.rust-lang.org/std/alloc/trait.Allocator.html"><code class="language-plaintext highlighter-rouge">Allocator</code></a>, which requires providing size <em>and</em> alignment to both the allocation <em>and</em> deallocation functions.</p> <p>Unfortunately<sup id="fnref:i-tried" role="doc-noteref"><a href="#fn:i-tried" class="footnote" rel="footnote">7</a></sup>, this means I need to explain alignment.</p> <h3 id="good-pointers-evil-pointers-lawful-pointers-chaotic-pointers"><a href="#good-pointers-evil-pointers-lawful-pointers-chaotic-pointers">Good Pointers, Evil Pointers, Lawful Pointers, Chaotic Pointers</a></h3> <p>“Alignment” is a somewhat annoying property of a pointer. A pointer is aligned to N bytes (always a power of 2) if its address is divisible by N. A pointer is “well-aligned” (or just “aligned”) if its address is aligned to the natural alignment of the thing it points to. For ints, this is <em>usually</em> their size; for structs, it is the maximum alignment among the alignments of the fields of that struct.</p> <p>Performing operations on a pointer requires that it be aligned<sup id="fnref:unaligned" role="doc-noteref"><a href="#fn:unaligned" class="footnote" rel="footnote">8</a></sup>. This is annoying because it requires some math. Specifically we need three functions:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="cd">/// Checks that `ptr` is aligned to an alignment.</span>
<span class="k">fn</span> <span class="nf">is_aligned</span><span class="p">(</span><span class="n">ptr</span><span class="p">:</span> <span class="n">Int</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">bool</span> <span class="p">{</span>
  <span class="n">ptr</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">align</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
<span class="p">}</span>

<span class="cd">/// Rounds `ptr` down to a multiple of `align`.</span>
<span class="k">fn</span> <span class="nf">align_down</span><span class="p">(</span><span class="n">ptr</span><span class="p">:</span> <span class="n">Int</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Int</span> <span class="p">{</span>
  <span class="n">ptr</span> <span class="o">&amp;</span> <span class="o">!</span><span class="p">(</span><span class="n">align</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">}</span>

<span class="cd">/// Rounds `ptr` up to a multiple of `align`.</span>
<span class="k">fn</span> <span class="nf">align_up</span><span class="p">(</span><span class="n">ptr</span><span class="p">:</span> <span class="n">Int</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="n">Int</span> <span class="p">{</span>
  <span class="c1">// (I always look this one up. &gt;_&gt;)</span>
  <span class="nf">align_down</span><span class="p">(</span><span class="n">ptr</span> <span class="o">+</span> <span class="n">align</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">align</span><span class="p">)</span>
<span class="p">}</span>

<span class="cd">/// Computes how much needs to be added to `ptr` to align it.</span>
<span class="k">fn</span> <span class="nf">misalign</span><span class="p">(</span><span class="n">ptr</span><span class="p">:</span> <span class="n">Int</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">usize</span> <span class="p">{</span>
  <span class="nf">align_up</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">align</span><span class="p">)</span> <span class="o">-</span> <span class="n">ptr</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>(Exercise: prove these formulas.)</p> <p>For the rest of the article I will assume I have these three functions available at any time for whatever type of integer I’d like (including raw pointers which are just boutique<sup id="fnref:provenance" role="doc-noteref"><a href="#fn:provenance" class="footnote" rel="footnote">9</a></sup> integers).</p> <p>Also we will treat the <code class="language-plaintext highlighter-rouge">Heap&lt;[u8]&gt;</code> holding our entire heap as being infinitely aligned; i.e. as a pointer it is aligned to all possible alignments that could matter (i.e. page-aligned, 4KB as always). (For an ordinary <code class="language-plaintext highlighter-rouge">Box&lt;[u8]&gt;</code>, this is not true.)</p> <h3 id="the-trivial-heap"><a href="#the-trivial-heap">The Trivial Heap</a></h3> <p>Allocating memory is actually very easy. <em>Arenas</em> are the leanest and meanest in the allocator food chain; they simply don’t bother to free any memory.</p> <p>This means allocation is just incrementing a cursor indicating where the hitherto-unallocated memory is.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-text" data-lang="text"> +-------------------------------------------------+
 | Allocated        | Free                         |
 +-------------------------------------------------+
                    ^
                    cursor</code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Plaintext</div></div></div> <p>Our allocator is as simple as <code class="language-plaintext highlighter-rouge">return ptr++;</code>.</p> <p>This is straightforward to implement in code:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">struct</span> <span class="n">Arena</span> <span class="p">{</span>
  <span class="n">heap</span><span class="p">:</span> <span class="n">Heap</span><span class="o">&lt;</span><span class="p">[</span><span class="nb">u8</span><span class="p">]</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">cursor</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">impl</span> <span class="n">Allocator</span> <span class="k">for</span> <span class="n">Arena</span> <span class="p">{</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">alloc</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span> <span class="p">{</span>
    <span class="c1">// To get an aligned pointer, we need to burn some "alignment</span>
    <span class="c1">// padding". This is one of the places where alignment is</span>
    <span class="c1">// annoying.</span>
    <span class="k">let</span> <span class="n">needed</span> <span class="o">=</span> <span class="n">size</span> <span class="o">+</span> <span class="nf">misalign</span><span class="p">(</span><span class="k">self</span><span class="py">.heap</span><span class="nf">.as_ptr</span><span class="p">(),</span> <span class="n">align</span><span class="p">);</span>

    <span class="c1">// Check that we're not out of memory.</span>
    <span class="k">if</span> <span class="k">self</span><span class="py">.heap</span><span class="nf">.len</span><span class="p">()</span> <span class="o">-</span> <span class="k">self</span><span class="py">.cursor</span> <span class="o">&lt;</span> <span class="n">needed</span> <span class="p">{</span>
      <span class="k">return</span> <span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">();</span>
    <span class="p">}</span>

    <span class="c1">// Advance the cursor and cut off the end of the allocated</span>
    <span class="c1">// section.</span>
    <span class="k">self</span><span class="py">.cursor</span> <span class="o">+=</span> <span class="n">needed</span><span class="p">;</span>
    <span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="py">.heap</span><span class="p">[</span><span class="k">self</span><span class="py">.cursor</span> <span class="o">-</span> <span class="n">size</span><span class="p">]</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">free</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">ptr</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// ayy lmao</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Arenas are very simple, but far from useless! They’re great for holding onto data that exists for the context of a “session”, such as for software that does lots of computations and then exits (a compiler) or software that handles requests from clients, where lots of data lives for the duration of the request and no longer (a webserver).</p> <p>They are not, however, good for long-running systems. Eventually the heap will be exhausted if objects are not recycled.</p> <p>Making this work turns out to be hard<sup>[citation-needed]</sup>. This is the “fundamental theorem” of allocators:</p> <blockquote> <h4 id="fundamental-theorem-of-allocators"><a href="#fundamental-theorem-of-allocators">Fundamental “Theorem” of Allocators</a></h4> <p>Handing out memory is easy. Handing it out <em>repeatedly</em> is hard.</p> </blockquote> <p>Thankfully, over the last fifty years we’ve mostly figured this out. Allocator designs can get pretty gnarly.</p> <h2 id="four-tropes"><a href="#four-tropes">Four Tropes</a></h2> <p>From here, we will gradually augment our allocator with more features to allow it to service all kinds of requests. For this, we will implement four common allocator features:</p> <ol> <li>Blocks and a block cache.</li> <li>Free lists.</li> <li>Block merging and splitting.</li> <li>Slab allocation.</li> </ol> <p>All four of these are present in some form in most modern allocators.</p> <h3 id="blocks"><a href="#blocks">Blocks</a></h3> <p>The first thing we should do is to deal in fixed-size blocks of memory of some minimum size. If you ask <code class="language-plaintext highlighter-rouge">malloc()</code> for a single byte, it will probably give you like 8 bytes on most systems. No one is asking <code class="language-plaintext highlighter-rouge">malloc()</code> for single bytes, so we can quietly round up and not have people care. (Also, Alkyne’s smallest heap objects are eight bytes, anyways.)</p> <p>Blocks are also convenient, because we can keep per-block metadata on each one, as a header before the user’s data:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="nd">#[repr(C)]</span>
<span class="k">struct</span> <span class="n">Block</span> <span class="p">{</span>
  <span class="n">header</span><span class="p">:</span> <span class="n">Header</span><span class="p">,</span>
  <span class="n">data</span><span class="p">:</span> <span class="p">[</span><span class="nb">u8</span><span class="p">;</span> <span class="n">BLOCK_SIZE</span><span class="p">],</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>To allow blocks to be re-used, we can keep a cache of recently freed blocks. The easiest way to do this is with a stack. Note that the heap is now made of <code class="language-plaintext highlighter-rouge">Block</code>s, not plain bytes.</p> <p>To allocate storage, first we check the stack. If the stack is empty, we revert to being an arena and increment the cursor. To free, we push the block onto the stack, so <code class="language-plaintext highlighter-rouge">alloc()</code> can return it on the next call.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">struct</span> <span class="n">BlockCache</span> <span class="p">{</span>
  <span class="n">heap</span><span class="p">:</span> <span class="n">Heap</span><span class="o">&lt;</span><span class="p">[</span><span class="n">Block</span><span class="p">]</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">cursor</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span>
  <span class="n">free_stack</span><span class="p">:</span> <span class="nb">Vec</span><span class="o">&lt;*</span><span class="k">mut</span> <span class="n">Block</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">impl</span> <span class="n">Allocator</span> <span class="k">for</span> <span class="n">BlockCache</span> <span class="p">{</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">alloc</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span> <span class="p">{</span>
    <span class="c1">// Check that the size isn't too big. We don't need to</span>
    <span class="c1">// bother with alignment, because every block is</span>
    <span class="c1">// infinitely-aligned, just like the heap itself.</span>
    <span class="k">if</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="n">BLOCK_SIZE</span> <span class="p">{</span>
      <span class="k">return</span> <span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">();</span>
    <span class="p">}</span>

    <span class="c1">// Try to serve a block from the stack.</span>
    <span class="k">if</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="o">=</span> <span class="k">self</span><span class="py">.free_stack</span><span class="nf">.pop</span><span class="p">()</span> <span class="p">{</span>
      <span class="k">return</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="n">block</span><span class="py">.data</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// Fall back to arena mode.</span>
    <span class="k">if</span> <span class="k">self</span><span class="py">.cursor</span> <span class="o">==</span> <span class="k">self</span><span class="py">.heap</span><span class="nf">.len</span><span class="p">()</span> <span class="p">{</span>
      <span class="k">return</span> <span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="k">self</span><span class="py">.cursor</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="py">.heap</span><span class="p">[</span><span class="k">self</span><span class="py">.cursor</span><span class="p">]</span><span class="py">.data</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span>
  <span class="p">}</span>

  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">free</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">ptr</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Use pointer subtraction to find the start of the block.</span>
    <span class="k">let</span> <span class="n">block</span> <span class="o">=</span> <span class="n">ptr</span><span class="nf">.sub</span><span class="p">(</span><span class="nn">size_of</span><span class="p">::</span><span class="o">&lt;</span><span class="n">Header</span><span class="o">&gt;</span><span class="p">())</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Block</span><span class="p">;</span>
    <span class="k">self</span><span class="py">.free_stack</span><span class="nf">.push</span><span class="p">(</span><span class="n">block</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>This allocator has a problem: it relies on the system allocator! <code class="language-plaintext highlighter-rouge">Heap</code> came directly from the OS, but <code class="language-plaintext highlighter-rouge">Vec</code> talks to <code class="language-plaintext highlighter-rouge">malloc()</code> (or something like it). It also adds some pretty big overhead: the <code class="language-plaintext highlighter-rouge">Vec</code> needs to be able to resize, since it grows as more and more things are freed. This can lead to long pauses during <code class="language-plaintext highlighter-rouge">free()</code> as the vector resizes.</p> <p>Cutting out the middleman gives us more control over this overhead.</p> <h3 id="free-lists"><a href="#free-lists">Free Lists</a></h3> <p>Of course, no one has ever heard of a “free stack”; everyone uses free lists! A free list is the cache idea but implemented as an <em>intrusive linked list</em>.</p> <p>A linked list is this data structure:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">enum</span> <span class="n">Node</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="p">{</span>
  <span class="nb">Nil</span><span class="p">,</span>
  <span class="nf">Cons</span><span class="p">(</span><span class="nb">Box</span><span class="o">&lt;</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">Node</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">)</span><span class="o">&gt;</span><span class="p">),</span>
  <span class="c1">//   ^~~ oops I allocated again</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>This has the same problem of needing to find an allocator to store the nodes. An intrusive list avoids that by making the nodes <em>part</em> of the elements. The <code class="language-plaintext highlighter-rouge">Header</code> we reserved for ourselves earlier is the perfect place to put it:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">struct</span> <span class="n">Header</span> <span class="p">{</span>
  <span class="cd">/// Pointer to the next and previous blocks in whatever</span>
  <span class="cd">/// list the block is in.</span>
  <span class="n">next</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Block</span><span class="p">,</span>
  <span class="n">prev</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Block</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>In particular we want to make sure block are in doubly-linked lists, which have the property that any element can be removed from them without walking the list.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-text" data-lang="text">   list.root
     |
     v
 +-&gt; Block--------------------------+
 |   | next | null | data data data |
 |   +------------------------------+
 +-----/------+
      /       |
     v        |
 +-&gt; Block--------------------------+
 |   | next | prev | data data data |
 |   +------------------------------+
 +-----/------+
      /       |
     v        |
 +-&gt; Block--------------------------+
 |   | next | prev | data data data |
 |   +------------------------------+
 +-----/------+
      /       |
     v        |
     Block--------------------------+
     | null | prev | data data data |
     +------------------------------+</code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Plaintext</div></div></div> <p>We also introduce a <code class="language-plaintext highlighter-rouge">List</code> container type that holds the root node of a list of blocks, to give us a convenient container-like API. This type looks like this:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">struct</span> <span class="n">List</span> <span class="p">{</span>
  <span class="cd">/// The root is actually a sacrificial block that exists only to</span>
  <span class="cd">/// make it possible to unlink blocks in the middle of a list. This</span>
  <span class="cd">/// needs to exist so that calling unlink() on the "first" element</span>
  <span class="cd">/// of the list has a predecessor to replace itself with.</span>
  <span class="n">root</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Block</span><span class="p">,</span>
<span class="p">}</span>

<span class="k">impl</span> <span class="n">List</span> <span class="p">{</span>
  <span class="cd">/// Pushes a block onto the list.</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">push</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">block</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="n">Block</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">block</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="n">block</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">root</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="k">self</span><span class="py">.root</span><span class="p">;</span>
    <span class="k">if</span> <span class="o">!</span><span class="n">root</span><span class="py">.header.next</span><span class="nf">.is_null</span><span class="p">()</span> <span class="p">{</span>
      <span class="k">let</span> <span class="n">first</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="n">root</span><span class="py">.header.next</span><span class="p">;</span>
      <span class="n">block</span><span class="py">.header.next</span> <span class="o">=</span> <span class="n">first</span><span class="p">;</span>
      <span class="n">first</span><span class="py">.header.prev</span> <span class="o">=</span> <span class="n">block</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">root</span><span class="py">.header.next</span> <span class="o">=</span> <span class="n">block</span><span class="p">;</span>
    <span class="n">block</span><span class="py">.header.prev</span> <span class="o">=</span> <span class="n">root</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="cd">/// Gets the first element of the list, if any.</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">first</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">Option</span><span class="o">&lt;&amp;</span><span class="k">mut</span> <span class="n">Block</span><span class="o">&gt;</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">root</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="k">self</span><span class="py">.root</span><span class="p">;</span>
    <span class="n">root</span><span class="py">.header.next</span><span class="nf">.as_mut</span><span class="p">()</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>We should also make it possible to ask a block whether it is in any list, and if so, remove it.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">impl</span> <span class="n">Block</span> <span class="p">{</span>
  <span class="cd">/// Checks if this block is part of a list.</span>
  <span class="k">fn</span> <span class="nf">is_linked</span><span class="p">(</span><span class="o">&amp;</span><span class="k">self</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="nb">bool</span> <span class="p">{</span>
    <span class="c1">// Only the prev link is guaranteed to exist; next is</span>
    <span class="c1">// null for the last element in a list. Sacrificial</span>
    <span class="c1">// nodes will never have prev non-null, and can't be</span>
    <span class="c1">// unlinked.</span>
    <span class="o">!</span><span class="k">self</span><span class="py">.header.prev</span><span class="nf">.is_null</span><span class="p">()</span>
  <span class="p">}</span>

  <span class="cd">/// Unlinks this linked block from whatever list it's in.</span>
  <span class="k">fn</span> <span class="nf">unlink</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">)</span> <span class="p">{</span>
    <span class="nd">assert!</span><span class="p">(</span><span class="k">self</span><span class="nf">.is_linked</span><span class="p">());</span>
    <span class="k">if</span> <span class="o">!</span><span class="k">self</span><span class="py">.header.next</span><span class="nf">.is_null</span><span class="p">()</span> <span class="p">{</span>
      <span class="k">let</span> <span class="n">next</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="k">self</span><span class="py">.header.next</span><span class="p">;</span>
      <span class="n">next</span><span class="py">.header.prev</span> <span class="o">=</span> <span class="k">self</span><span class="py">.header.prev</span><span class="p">;</span> 
    <span class="p">}</span>

    <span class="c1">// This is why we need the sacrificial node.</span>
    <span class="k">let</span> <span class="n">prev</span> <span class="o">=</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="k">self</span><span class="py">.header.prev</span><span class="p">;</span>
    <span class="n">prev</span><span class="py">.header.next</span> <span class="o">=</span> <span class="k">self</span><span class="py">.header.next</span><span class="p">;</span>

    <span class="k">self</span><span class="py">.header.prev</span> <span class="o">=</span> <span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">();</span>
    <span class="k">self</span><span class="py">.header.next</span> <span class="o">=</span> <span class="nn">ptr</span><span class="p">::</span><span class="nf">null_mut</span><span class="p">();</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Using these abstractions we can upgrade <code class="language-plaintext highlighter-rouge">BlockCache</code> to <code class="language-plaintext highlighter-rouge">FreeList</code>. We only need to rename <code class="language-plaintext highlighter-rouge">free_stack</code> to <code class="language-plaintext highlighter-rouge">free_list</code>, and make a one-line change:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="o">-</span> <span class="k">if</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="o">=</span> <span class="k">self</span><span class="py">.free_stack</span><span class="nf">.pop</span><span class="p">()</span> <span class="p">{</span>
<span class="o">+</span> <span class="k">if</span> <span class="k">let</span> <span class="nf">Some</span><span class="p">(</span><span class="n">block</span><span class="p">)</span> <span class="o">=</span> <span class="k">self</span><span class="py">.free_list</span><span class="nf">.first</span><span class="p">()</span> <span class="p">{</span>
<span class="o">+</span>   <span class="n">block</span><span class="nf">.unlink</span><span class="p">();</span>
    <span class="k">return</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="o">*</span><span class="n">block</span><span class="py">.data</span> <span class="k">as</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">;</span>
 <span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Hooray for encapsulation!</p> <p>This is a very early <code class="language-plaintext highlighter-rouge">malloc()</code> design, similar to the one described in the K&amp;R C book. It does have big blind spot: it can only serve up blocks up to a fixed size! It’s also quite wasteful, because all allocations are served the same size blocks: the bigger we make the maximum request, the more wasteful <code class="language-plaintext highlighter-rouge">alloc(8)</code> gets.</p> <h3 id="block-splitting-alkynes-way"><a href="#block-splitting-alkynes-way">Block Splitting (Alkyne’s Way)</a></h3> <p>The next step is to use a block splitting/merging scheme, such as the <a href="https://en.wikipedia.org/wiki/Buddy_memory_allocation"><em>buddy system</em></a>. Alkyne does not precisely use a buddy system, but it does something similar.</p> <p>Alkyne does not have fixed-size blocks. Like many allocators, it defines a “page” of memory as the atom that it keeps its data structures. Alkyne defines a page to be 4KB, but other choices are possible: TCMalloc uses 8KB pages.</p> <p>In Alkyne, pages come together to form contiguous, variable-size <em>reams</em> (get it?). These take the place of blocks.</p> <h4 id="page-descriptors"><a href="#page-descriptors">Page Descriptors</a></h4> <p>Merging and splitting makes it hard to keep headers at the start of reams, so Alkyne puts them all in a giant array somewhere else. Each page gets its own “header” called a page descriptor, or <a href="https://github.com/mcy/alkyne/blob/a62ad3b7ee70268625da640c1edeea8ff7116512/src/eval2/gc.rs#L416"><code class="language-plaintext highlighter-rouge">Pd</code></a>.</p> <p>The array of page descriptors lives at the beginning of the heap, and the actual pages follow after that. It turns out that this array has a maximum size, which we can use to pre-compute where the array ends.</p> <p>Currently, each <code class="language-plaintext highlighter-rouge">Pd</code> is 32 bytes, in addition to the 4KB it describes. If we divide 4GB by 32 + 4K, it comes out to around four million pages (4067203 to be precise). Rounded up to the next page boundary, this means that pages begin at the 127102nd 4K boundary after the <code class="language-plaintext highlighter-rouge">Heap&lt;[u8]&gt;</code> base address, or an offset of <code class="language-plaintext highlighter-rouge">0x7c1f400</code> bytes.</p> <p>Having them all in a giant array is also very useful, because it means the GC can trivially find <em>every allocation</em> in the whole heap: just iterate the <code class="language-plaintext highlighter-rouge">Pd</code> array!</p> <p>So! This is our heap:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-text" data-lang="text">+---------------------------------------+  &lt;-- mmap(2)'d region base
| Pd | Pd | Pd | Pd | Pd | Pd | Pd | Pd | \
+---------------------------------------+ |--- Page Descriptors
| Pd | Pd | Pd | Pd | Pd | Pd | Pd | Pd | |    for every page we can
+---------------------------------------+ |    ever allocate.
: ...                                   : |
+---------------------------------------+ |
| Pd | Pd | Pd | Pd | Pd | Pd | Pd | Pd | /
+---------------------------------------+  &lt;-- Heap base address
| Page 0                                | \    = region + 0x7c1f400
|                                       | |
|                                       | |--- 4K pages corresponding
+---------------------------------------+ |    to the Pds above.
| Page 1                                | |    (not to scale)
|                                       | |
|                                       | |
+---------------------------------------+ |
: ...                                   | |
+---------------------------------------+ |
| Page N                                | |
|                                       | |
|                                       | /
+---------------------------------------+
  (not to scale by a factor of about 4)</code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Plaintext</div></div></div> <p>Each one of those little <code class="language-plaintext highlighter-rouge">Pd</code>s looks something like this:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="nd">#[repr(C)]</span>
<span class="k">struct</span> <span class="n">Pd</span> <span class="p">{</span>
  <span class="n">gc_bits</span><span class="p">:</span> <span class="nb">u64</span><span class="p">,</span>
  <span class="n">prev</span><span class="p">:</span> <span class="nb">Option</span><span class="o">&lt;</span><span class="nb">u32</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">next</span><span class="p">:</span> <span class="nb">Option</span><span class="o">&lt;</span><span class="nb">u32</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">len</span><span class="p">:</span> <span class="nb">u16</span><span class="p">,</span>
  <span class="n">class</span><span class="p">:</span> <span class="n">SizeClass</span><span class="p">,</span>
  <span class="c1">// More fields...</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p><code class="language-plaintext highlighter-rouge">prev</code> and <code class="language-plaintext highlighter-rouge">next</code> are the intrusive linked list pointers used for the free lists, but now they are indices into the <code class="language-plaintext highlighter-rouge">Pd</code> array. The other fields will be used for this and the trope that follows.</p> <p>Given a pointer into a page, we can get the corresponding <code class="language-plaintext highlighter-rouge">Pd</code> by <code class="language-plaintext highlighter-rouge">align_down()</code>‘ing to a page boundary, computing the index of the page (relative to the heap base), and then index into the <code class="language-plaintext highlighter-rouge">Pd</code> array. This process can be reversed to convert a pointer to a <code class="language-plaintext highlighter-rouge">Pd</code> into a pointer to a page, so going between the two is very easy.</p> <blockquote> <p>I won’t cover this here, but Alkyne actually wraps <code class="language-plaintext highlighter-rouge">Pd</code> pointers in a special <code class="language-plaintext highlighter-rouge">PdRef</code> type that also carries a reference to the <code class="language-plaintext highlighter-rouge">Heap</code>; this allows implementing functions like <code class="language-plaintext highlighter-rouge">is_linked()</code>, <code class="language-plaintext highlighter-rouge">unlink()</code>, and <code class="language-plaintext highlighter-rouge">data()</code> directly.</p> <p>I won’t show how this is implemented, since it’s mostly boilerplate.</p> </blockquote> <h4 id="reams-of-pages"><a href="#reams-of-pages">Reams of Pages</a></h4> <p>There is one giant free list that contains all of the reams. Reams use their first page’s descriptor to track all of their metadata, including the list pointers for the free list. The <code class="language-plaintext highlighter-rouge">len</code> field additionally tracks how many <em>additional</em> pages are in the ream. <code class="language-plaintext highlighter-rouge">gc_bits</code> is set to 1 if the page is in use and 0 otherwise.</p> <p>To allocate N continuous pages from the free ream list:</p> <ol> <li>We walk through the free ream list, and pick the first one with at least N pages.</li> <li>We “split” it: the first N pages are returned to fulfill the request.</li> <li>The rest of the ream is put back into the free list.</li> <li>If no such ream exists, we allocate a max-sized ream<sup id="fnref:max-size" role="doc-noteref"><a href="#fn:max-size" class="footnote" rel="footnote">10</a></sup> (65536 pages), and split that as above.</li> </ol> <p>In a sense, each ream is an arena that we allocate smaller reams out of; those reams cannot be “freed” back to the ream they came from. Instead, to free a ream, we just stick it back on the main free list.</p> <p>If we ever run out, we turn back into an arena and initialize the next uninitialized <code class="language-plaintext highlighter-rouge">Pd</code> in the big ol’ <code class="language-plaintext highlighter-rouge">Pd</code> array.</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">struct</span> <span class="n">ReamAlloc</span> <span class="p">{</span>
  <span class="n">heap</span><span class="p">:</span> <span class="n">Heap</span><span class="o">&lt;</span><span class="p">[</span><span class="n">Page</span><span class="p">]</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">cursor</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span>
  <span class="n">free_list</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span>
<span class="p">}</span>

<span class="cd">/// The offset to the end of the maximally-large Pd array.</span>
<span class="cd">/// This can be computed ahead of time.</span>
<span class="k">const</span> <span class="n">PAGES_START</span><span class="p">:</span> <span class="nb">usize</span> <span class="o">=</span> <span class="o">...</span><span class="p">;</span>

<span class="k">impl</span> <span class="n">Allocator</span> <span class="k">for</span> <span class="n">ReamAlloc</span> <span class="p">{</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">alloc</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">usize</span><span class="p">,</span> <span class="n">align</span><span class="p">:</span> <span class="nb">usize</span><span class="p">)</span> <span class="k">-&gt;</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span> <span class="p">{</span>
    <span class="c1">// We don't need to bother with alignment, because every page is</span>
    <span class="c1">// already infinitely aligned; we only allocate at the page</span>
    <span class="c1">// boundary.</span>
    <span class="k">let</span> <span class="n">page_count</span> <span class="o">=</span> <span class="nf">align_up</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span> <span class="o">/</span> <span class="mi">4096</span><span class="p">;</span>

    <span class="c1">// Find the first page in the list that's big enough.</span>
    <span class="c1">// (Making `List` iterable is an easy exercise.)</span>
    <span class="k">for</span> <span class="n">pd</span> <span class="k">in</span> <span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="py">.list</span> <span class="p">{</span>
      <span class="k">if</span> <span class="n">pd</span><span class="py">.len</span> <span class="o">&lt;</span> <span class="n">page_count</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">{</span>
        <span class="k">continue</span>
      <span class="p">}</span>
      <span class="k">if</span> <span class="n">pd</span><span class="py">.len</span> <span class="o">==</span> <span class="n">page_count</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">{</span>
        <span class="c1">// No need to split here.</span>
        <span class="n">pd</span><span class="nf">.unlink</span><span class="p">();</span>
        <span class="k">return</span> <span class="n">pd</span><span class="nf">.data</span><span class="p">();</span>
      <span class="p">}</span>

      <span class="c1">// We can chop off the *end* of the ream to avoid needing</span>
      <span class="c1">// to update any pointers.</span>
      <span class="k">let</span> <span class="n">new_ream</span> <span class="o">=</span> <span class="n">pd</span><span class="nf">.add</span><span class="p">(</span><span class="n">page_count</span><span class="p">);</span>
      <span class="n">new_ream</span><span class="py">.len</span> <span class="o">=</span> <span class="n">page_count</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>
      <span class="n">pd</span><span class="py">.len</span> <span class="o">-=</span> <span class="n">page_count</span><span class="p">;</span>

      <span class="k">return</span> <span class="n">new_ream</span><span class="nf">.data</span><span class="p">();</span>
    <span class="p">}</span>

    <span class="c1">// Allocate a new ream. This is more of the same arena stuff.</span>
  <span class="p">}</span>
  <span class="k">unsafe</span> <span class="k">fn</span> <span class="nf">free</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="k">self</span><span class="p">,</span> <span class="n">ptr</span><span class="p">:</span> <span class="o">*</span><span class="k">mut</span> <span class="nb">u8</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Find the Pd corresponding to this page's pointer. This</span>
    <span class="c1">// will always be a ream's first Pd assuming the user</span>
    <span class="c1">// didn't give us a bad pointer.</span>
    <span class="k">let</span> <span class="n">pd</span> <span class="o">=</span> <span class="nn">Pd</span><span class="p">::</span><span class="nf">from_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">);</span>
    <span class="k">self</span><span class="py">.free_list</span><span class="nf">.push</span><span class="p">(</span><span class="n">pd</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>This presents a problem: over time, reams will shrink and never grow, and eventually there will be nothing left but single pages.</p> <p>Top fix this, we can merge reams (not yet implemented in Alkyne). Thus:</p> <ol> <li>Find two adjacent, unallocated reams.</li> <li>Unlink the second ream from the free list.</li> <li>Increase the length of the first ream by the number of pages in the second.</li> </ol> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="c1">// `reams()` returns an iterator that walks the `Pd` array using</span>
<span class="c1">// the `len` fields to find the next ream each time.</span>
<span class="k">for</span> <span class="n">pd</span> <span class="k">in</span> <span class="k">self</span><span class="nf">.reams</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">if</span> <span class="n">pd</span><span class="py">.gc_bits</span> <span class="o">!=</span> <span class="mi">0</span> <span class="p">{</span> <span class="k">continue</span> <span class="p">}</span>
  <span class="k">loop</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">next</span> <span class="o">=</span> <span class="n">pd</span><span class="nf">.add</span><span class="p">(</span><span class="n">pd</span><span class="py">.len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
    <span class="k">if</span> <span class="n">next</span><span class="py">.gc_bits</span> <span class="o">!=</span> <span class="mi">0</span> <span class="p">{</span> <span class="k">break</span> <span class="p">}</span>
    <span class="n">next</span><span class="nf">.unlink</span><span class="p">();</span>
    <span class="n">pd</span><span class="py">.len</span> <span class="o">+=</span> <span class="n">next</span><span class="py">.len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>We don’t need to do anything to the second ream’s <code class="language-plaintext highlighter-rouge">Pd</code>; by becoming part of the first ream, it is subsumed. Walking the heap requires using reams’ lengths to skip over currently-invalid <code class="language-plaintext highlighter-rouge">Pd</code>s, anyways.</p> <p>We have two options for finding mergeable reams. Either we can walk the entire heap, as above, or, when a ream is freed, we can check that the previous and following reams are mergeable (finding the previous ream would require storing the length of a ream at its first <em>and</em> last <code class="language-plaintext highlighter-rouge">Pd</code>).</p> <p>Which merging strategy we use depends on whether we’re implementing an ordinary <code class="language-plaintext highlighter-rouge">malloc</code>-like heap or a garbage collector; in the <code class="language-plaintext highlighter-rouge">malloc</code> case, merging on free makes more sense, but merging in one shot makes more sense for Alkyne’s GC (we’ll see why in a bit).</p> <h3 id="slabs-and-size-classes"><a href="#slabs-and-size-classes">Slabs and Size Classes</a></h3> <p>A <em>slab allocator</em> is a specialized allocator that allocates a single type of object; they are quite popular in kernels as pools of commonly-used object. The crux of a slab allocator is that, because everything is the same size, we <em>don’t</em> need to implement splitting and merging. The <code class="language-plaintext highlighter-rouge">BlockCache</code> above is actually a very primitive slab allocator.</p> <p>Our <code class="language-plaintext highlighter-rouge">Pd</code> array is also kind of like a slab allocator; instead of mixing them in with the variably-sized blocks, they all live together with no gaps in between; entire pages are dedicated just to <code class="language-plaintext highlighter-rouge">Pd</code>s.</p> <p>The Alkyne page allocator cannot allocate pages smaller than 4K, and making them any smaller increases the relative overhead of a <code class="language-plaintext highlighter-rouge">Pd</code>. To cut down on book-keeping, we slab-allocate small objects by defining <em>size classes</em>.</p> <p>A size class is size of smaller-than-a-page object that Alkyne will allocate; other sizes are rounded up to the next size class. Entire pages are dedicated to holding just objects of the same size; these are called small object pages, or simply <em>slabs</em>. The size class is tracked with the <code class="language-plaintext highlighter-rouge">class</code> field of the <code class="language-plaintext highlighter-rouge">Pd</code>.</p> <p>Each size class has its own free list of partially-filled slabs of that size. For slabs, <code class="language-plaintext highlighter-rouge">gc_bits</code> field becomes a bitset that tracks which slots in the page are currently in-use, reducing the overhead for small objects to only a little over a single bit each!</p> <p>In the diagram below, bits set in the 32-bit, little-endian bitset indicate which slots in the slab (no to scale!) are filled with three-letter words. (The user likes cats.)</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-text" data-lang="text">  Pd--------------------------------------------+
  | gc_bits: 0b01010011111010100110000010101011 |
  +---------------------------------------------+

 Page--------------------------------------------+
 | cat | ink |     | hat |     | jug |     | fig |
 +-----------------------------------------------+
 |     |     |     |     |     | zip | net |     |
 +-----------------------------------------------+
 |     | aid |     | yes |     | war | cat | van |
 +-----------------------------------------------+
 | can | cat |     |     | rat |     | urn |     |
 +-----------------------------------------------+</code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Plaintext</div></div></div> <p>Allocating an object is a bit more complicated now, but now we have a really, really short fast path for small objects:</p> <ol> <li>Round up to the next highest size class, or else to the next page boundary.</li> <li>If a slab size class… a. Check the pertinent slab list for a partially-filled slab. i. If there isn’t one, allocate a page per the instructions below and initialize it as a slab page. b. Find the next available slot with <code class="language-plaintext highlighter-rouge">(!gc_bits).count_trailing_zeros()</code>, and set that bit. c. Return <code class="language-plaintext highlighter-rouge">page_addr + slab_slot_size * slot</code>.</li> <li>Else, if a single page, allocate from the single-page list. a. If there isn’t one, allocate from the ream list as usual.</li> <li>Else, multiple pages, allocate a ream as usual.</li> </ol> <p>Allocating small objects is very fast, since the slab free lists, if not empty, will always have a spot to fill in <code class="language-plaintext highlighter-rouge">gc_bits</code>. Finding the empty spot in the bitset is a few instructions (a <code class="language-plaintext highlighter-rouge">not</code> plust a <code class="language-plaintext highlighter-rouge">ctz</code> or equivalent on most hardware).</p> <p>Alkyne maintains a separate free list for single free pages to speed up finding such pages to turn into fresh slabs. This also minimizes the need to allocate single pages off of large reams, which limits fragmentation.</p> <p>Alkyne’s size classes are the powers of two from 8 (the smallest possible object) to 2048. For the classes 8, 16, and 32, which would have more than 64 slots in the page, we use up to 56 bytes on the page itself to extend <code class="language-plaintext highlighter-rouge">gc_bits</code>; 8-byte pages can only hold 505 objects, instead of the full 512, a 1% overhead.</p> <p>Directly freeing an object via is now tricky, since we do not a priori know the size.</p> <ol> <li>Round the pointer up to the next page boundary, and obtain that page’s <code class="language-plaintext highlighter-rouge">Pd</code>.</li> <li>If this is a start-of-ream page, stick it into the appropriate free list (single page or ream, depending on the size of the ream).</li> <li>Else, we can look at <code class="language-plaintext highlighter-rouge">class</code> to find the size class, and from that, and the offset of the original pointer into the page, the index of the slot.</li> <li>Clear the slot’s index in <code class="language-plaintext highlighter-rouge">gc_bits</code>.</li> <li>If the page was full before, place it onto the correct slab free list; if it becomes empty, place it into the page free list.</li> </ol> <p>At this point, we know whether the page just became partially full or empty, and can move it to the correct free list.</p> <p>Size classes are an important allocator optimization. TCMalloc takes this to an . These constants are generated by some crazy script based on profiling data.</p> <h2 id="intermission"><a href="#intermission">Intermission</a></h2> <p>Before continuing to the GC part of the article, it’s useful to go over what we learned.</p> <p>A neat thing about this is that most of these tricks are somewhat independent. While giving feedback for an early draft, Matt Kulukundis shared <a href="https://www.youtube.com/watch?v=LIb3L4vKZ7U">this awesome talk</a> that describes how to build complex allocators out of simple ones, and covers many of the same tropes as we did here. This perspective on allocators actually blew my mind.</p> <p>Good allocators don’t just use one strategy; the use many and pick and chose the best one for the job based on expected workloads. For example, Alkyne expects to allocate many small objects; the slab pages were originally only for float objects, but it turned out to simplify a lot of the code to make <em>all</em> small objects be slab-allocated.</p> <p>Even size classes are a deep topic: TCMalloc uses <a href="https://research.google/pubs/pub36575/">GWP telemetry</a> from Google’s fleet to inform its <em>many</em> tuning parameters, including its <a href="https://github.com/google/tcmalloc/blob/master/tcmalloc/size_classes.cc">comically large</a> tables of size classes.</p> <p>At this point, we have a pretty solid allocator. Now, let’s get rid of the free function.</p> <h2 id="throwing-out-the-trash"><a href="#throwing-out-the-trash">Throwing out the Trash</a></h2> <p>Garbage collection is very different from manual memory management in that frees are performed in <em>batches</em> without cue from the user. There are no calls to <code class="language-plaintext highlighter-rouge">free()</code>; instead, we need to figure out which calls to <code class="language-plaintext highlighter-rouge">free()</code> we <em>can</em> make on the user’s behalf that they won’t notice (i.e., without quietly freeing pointers the user can still reach, resulting in a use-after-free bug). We need to do this as fast as we can.</p> <p>Alkyne is a “tracing GC”. Tracing GCs walk the “object graph” from a root set of known-reachable objects. Given an object <code class="language-plaintext highlighter-rouge">a</code>, it will <em>trace</em> through any data in the object that it knows is actually a GC pointer. In the object graph, <code class="language-plaintext highlighter-rouge">b</code> is reachable from <code class="language-plaintext highlighter-rouge">a</code> if one can repeatedly trace through GC pointers to get from <code class="language-plaintext highlighter-rouge">a</code> to <code class="language-plaintext highlighter-rouge">b</code>.</p> <p>Alkyne uses tracing to implement garbage collection in a two-step process, commonly called “mark-and-sweep”.</p> <p><em>Marking</em> consists of traversing the entire graph from a collection of reachable-by-definition values, such as things on the stack, and recording each object that is visited. Every object <em>not</em> so marked must therefore be definitely unreachable and can be reclaimed; this reclamation is called <em>sweeping</em>.</p> <p>Alkyne reverses the order of operations somewhat: it “sweeps” first and then marks, i.e., it marks every value as dead and then, as it walks the graph, marks every block as alive. It then rebuilds the free lists to reflect the new marks, allowing the blocks to be reallocated. This is sometimes called “mark and don’t sweep”, but fixing up the free lists is effectively a sweeping step.</p> <figure> <img src="https://upload.wikimedia.org/wikipedia/commons/4/4a/Animation_of_the_Naive_Mark_and_Sweep_Garbage_Collector_Algorithm.gif"/> <figcaption>Marking and sweeping! (via Wikipedia, CC0)</figcaption> </figure> <p>Alkyne is a “stop-the-world” (STW) GC. It needs to pause all program execution while cleaning out the heap. It is possible to build GCs that do not do this (I believe modern HotSpot GCs very rarely stop the world), but also very difficult. Most GCs are world-stopping to some degree.</p> <p>One thing we do not touch on is <em>when</em> to sweep. This is a more complicated and somewhat hand-wavy tuning topic that I’m going to quietly sweep under the rug by pointing you to <a href="https://cs.opensource.google/go/go/+/master:src/runtime/mgcpacer.go">how Go does it</a>.</p> <h3 id="heap-armageddon-and-resurrection"><a href="#heap-armageddon-and-resurrection">Heap Armageddon and Resurrection</a></h3> <p>Delicate freeing of individual objects is quite difficult, but scorching the earth is very easy. To do this, we walk the whole <code class="language-plaintext highlighter-rouge">Pd</code> array (see, I said this would be useful!) and blow away every <code class="language-plaintext highlighter-rouge">gc_bits</code>. This leaves the heap in a broken state where every pointer appears to be dangling. This is “armageddon”.</p> <p>To fix this up, we need to “resurrect” any objects we shouldn’t have killed (oops). The roots are objects in the Alkyne interpreter stack<sup id="fnref:stack-roots" role="doc-noteref"><a href="#fn:stack-roots" class="footnote" rel="footnote">11</a></sup>. To mark an object, we convert a pointer to it into a <code class="language-plaintext highlighter-rouge">Pd</code> via the page-<code class="language-plaintext highlighter-rouge">Pd</code> correspondence, and mark it as alive by “allocating” it.</p> <p>We then use our knowledge<sup id="fnref:interpreter-knowledge" role="doc-noteref"><a href="#fn:interpreter-knowledge" class="footnote" rel="footnote">12</a></sup> of Alkyne objects’ heap layout to find pointers to other objects in the heap (for example, the intepreter <em>knows</em> it’s looking at a list and can <em>just find</em> the list elements within, which are likely pointers themselves). If we trace into an object and find it has been marked as allocated, we don’t recurse; this avoids infinite recursion when encountering cycles.</p> <blockquote> <p>It’s a big hard to give a code example for this, because the “mark” part that’s part of the GC is mixed up with interpreter code, so there isn’t much to show in this case. :(</p> </blockquote> <p>At the end of this process, every reachable object will once again be alive, but anything we couldn’t reach stays dead.</p> <h3 id="instant-apocalypse"><a href="#instant-apocalypse">Instant Apocalypse</a></h3> <p>(Alkyne currently does not make this optimization, but really should.)</p> <p>Rather than flipping every bit, we flip the global <em>convention</em> for whether 0 or 1 means “alive”, implemented by having a global <code class="language-plaintext highlighter-rouge">bool</code> specifying which is which at any given time; this would alternate from sweep to sweep. Thus, killing every living object is now a single operation.</p> <p>This works if the allocated bit of objects in the free lists is never read, and only ever overwritten with the “alive” value when allocated, so that all of the dead objects suddenly becoming alive isn’t noticed. This does not work with slab-allocated small objects: pages may be in a mixed state where they are partially allocated and partially freed.</p> <p>We can still make this optimization by adding a second bit that tracks whether the page contains <em>any</em> living objects, using the same convention. This allows delaying the clear of the allocated bits for small objects to when the page is visited, which also marks the whole page as alive.</p> <p>Pages that were never visited (i.e., still marked as dead) can be reclaimed as usual, ignoring the allocated bits.</p> <h3 id="free-list-reconciliation"><a href="#free-list-reconciliation">Free List Reconciliation</a></h3> <p>At this point, no pointers are dangling, but newly emptied out pages are not in the free lists they should be in. To fix this, we can walk over all <code class="language-plaintext highlighter-rouge">Pd</code>s and put them where they need to go if they’re not full. This is the kinda-but-not-really sweep phase.</p> <p>The code for this is simpler to show than explaining it:</p> <div class="codeblock"><figure class="highlight"><pre><code class="language-rust" data-lang="rust"><span class="k">for</span> <span class="n">pd</span> <span class="k">in</span> <span class="k">self</span><span class="nf">.reams</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">if</span> <span class="n">pd</span><span class="py">.gc_bits</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
    <span class="n">pd</span><span class="nf">.unlink</span><span class="p">();</span>
    <span class="k">if</span> <span class="n">pd</span><span class="py">.len</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
      <span class="k">unsafe</span> <span class="p">{</span> <span class="k">self</span><span class="py">.page_free_list</span><span class="nf">.push</span><span class="p">(</span><span class="n">pd</span><span class="p">)</span> <span class="p">}</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="k">unsafe</span> <span class="p">{</span> <span class="k">self</span><span class="py">.ream_free_list</span><span class="nf">.push</span><span class="p">(</span><span class="n">pd</span><span class="p">)</span> <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="n">pd</span><span class="nf">.is_full</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">// GC can't make a not-full-list become full, so we don't</span>
    <span class="c1">// need to move it.</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="c1">// Non-empty, non-full lists cannot be reams.</span>
    <span class="nd">debug_assert!</span><span class="p">(</span><span class="n">pd</span><span class="py">.class</span> <span class="o">!=</span> <span class="nn">SizeClass</span><span class="p">::</span><span class="n">Ream</span><span class="p">);</span>

    <span class="n">pd</span><span class="nf">.unlink</span><span class="p">();</span>
    <span class="k">unsafe</span> <span class="p">{</span>
      <span class="k">self</span><span class="py">.slab_free_lists</span><span class="p">[</span><span class="n">pd</span><span class="py">.class</span><span class="p">]</span><span class="nf">.push</span><span class="p">(</span><span class="n">pd</span><span class="p">)</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure><div class="codeblock-buttons"><div class="codeblock-button">Rust</div></div></div> <p>Of course, this will also shuffle around all pages that did not become partially empty or empty while marking. If the “instant apocalypse” optimization is used, this step must still inspect every <code class="language-plaintext highlighter-rouge">Pd</code> and modify the free lists.</p> <p>However, it is a completely separate phase: all it does is find pages that did not survive the previous mark phase. This means that user code can run between the phases, reducing latency. If it turns out to be very expensive to sweep the whole heap, it can even be run less often than mark phases<sup id="fnref:if-quick-kill" role="doc-noteref"><a href="#fn:if-quick-kill" class="footnote" rel="footnote">13</a></sup>.</p> <p>This is also a great chance to merge reams, because we’re inspecting every page anyways; this is why the merging strategy depends on wanting to be a GC’s allocator rather than a normal <code class="language-plaintext highlighter-rouge">malloc()</code>/<code class="language-plaintext highlighter-rouge">free()</code> allocator.</p> <p>…and that’s it! That’s garbage collection. The setup of completely owning the layout of blocks in the allocator allows us to cut down significantly on memory needed to track objects in the heap, while keeping the mark and sweep steps short and sweet. A garbage collector is like any other data structure: you pack in a lot of complexity into the invariants to make the actual operations very quick.</p> <h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2> <p>Alkyne’s GC is intended to be super simple because I didn’t want to think too hard about it (even though I clearly did lmao). The GC layouts are a whole ‘nother story I have been swirling around in my head for months, which is described <a href="https://github.com/mcy/alkyne/blob/a62ad3b7ee70268625da640c1edeea8ff7116512/src/eval2/value.rs#L78">here</a>. The choices made there influenced the design of the GC itself.</p> <p>There are still many optimizations to make, but it’s a really simple but realistic GC design, and I’m pretty happy with it!</p> <h3 id="a-note-on-finalizers-tools-of-the-devil"><a href="#a-note-on-finalizers-tools-of-the-devil">A Note on Finalizers (Tools of the Devil!)</a></h3> <p>Alkyne also does not provide finalizers. A finalizer is the GC equivalent of a destructor: it gets run after the GC declares an object dead. Finalizers complicate a GC significantly by their very nature; they are called in unspecified orders and can witness broken GC state; they can stall the entire program (if they are implemented to run during the GC pause in a multi-threaded GC) or else need to be called with a zombie argument that either can’t escape the finalizer or, worse, must be resurrected if it does!</p> <p>If finalizers depend on each other, they can’t be run at all, for the same reason an ARC cycle cannot be broken; this weakness of ARC is one of the major benefits of an omniscient GC.</p> <p>Java’s <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Object.html#finalize()">documentation for <code class="language-plaintext highlighter-rouge">Object.finalize()</code></a> is a wall of text of lies, damned lies, and ghost stories.</p> <p>I learned earlier (the week before I started writing this article) that Go ALSO has finalizers and that they are <a href="https://pkg.go.dev/runtime#SetFinalizer">similarly cursed</a>. Go does behave somewhat more nicely than Java (finalizers are per-value and avoid zombie problems by unconditionally resurrecting objects with a finalizer).</p> <h3 id="further-reading"><a href="#further-reading">Further Reading</a></h3> <p>Here are some other allocators that I find interesting and worth reading about, some of which have inspired elements of Alkyne’s design.</p> <p><a href="https://google.github.io/tcmalloc/design.html">TCMalloc</a> is Google’s crazy thread-caching allocator. It’s really fast and really cool, but I work for Google, so I’m biased. But it uses radix trees! Radix trees are cool!!!</p> <p>Go <a href="https://cs.opensource.google/go/go/+/master:src/runtime/mgc.go">has a garbage collector</a> that has well-known performance properties but does not perform any wild optimizations like moving, and is a world-stopping, incremental GC.</p> <p><a href="https://chromium.googlesource.com/chromium/src/+/master/third_party/blink/renderer/platform/heap/BlinkGCAPIReference.md">Oilpan</a> is the Chronimum renderer’s GC (you know, for DOM elements). It’s actually grafted onto C++ and has a very complex API reflective of the subtleties of GCs as a result.</p> <p><a href="https://www.hboehm.info/gc/">libboehm</a> is another C/C++ GC written by Hans Boehm, one of the world’s top experts on concurrency.</p> <p><a href="https://v8.dev/blog/trash-talk">Orinoco</a> is V8’s GC for the JavaScript heap (i.e., Chronimum’s <em>other</em> GC). It is a <em>generational</em> or <em>moving GC</em> that can defragment the heap over time by moving things around (and updating pointers). It also has a separate sub-GC just for short-lived objects.</p> <p><a href="https://arxiv.org/abs/1902.04738">Mesh</a> is a non-GC allocator that can do compacting via clever use of <code class="language-plaintext highlighter-rouge">mmap(2)</code>.</p> <p><a href="https://github.com/protocolbuffers/upb/blob/1cf8214e4daa1d0dd9777c987697e82c2a3c6584/upb/upb.c#L117"><code class="language-plaintext highlighter-rouge">upb_Arena</code></a> is an arena allocator that uses free-lists to allows fusing arenas together. This part of the μpb Protobuf runtime.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:ast-walker" role="doc-endnote"> <p>In other words, it uses recursion along a syntax tree, instead of a more efficient approach that compiles the program down to bytecode. <a href="#fnref:ast-walker" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:arc" role="doc-endnote"> <p><em>A</em>utomatic <em>R</em>eference <em>C</em>ounting is an automatic memory management technique where every heap allocation contains a counter of how many pointers currently point to it; once pointers go out of scope, they decrement the counter; when the counter hits zero the memory is freed.</p> <p>This is used by Python and Swift as the core memory management strategy, and provided by C++ and Rust via the <code class="language-plaintext highlighter-rouge">std::shared_ptr&lt;T&gt;</code> and <code class="language-plaintext highlighter-rouge">Arc&lt;T&gt;</code> types, respectively. <a href="#fnref:arc" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:src" role="doc-endnote"> <p><a href="https://github.com/mcy/alkyne/blob/a62ad3b7ee70268625da640c1edeea8ff7116512/src/eval2/gc.rs">This is the file.</a> It’s got fairly complete comments, but they’re written for an audience familiar with allocators and garbage collectors. <a href="#fnref:src" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:nan-boxing" role="doc-endnote"> <p>This is a tangent, but I should point out that Alkyne does not do <a href="https://leonardschuetz.ch/blog/nan-boxing/">“NaN boxing”</a>. This is a technique used by some JavaScript runtimes, like Spidermonkey, which represent dynamically typed values as either ordinary floats, or pointers hidden in the mantissas of 64-bit IEEE 754 signaling NaNs.</p> <p>Alkyne instead uses something like V8’s <a href="https://v8.dev/blog/pointer-compression">Smi pointer compression</a>, so our heap values are four bytes, not eight. Non-Smi values that aren’t on the stack (which uses a completely different representation) can only exist as elements of lists or objects. Alkyne’s slab allocator design (described below) is focused on trying to minimize the overhead of all floats being in their own little allocations. <a href="#fnref:nan-boxing" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:os-allocator" role="doc-endnote"> <p>The operating system’s own physical page allocator is actually solving the same problem: given a vast range of memory (in this case, physical RAM), allocate it. The algorithms in this article apply to those, too.</p> <p>Operating system allocators can be slightly fussier because they need to deal with virtual memory mappings, but that is a topic for another time. <a href="#fnref:os-allocator" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:load-bearing" role="doc-endnote"> <p>As you might expect, these scare-quotes are load-bearing. <a href="#fnref:load-bearing" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:i-tried" role="doc-endnote"> <p>I tried leaving this out of the first draft, and failed. So many things would be simpler without fussing around with alignment. <a href="#fnref:i-tried" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:unaligned" role="doc-endnote"> <p>Yes yes most architectures can cope with unaligned loads and stores but compilers rather like to pretend that’s not true. <a href="#fnref:unaligned" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:provenance" role="doc-endnote"> <p>Boutique means <a href="https://llvm.org/docs/LangRef.html#pointer-aliasing-rules">provenance</a> in French. <a href="#fnref:provenance" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:max-size" role="doc-endnote"> <p>Currently Alkyne has a rather small max ream size. A better way to approach this would be to treat the entire heap as one gigantic ream at the start, which is always at the bottom of the free list. <a href="#fnref:max-size" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:stack-roots" role="doc-endnote"> <p>In GC terms, these are often called “stack roots”. <a href="#fnref:stack-roots" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:interpreter-knowledge" role="doc-endnote"> <p>The interpreter simply <em>knows</em> this and can instruct the GC appropriately.</p> <p>In any tracing GC, the compiler or interpreter must be keenly aware of the layouts of types so that it can generate the appropriate tracing code for each.</p> <p>This is why grafting GCs to non-GC’d languages is non-trivial, even though people have totally done it: <a href="https://www.hboehm.info/gc/">libboehm</a> and <a href="https://chromium.googlesource.com/chromium/src/+/master/third_party/blink/renderer/platform/heap/BlinkGCAPIReference.md">Oilpan</a> are good (albeit sometimes controversial) examples of how this can be done. <a href="#fnref:interpreter-knowledge" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:if-quick-kill" role="doc-endnote"> <p>With “instant apocalypse”, this isn’t quite true; after two mark phases, pages from the first mark phase will appear to be alive, since the global “alive” convention has changed twice. Thus, only pages condemned in every other mark phase will be swept; sweeping is most optimal after an odd number of marks. <a href="#fnref:if-quick-kill" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div> </div> <div class="related post-footer"> <h2>Related Posts</h2> <ul class="related-posts"> <li> <span class="post-meta">2024-12-16</span> / <h6 style="display:inline"><a href="/2024/12/16/rangefuncs/">Go's Weird Little Iterators</a></h6> <li> <span class="post-meta">2024-12-12</span> / <h6 style="display:inline"><a href="/2024/12/12/go-abi/">Things You Never Wanted To Know About Go Interfaces</a></h6> <li> <span class="post-meta">2024-12-10</span> / <h6 style="display:inline"><a href="/2024/12/10/json-sucks/">Nobody Gets Fired for Picking JSON, but Maybe They Should?</a></h6> </ul> </div> </div> </div> </div></div> <div class="sidebar show-if-mobile footer"> <div class="container sidebar-sticky"> <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC BY-SA</a> • <a href="https://varz.mcyoung.xyz/">Site Analytics</a> <br> &copy; 2024 Miguel Young de la Sota </div> </div> </body> </html>